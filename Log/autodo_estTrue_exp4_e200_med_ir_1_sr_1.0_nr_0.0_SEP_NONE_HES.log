[2022-10-14 21:17:13,503] exp4_main.py->main line:122 [INFO]Namespace(aug_model='SEP', data='./local_data', dataset='med', epochs=200, gpu='0', hyper_alpha=0.01, hyper_beta=0, hyper_est=True, hyper_gamma=0, hyper_iters=5, hyper_opt='HES', hyper_steps=0, imbalance_ratio=1, log_interval=500, los_model='NONE', lr_cosine=True, lr_decay_epochs='30,55,80', lr_decay_rate=0.1, lr_warm=True, lr_warm_epochs=5, no_cuda=False, noise_ratio=0.0, overfit=False, oversplit=False, plot_debug=False, run_folder='exp4', scale=1, subsample_ratio=1.0, workers=4)
[2022-10-14 21:17:48,277] exp4_main.py->main line:122 [INFO]Namespace(aug_model='SEP', data='./local_data', dataset='med', epochs=200, gpu='1', hyper_alpha=0.01, hyper_beta=0, hyper_est=True, hyper_gamma=0, hyper_iters=5, hyper_opt='HES', hyper_steps=0, imbalance_ratio=1, log_interval=500, los_model='NONE', lr_cosine=True, lr_decay_epochs='30,55,80', lr_decay_rate=0.1, lr_warm=True, lr_warm_epochs=5, no_cuda=False, noise_ratio=0.0, overfit=False, oversplit=False, plot_debug=False, run_folder='exp4', scale=1, subsample_ratio=1.0, workers=4)
[2022-10-14 21:17:55,088] exp4_main.py->main line:183 [INFO]Valid/Train Split: 262/50
[2022-10-14 21:17:55,090] exp4_main.py->main line:236 [INFO]Test/Valid/Train Split: 43/50/262 out of total 287 train images
[2022-10-14 21:17:55,094] exp4_main.py->main line:269 [INFO]Run: ./local_data/med/exp4/UNet_e200_opt_HES_est_True_aug_model_SEP_los_model_NONE_ir_1_sr_1.0_nr_0.0
[2022-10-14 21:17:55,094] exp4_main.py->main line:277 [INFO]0% (0/200)
[2022-10-14 21:17:56,331] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 0, batch_idx: 0, global_img_step: 0
[2022-10-14 21:18:19,434] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 0	 Inner Train loss: 0.7828, acc=0.6952, lr=0.000010	
[2022-10-14 21:18:20,955] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 0	 Test loss: 1.3052, score: 0.4853
[2022-10-14 21:18:20,956] exp4_main.py->main line:299 [INFO]SAVING trained model at epoch 0 with 0.4853 Dice score
[2022-10-14 21:18:21,110] exp4_main.py->main line:277 [INFO]0% (1/200)
[2022-10-14 21:18:21,820] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 1, batch_idx: 0, global_img_step: 1
[2022-10-14 21:18:45,528] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 1	 Inner Train loss: 0.6531, acc=0.7457, lr=0.000010	
[2022-10-14 21:18:47,107] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 1	 Test loss: 0.9131, score: 0.5834
[2022-10-14 21:18:47,108] exp4_main.py->main line:299 [INFO]SAVING trained model at epoch 1 with 0.5834 Dice score
[2022-10-14 21:18:47,509] exp4_main.py->main line:277 [INFO]1% (2/200)
[2022-10-14 21:18:48,212] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 2, batch_idx: 0, global_img_step: 2
[2022-10-14 21:19:12,428] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 2	 Inner Train loss: 0.5332, acc=0.7922, lr=0.000010	
[2022-10-14 21:19:14,024] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 2	 Test loss: 1.4905, score: 0.4900
[2022-10-14 21:19:14,025] exp4_main.py->main line:277 [INFO]2% (3/200)
[2022-10-14 21:19:14,723] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 3, batch_idx: 0, global_img_step: 3
[2022-10-14 21:19:39,522] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 3	 Inner Train loss: 0.5085, acc=0.8085, lr=0.000010	
[2022-10-14 21:19:41,149] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 3	 Test loss: 1.1118, score: 0.6042
[2022-10-14 21:19:41,149] exp4_main.py->main line:299 [INFO]SAVING trained model at epoch 3 with 0.6042 Dice score
[2022-10-14 21:19:41,541] exp4_main.py->main line:277 [INFO]2% (4/200)
[2022-10-14 21:19:42,281] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 4, batch_idx: 0, global_img_step: 4
[2022-10-14 21:20:07,002] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 4	 Inner Train loss: 0.4525, acc=0.8269, lr=0.000010	
[2022-10-14 21:20:08,605] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 4	 Test loss: 1.1962, score: 0.5204
[2022-10-14 21:20:08,605] exp4_main.py->main line:277 [INFO]2% (5/200)
[2022-10-14 21:20:09,298] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 5, batch_idx: 0, global_img_step: 5
[2022-10-14 21:20:33,958] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 5	 Inner Train loss: 0.5144, acc=0.8058, lr=0.000010	
[2022-10-14 21:20:35,589] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 5	 Test loss: 1.2473, score: 0.5470
[2022-10-14 21:20:35,590] exp4_main.py->main line:277 [INFO]3% (6/200)
[2022-10-14 21:20:36,310] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 6, batch_idx: 0, global_img_step: 6
[2022-10-14 21:21:01,016] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 6	 Inner Train loss: 0.4479, acc=0.8303, lr=0.000010	
[2022-10-14 21:21:02,646] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 6	 Test loss: 1.0419, score: 0.5909
[2022-10-14 21:21:02,647] exp4_main.py->main line:277 [INFO]4% (7/200)
[2022-10-14 21:21:03,383] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 7, batch_idx: 0, global_img_step: 7
[2022-10-14 21:21:28,014] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 7	 Inner Train loss: 0.4354, acc=0.8355, lr=0.000010	
[2022-10-14 21:21:29,626] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 7	 Test loss: 1.4009, score: 0.5007
[2022-10-14 21:21:29,626] exp4_main.py->main line:277 [INFO]4% (8/200)
[2022-10-14 21:21:30,337] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 8, batch_idx: 0, global_img_step: 8
[2022-10-14 21:21:55,036] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 8	 Inner Train loss: 0.4367, acc=0.8378, lr=0.000010	
[2022-10-14 21:21:56,655] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 8	 Test loss: 1.6388, score: 0.4818
[2022-10-14 21:21:56,656] exp4_main.py->main line:277 [INFO]4% (9/200)
[2022-10-14 21:21:57,391] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 9, batch_idx: 0, global_img_step: 9
[2022-10-14 21:22:22,030] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 9	 Inner Train loss: 0.3967, acc=0.8464, lr=0.000010	
[2022-10-14 21:22:23,667] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 9	 Test loss: 0.6709, score: 0.7108
[2022-10-14 21:22:23,668] exp4_main.py->main line:299 [INFO]SAVING trained model at epoch 9 with 0.7108 Dice score
[2022-10-14 21:22:24,074] exp4_main.py->main line:277 [INFO]5% (10/200)
[2022-10-14 21:22:24,795] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 10, batch_idx: 0, global_img_step: 10
[2022-10-14 21:22:49,456] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 10	 Inner Train loss: 0.4048, acc=0.8497, lr=0.000010	
[2022-10-14 21:22:51,074] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 10	 Test loss: 0.8716, score: 0.6381
[2022-10-14 21:22:51,075] exp4_main.py->main line:277 [INFO]6% (11/200)
[2022-10-14 21:22:51,919] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 11, batch_idx: 0, global_img_step: 11
[2022-10-14 21:23:16,566] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 11	 Inner Train loss: 0.3851, acc=0.8603, lr=0.000010	
[2022-10-14 21:23:18,184] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 11	 Test loss: 2.1610, score: 0.4254
[2022-10-14 21:23:18,185] exp4_main.py->main line:277 [INFO]6% (12/200)
[2022-10-14 21:23:18,920] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 12, batch_idx: 0, global_img_step: 12
[2022-10-14 21:23:43,508] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 12	 Inner Train loss: 0.3841, acc=0.8541, lr=0.000010	
[2022-10-14 21:23:45,127] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 12	 Test loss: 1.1449, score: 0.5570
[2022-10-14 21:23:45,128] exp4_main.py->main line:277 [INFO]6% (13/200)
[2022-10-14 21:23:45,845] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 13, batch_idx: 0, global_img_step: 13
[2022-10-14 21:24:10,510] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 13	 Inner Train loss: 0.3542, acc=0.8685, lr=0.000010	
[2022-10-14 21:24:12,127] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 13	 Test loss: 1.8642, score: 0.4681
[2022-10-14 21:24:12,128] exp4_main.py->main line:277 [INFO]7% (14/200)
[2022-10-14 21:24:12,861] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 14, batch_idx: 0, global_img_step: 14
[2022-10-14 21:24:37,495] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 14	 Inner Train loss: 0.3716, acc=0.8591, lr=0.000010	
[2022-10-14 21:24:39,107] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 14	 Test loss: 0.6791, score: 0.6935
[2022-10-14 21:24:39,108] exp4_main.py->main line:277 [INFO]8% (15/200)
[2022-10-14 21:24:39,856] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 15, batch_idx: 0, global_img_step: 15
[2022-10-14 21:25:04,563] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 15	 Inner Train loss: 0.3428, acc=0.8712, lr=0.000010	
[2022-10-14 21:25:06,176] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 15	 Test loss: 0.9289, score: 0.6545
[2022-10-14 21:25:06,177] exp4_main.py->main line:277 [INFO]8% (16/200)
[2022-10-14 21:25:06,900] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 16, batch_idx: 0, global_img_step: 16
[2022-10-14 21:25:31,534] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 16	 Inner Train loss: 0.3739, acc=0.8611, lr=0.000010	
[2022-10-14 21:25:33,131] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 16	 Test loss: 1.0099, score: 0.6233
[2022-10-14 21:25:33,132] exp4_main.py->main line:277 [INFO]8% (17/200)
[2022-10-14 21:25:33,838] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 17, batch_idx: 0, global_img_step: 17
[2022-10-14 21:25:58,500] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 17	 Inner Train loss: 0.3387, acc=0.8734, lr=0.000010	
[2022-10-14 21:26:00,149] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 17	 Test loss: 0.9208, score: 0.6025
[2022-10-14 21:26:00,150] exp4_main.py->main line:277 [INFO]9% (18/200)
[2022-10-14 21:26:00,881] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 18, batch_idx: 0, global_img_step: 18
[2022-10-14 21:26:25,479] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 18	 Inner Train loss: 0.3559, acc=0.8715, lr=0.000010	
[2022-10-14 21:26:27,102] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 18	 Test loss: 1.2832, score: 0.5430
[2022-10-14 21:26:27,103] exp4_main.py->main line:277 [INFO]10% (19/200)
[2022-10-14 21:26:27,857] automodels.py->Med_innerTrain line:1025 [INFO]Train epoch: 19, batch_idx: 0, global_img_step: 19
[2022-10-14 21:26:52,566] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 19	 Inner Train loss: 0.2981, acc=0.8907, lr=0.000010	
[2022-10-14 21:26:54,199] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 19	 Test loss: 1.2395, score: 0.5785
[2022-10-14 21:26:54,200] exp4_main.py->main line:277 [INFO]10% (20/200)
[2022-10-14 21:26:54,942] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849,
        -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849])
[2022-10-14 21:26:54,943] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-10-14 21:26:55,099] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 20, batch_idx: 0, global_img_step: 20, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:26:55,099] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.005000	gLtNorm 0.5425 (0.5425)	gLvNorm 0.0254 (0.0254)	mvpNorm 0.3725 (0.3725)

[2022-10-14 21:27:51,929] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 20, batch_idx: 0, global_img_step: 21, aug_ops:[('ShearY', tensor([-0.0198]))]
[2022-10-14 21:28:34,838] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 20	 Inner Train loss: 0.9929, acc=0.6632, lr=0.000010	
[2022-10-14 21:28:36,474] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 20	 Test loss: 2.9195, score: 0.5221
[2022-10-14 21:28:36,475] exp4_main.py->main line:277 [INFO]10% (21/200)
[2022-10-14 21:28:37,174] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.3663, -2.3663, -2.3663, -2.6035, -2.3729, -2.4849, -2.3664, -2.4849,
        -2.4849, -2.3663, -2.3663, -2.6035, -2.3663, -2.3663, -2.6035])
[2022-10-14 21:28:37,176] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-10-14 21:28:37,346] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 21, batch_idx: 0, global_img_step: 22, aug_ops:[('elastic transform', tensor([0.1110]))]
[2022-10-14 21:28:37,346] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.013985	gLtNorm 2.2233 (2.2233)	gLvNorm 1.7939 (1.7939)	mvpNorm 5.9041 (5.9041)

[2022-10-14 21:29:34,316] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 21, batch_idx: 0, global_img_step: 23, aug_ops:[('gaussian blur', tensor([0.3606]))]
[2022-10-14 21:30:17,267] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 21	 Inner Train loss: 0.9102, acc=0.6450, lr=0.000010	
[2022-10-14 21:30:18,882] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 21	 Test loss: 1.9904, score: 0.5499
[2022-10-14 21:30:18,883] exp4_main.py->main line:277 [INFO]11% (22/200)
[2022-10-14 21:30:19,565] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.5589, -2.3660, -2.4364, -2.6032, -2.5689, -2.4849, -2.1874, -2.4849,
        -2.4849, -2.3644, -2.2044, -2.6060, -2.3668, -2.3196, -2.6081])
[2022-10-14 21:30:19,567] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1961,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000])
[2022-10-14 21:30:19,725] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 22, batch_idx: 0, global_img_step: 24, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:30:19,725] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.022969	gLtNorm 1.6688 (1.6688)	gLvNorm 0.4173 (0.4173)	mvpNorm 2.9081 (2.9081)

[2022-10-14 21:31:16,803] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 22, batch_idx: 0, global_img_step: 25, aug_ops:[('brightness', tensor([-0.3971])), ('ShearX', tensor([-0.7330]))]
[2022-10-14 21:31:59,798] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 22	 Inner Train loss: 0.8407, acc=0.6705, lr=0.000010	
[2022-10-14 21:32:01,441] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 22	 Test loss: 1.2200, score: 0.5883
[2022-10-14 21:32:01,442] exp4_main.py->main line:277 [INFO]12% (23/200)
[2022-10-14 21:32:02,124] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.8185, -2.1086, -2.6966, -2.7246, -2.3086, -2.4849, -2.4478, -2.4849,
        -2.4849, -2.1097, -2.4640, -2.6004, -2.3855, -2.3198, -2.8616])
[2022-10-14 21:32:02,126] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2606,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.1961,  0.0000, -0.2606,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:32:02,315] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 23, batch_idx: 0, global_img_step: 26, aug_ops:[('Equalize', tensor([0.4352]))]
[2022-10-14 21:32:02,315] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.031954	gLtNorm 0.4397 (0.4397)	gLvNorm 1.0599 (1.0599)	mvpNorm 2.1732 (2.1732)

[2022-10-14 21:32:59,225] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 23, batch_idx: 0, global_img_step: 27, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:33:42,126] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 23	 Inner Train loss: 0.8593, acc=0.6784, lr=0.000010	
[2022-10-14 21:33:43,734] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 23	 Test loss: 1.3415, score: 0.5951
[2022-10-14 21:33:43,736] exp4_main.py->main line:277 [INFO]12% (24/200)
[2022-10-14 21:33:44,427] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.8189, -2.1044, -2.6959, -3.0001, -1.9568, -2.4849, -2.4793, -2.4849,
        -2.4849, -2.1348, -2.4581, -2.6052, -2.3791, -2.3292, -2.8621])
[2022-10-14 21:33:44,429] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2606,  0.3771,  0.0000,  0.0000,
         0.0000, -0.3771,  0.0000,  0.0000,  0.1961, -0.3771, -0.2606,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:33:44,588] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 24, batch_idx: 0, global_img_step: 28, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:33:44,589] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.040938	gLtNorm 0.6689 (0.6689)	gLvNorm 0.1457 (0.1457)	mvpNorm 0.2216 (0.2216)

[2022-10-14 21:34:41,634] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 24, batch_idx: 0, global_img_step: 29, aug_ops:[('saturation', tensor([-0.1803])), ('gaussian blur', tensor([-0.5487]))]
[2022-10-14 21:35:24,528] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 24	 Inner Train loss: 0.8510, acc=0.6785, lr=0.000010	
[2022-10-14 21:35:26,148] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 24	 Test loss: 1.7624, score: 0.5368
[2022-10-14 21:35:26,150] exp4_main.py->main line:277 [INFO]12% (25/200)
[2022-10-14 21:35:26,829] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.5540, -2.0893, -2.5061, -2.6963, -2.3795, -2.4849, -2.9484, -2.4849,
        -2.4849, -1.6609, -2.9337, -2.7831, -2.5626, -2.7559, -3.3123])
[2022-10-14 21:35:26,831] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2606,  0.3771,  0.0000,  0.0000,
         0.0000, -0.3771,  0.0000,  0.0000,  0.1961, -0.3771, -0.7138,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:35:26,975] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 25, batch_idx: 0, global_img_step: 30, aug_ops:[('TranslateX', tensor([-1.]))]
[2022-10-14 21:35:26,975] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.049905	gLtNorm 0.5887 (0.5887)	gLvNorm 2.7509 (2.7509)	mvpNorm 1.0446 (1.0446)

[2022-10-14 21:36:23,792] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 25, batch_idx: 0, global_img_step: 31, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:37:06,676] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 25	 Inner Train loss: 0.7998, acc=0.6975, lr=0.000010	
[2022-10-14 21:37:08,327] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 25	 Test loss: 1.2333, score: 0.5996
[2022-10-14 21:37:08,328] exp4_main.py->main line:277 [INFO]13% (26/200)
[2022-10-14 21:37:09,016] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.5524, -2.2238, -2.9493, -3.1865, -2.8785, -2.4849, -2.5310, -2.4849,
        -2.4849, -2.1113, -2.9411, -3.2793, -2.0690, -3.2403, -3.3114])
[2022-10-14 21:37:09,018] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2606,  0.3771, -0.4990,  0.0000,
         0.0000, -0.3771,  0.0000,  0.0000,  0.2024, -0.3771, -0.7138,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:37:09,136] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 26, batch_idx: 0, global_img_step: 32, aug_ops:[('contrast', tensor([0.7009]))]
[2022-10-14 21:37:09,136] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.049863	gLtNorm 7.9024 (7.9024)	gLvNorm 0.9553 (0.9553)	mvpNorm 10.2462 (10.2462)

[2022-10-14 21:38:05,951] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 26, batch_idx: 0, global_img_step: 33, aug_ops:[('saturation', tensor([-0.1164]))]
[2022-10-14 21:38:48,787] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 26	 Inner Train loss: 0.8357, acc=0.6810, lr=0.000010	
[2022-10-14 21:38:50,429] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 26	 Test loss: 0.9995, score: 0.6057
[2022-10-14 21:38:50,430] exp4_main.py->main line:277 [INFO]14% (27/200)
[2022-10-14 21:38:51,131] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.4871, -2.7118, -2.7843, -3.2647, -2.7839, -2.4849, -2.0471, -2.4849,
        -2.4849, -1.6132, -2.4458, -2.8869, -1.5716, -2.7423, -2.8355])
[2022-10-14 21:38:51,133] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2606,  0.3771, -0.4990,  0.0000,
         0.0000, -0.3771,  0.0000,  0.0000,  0.2024, -0.3771, -0.7138,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:38:51,304] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 27, batch_idx: 0, global_img_step: 34, aug_ops:[('gaussian noise', tensor([-0.5354]))]
[2022-10-14 21:38:51,305] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.049814	gLtNorm 0.3033 (0.3033)	gLvNorm 1.2074 (1.2074)	mvpNorm 2.4861 (2.4861)

[2022-10-14 21:39:48,193] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 27, batch_idx: 0, global_img_step: 35, aug_ops:[('Hsv', tensor([ 0.4958, -0.5223, -0.2059]))]
[2022-10-14 21:40:31,000] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 27	 Inner Train loss: 0.8063, acc=0.6938, lr=0.000010	
[2022-10-14 21:40:32,614] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 27	 Test loss: 1.5243, score: 0.5893
[2022-10-14 21:40:32,615] exp4_main.py->main line:277 [INFO]14% (28/200)
[2022-10-14 21:40:33,297] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.4260, -2.4185, -2.7967, -3.7172, -2.7229, -2.4849, -2.3839, -2.4849,
        -2.4849, -1.6254, -2.6138, -2.4311, -1.6198, -2.7502, -2.9338])
[2022-10-14 21:40:33,298] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000,  0.0000,  0.0000,  0.2495,  0.3771, -0.4990,  0.0000,
         0.0000, -0.3771,  0.0000,  0.0000,  0.2024, -0.3771, -0.7138,  0.0000,
         0.0000, -0.2606])
[2022-10-14 21:40:33,479] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 28, batch_idx: 0, global_img_step: 36, aug_ops:[('Hsv', tensor([ 0.6094, -0.4498,  0.7168]))]
[2022-10-14 21:40:33,480] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.049757	gLtNorm 0.9971 (0.9971)	gLvNorm 0.0098 (0.0098)	mvpNorm 0.9434 (0.9434)

[2022-10-14 21:41:30,347] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 28, batch_idx: 0, global_img_step: 37, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:42:13,199] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 28	 Inner Train loss: 0.8389, acc=0.6894, lr=0.000010	
[2022-10-14 21:42:14,818] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 28	 Test loss: 1.1062, score: 0.6094
[2022-10-14 21:42:14,819] exp4_main.py->main line:277 [INFO]14% (29/200)
[2022-10-14 21:42:15,496] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.7028, -3.0806, -2.3282, -4.2984, -2.5382, -2.4849, -2.5121, -2.4849,
        -2.4849, -1.6242, -2.4301, -2.4694, -1.5955, -2.7156, -3.1051])
[2022-10-14 21:42:15,498] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000, -0.4969,  0.0000,  0.2495,  0.3771, -0.4990, -0.4969,
         0.4969, -0.3771,  0.0000,  0.0000,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:42:15,624] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 29, batch_idx: 0, global_img_step: 38, aug_ops:[('saturation', tensor([0.1716])), ('elastic transform', tensor([-0.2426]))]
[2022-10-14 21:42:15,624] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000010, hyper_lr=0.049693	gLtNorm 29.1789 (29.1789)	gLvNorm 0.5307 (0.5307)	mvpNorm 24.4197 (24.4197)

[2022-10-14 21:43:12,380] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 29, batch_idx: 0, global_img_step: 39, aug_ops:[('Hsv', tensor([-0.2021,  0.0835, -0.2714]))]
[2022-10-14 21:43:55,247] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 29	 Inner Train loss: 0.7836, acc=0.7034, lr=0.000010	
[2022-10-14 21:43:56,898] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 29	 Test loss: 0.7311, score: 0.6808
[2022-10-14 21:43:56,899] exp4_main.py->main line:277 [INFO]15% (30/200)
[2022-10-14 21:43:57,586] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.7028, -3.0806, -2.3282, -4.2984, -2.5382, -2.4849, -2.5121, -2.4849,
        -2.4849, -1.6242, -2.4301, -2.4694, -1.5955, -2.7156, -3.1051])
[2022-10-14 21:43:57,588] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000, -0.4969,  0.0000,  0.2495,  0.3771, -0.4990, -0.4969,
         0.4969, -0.3771,  0.0000,  0.0000,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:43:57,689] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 30, batch_idx: 0, global_img_step: 40, aug_ops:[('contrast', tensor([0.0346])), ('elastic transform', tensor([-0.0453]))]
[2022-10-14 21:43:57,690] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049621	gLtNorm 0.4455 (0.4455)	gLvNorm 0.3026 (0.3026)	mvpNorm 1.2041 (1.2041)

[2022-10-14 21:44:54,468] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 30, batch_idx: 0, global_img_step: 41, aug_ops:[('Hsv', tensor([ 0.1891, -0.4309,  0.2133]))]
[2022-10-14 21:45:37,503] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 30	 Inner Train loss: 0.7808, acc=0.6960, lr=0.000001	
[2022-10-14 21:45:39,119] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 30	 Test loss: 0.7989, score: 0.6821
[2022-10-14 21:45:39,120] exp4_main.py->main line:277 [INFO]16% (31/200)
[2022-10-14 21:45:39,809] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.2238, -2.5847, -2.3339, -4.3170, -3.0326, -2.4849, -2.7444, -2.4849,
        -2.4849, -1.5225, -1.9883, -2.5163, -2.0133, -2.7153, -3.6001])
[2022-10-14 21:45:39,811] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000, -0.4969,  0.0000,  0.2495,  0.3771, -0.4990, -0.4969,
         0.4969, -0.3771,  0.0000,  0.0000,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:45:40,020] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 31, batch_idx: 0, global_img_step: 42, aug_ops:[('gaussian noise', tensor([0.9234]))]
[2022-10-14 21:45:40,021] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049541	gLtNorm 0.0942 (0.0942)	gLvNorm 0.1491 (0.1491)	mvpNorm 0.1294 (0.1294)

[2022-10-14 21:46:36,935] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 31, batch_idx: 0, global_img_step: 43, aug_ops:[('TranslateX', tensor([0.3532])), ('ShearY', tensor([0.5129]))]
[2022-10-14 21:47:19,730] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 31	 Inner Train loss: 0.7987, acc=0.6915, lr=0.000001	
[2022-10-14 21:47:21,343] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 31	 Test loss: 1.0092, score: 0.6408
[2022-10-14 21:47:21,343] exp4_main.py->main line:277 [INFO]16% (32/200)
[2022-10-14 21:47:22,021] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.5061, -2.4632, -2.3457, -4.2594, -3.0337, -2.4849, -3.2346, -2.9803,
        -2.4849, -1.0380, -2.1037, -2.9577, -1.9803, -2.7291, -3.6112])
[2022-10-14 21:47:22,023] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000, -0.4969,  0.0000,  0.2495,  0.3771, -0.4990, -0.4969,
         0.4969, -0.3771,  0.0000, -0.4954,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:47:22,191] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 32, batch_idx: 0, global_img_step: 44, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:47:22,192] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049454	gLtNorm 0.6881 (0.6881)	gLvNorm 0.3040 (0.3040)	mvpNorm 0.3071 (0.3071)

[2022-10-14 21:48:18,958] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 32, batch_idx: 0, global_img_step: 45, aug_ops:[('Hed', tensor([-0.0548,  0.1064, -0.0599]))]
[2022-10-14 21:49:01,560] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 32	 Inner Train loss: 0.7494, acc=0.7072, lr=0.000001	
[2022-10-14 21:49:03,194] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 32	 Test loss: 1.1733, score: 0.6116
[2022-10-14 21:49:03,194] exp4_main.py->main line:277 [INFO]16% (33/200)
[2022-10-14 21:49:03,876] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.7482, -2.0243, -2.3458, -3.7657, -3.0351, -2.4849, -3.1129, -2.9803,
        -2.4849, -1.0405, -2.1088, -3.2735, -2.4700, -3.1959, -3.6025])
[2022-10-14 21:49:03,878] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.1961,  0.0000, -0.9313,  0.0000,  0.4369,  0.3771, -0.4990, -0.4969,
         0.4969, -0.3771,  0.0000, -0.4954,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:49:04,050] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 33, batch_idx: 0, global_img_step: 46, aug_ops:[('gaussian noise', tensor([-0.2800]))]
[2022-10-14 21:49:04,050] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049360	gLtNorm 0.0502 (0.0502)	gLvNorm 0.2853 (0.2853)	mvpNorm 0.4251 (0.4251)

[2022-10-14 21:50:00,791] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 33, batch_idx: 0, global_img_step: 47, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:50:43,571] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 33	 Inner Train loss: 0.7859, acc=0.7029, lr=0.000001	
[2022-10-14 21:50:45,197] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 33	 Test loss: 1.1697, score: 0.6191
[2022-10-14 21:50:45,198] exp4_main.py->main line:277 [INFO]17% (34/200)
[2022-10-14 21:50:45,886] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.8761, -1.7188, -2.1988, -3.9481, -3.2804, -2.4849, -3.3497, -2.9803,
        -2.4849, -1.0509, -2.0773, -2.7905, -2.4731, -3.2503, -3.2823])
[2022-10-14 21:50:45,888] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897,  0.0000, -1.4243,  0.0000,  0.4369,  0.3771, -0.9926, -0.4969,
         0.9905, -0.3771,  0.0000, -0.4954,  0.2024,  0.1203, -0.7138, -0.4976,
         0.0000, -0.2606])
[2022-10-14 21:50:46,048] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 34, batch_idx: 0, global_img_step: 48, aug_ops:[('elastic transform', tensor([-1.]))]
[2022-10-14 21:50:46,049] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049258	gLtNorm 6.4825 (6.4825)	gLvNorm 0.2562 (0.2562)	mvpNorm 6.9831 (6.9831)

[2022-10-14 21:51:42,711] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 34, batch_idx: 0, global_img_step: 49, aug_ops:[('Hed', tensor([ 0.3708,  0.1255, -0.3258]))]
[2022-10-14 21:52:25,481] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 34	 Inner Train loss: 0.7776, acc=0.7034, lr=0.000001	
[2022-10-14 21:52:27,095] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 34	 Test loss: 1.0933, score: 0.6220
[2022-10-14 21:52:27,096] exp4_main.py->main line:277 [INFO]18% (35/200)
[2022-10-14 21:52:27,788] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.0336, -1.7239, -1.7815, -4.2310, -3.7708, -2.4849, -3.5837, -2.9803,
        -2.4849, -0.9003, -2.1582, -2.7853, -2.6591, -3.2068, -3.2750])
[2022-10-14 21:52:27,790] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.9905, -0.3771,  0.0000, -0.4954,  0.2024,  0.1203, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 21:52:27,939] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 35, batch_idx: 0, global_img_step: 50, aug_ops:[('idenity', [1.0])]
[2022-10-14 21:52:27,939] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049149	gLtNorm 0.1148 (0.1148)	gLvNorm 0.2377 (0.2377)	mvpNorm 0.0558 (0.0558)

[2022-10-14 21:53:24,723] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 35, batch_idx: 0, global_img_step: 51, aug_ops:[('Hed', tensor([-0.4916,  0.2422, -0.9059])), ('ShearY', tensor([-0.2745]))]
[2022-10-14 21:54:07,476] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 35	 Inner Train loss: 0.7377, acc=0.7140, lr=0.000001	
[2022-10-14 21:54:09,120] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 35	 Test loss: 1.2081, score: 0.6101
[2022-10-14 21:54:09,121] exp4_main.py->main line:277 [INFO]18% (36/200)
[2022-10-14 21:54:09,811] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.2188, -2.0735, -2.2250, -4.1521, -3.7758, -2.4849, -3.8208, -2.9803,
        -2.4849, -1.3892, -1.6668, -2.2989, -2.1681, -3.0847, -2.7993])
[2022-10-14 21:54:09,813] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.9928, -0.3771, -0.4915, -0.4954,  0.2024,  0.1203, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 21:54:09,968] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 36, batch_idx: 0, global_img_step: 52, aug_ops:[('brightness', tensor([0.0525])), ('ShearY', tensor([0.1073]))]
[2022-10-14 21:54:09,968] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.049033	gLtNorm 11.7619 (11.7619)	gLvNorm 0.7048 (0.7048)	mvpNorm 16.3818 (16.3818)

[2022-10-14 21:55:06,610] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 36, batch_idx: 0, global_img_step: 53, aug_ops:[('contrast', tensor([0.9384]))]
[2022-10-14 21:55:49,415] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 36	 Inner Train loss: 0.7703, acc=0.7020, lr=0.000001	
[2022-10-14 21:55:51,059] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 36	 Test loss: 0.9970, score: 0.6436
[2022-10-14 21:55:51,060] exp4_main.py->main line:277 [INFO]18% (37/200)
[2022-10-14 21:55:51,749] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.7293, -1.9893, -2.0586, -4.2435, -3.7771, -2.4849, -3.8654, -2.9803,
        -2.4849, -1.5445, -1.6695, -2.0705, -2.2155, -3.5717, -2.8012])
[2022-10-14 21:55:51,751] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.9928, -0.3771, -0.4915, -0.9857,  0.2024,  0.1203, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 21:55:51,898] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 37, batch_idx: 0, global_img_step: 54, aug_ops:[('brightness', tensor([-0.3169])), ('contrast', tensor([0.0018]))]
[2022-10-14 21:55:51,898] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048909	gLtNorm 0.1907 (0.1907)	gLvNorm 0.7492 (0.7492)	mvpNorm 0.6840 (0.6840)

[2022-10-14 21:56:48,497] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 37, batch_idx: 0, global_img_step: 55, aug_ops:[('Hed', tensor([-0.0065,  0.2202, -0.4796])), ('Rotate', tensor([0.1285]))]
[2022-10-14 21:57:31,295] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 37	 Inner Train loss: 0.7006, acc=0.7278, lr=0.000001	
[2022-10-14 21:57:32,920] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 37	 Test loss: 1.0330, score: 0.6424
[2022-10-14 21:57:32,921] exp4_main.py->main line:277 [INFO]19% (38/200)
[2022-10-14 21:57:33,606] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.1956, -1.8364, -2.5410, -3.7554, -3.9238, -2.4849, -3.9422, -2.9803,
        -2.4849, -2.0301, -2.1579, -1.6422, -2.4114, -3.1525, -3.0029])
[2022-10-14 21:57:33,608] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.9928, -0.3771, -0.4915, -0.9857,  0.2024,  0.1203, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 21:57:33,816] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 38, batch_idx: 0, global_img_step: 56, aug_ops:[('sharpen', tensor([-0.0343])), ('elastic transform', tensor([0.2261]))]
[2022-10-14 21:57:33,816] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048778	gLtNorm 0.2713 (0.2713)	gLvNorm 0.1542 (0.1542)	mvpNorm 0.1136 (0.1136)

[2022-10-14 21:58:30,496] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 38, batch_idx: 0, global_img_step: 57, aug_ops:[('Hed', tensor([0.2577, 0.4055, 1.0000])), ('sharpen', tensor([-0.3140])), ('elastic transform', tensor([0.2513])), ('TranslateY', tensor([0.7748])), ('Equalize', tensor([0.5476]))]
[2022-10-14 21:59:13,278] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 38	 Inner Train loss: 0.7380, acc=0.7187, lr=0.000001	
[2022-10-14 21:59:14,904] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 38	 Test loss: 0.9543, score: 0.6463
[2022-10-14 21:59:14,905] exp4_main.py->main line:277 [INFO]20% (39/200)
[2022-10-14 21:59:15,590] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.7717, -1.6254, -2.9274, -3.7192, -3.7343, -2.4849, -3.4546, -2.9803,
        -2.4849, -1.5747, -2.0213, -1.4129, -2.1144, -3.1373, -3.3816])
[2022-10-14 21:59:15,593] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-0.6897, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024,  0.1203, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 21:59:15,730] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 39, batch_idx: 0, global_img_step: 58, aug_ops:[('brightness', tensor([0.8403])), ('saturation', tensor([-0.3080])), ('TranslateX', tensor([0.4565]))]
[2022-10-14 21:59:15,731] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048639	gLtNorm 2.8529 (2.8529)	gLvNorm 0.5740 (0.5740)	mvpNorm 5.4677 (5.4677)

[2022-10-14 22:00:12,592] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 39, batch_idx: 0, global_img_step: 59, aug_ops:[('TranslateX', tensor([0.3572]))]
[2022-10-14 22:00:55,422] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 39	 Inner Train loss: 0.7242, acc=0.7185, lr=0.000001	
[2022-10-14 22:00:57,023] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 39	 Test loss: 1.1804, score: 0.6225
[2022-10-14 22:00:57,024] exp4_main.py->main line:277 [INFO]20% (40/200)
[2022-10-14 22:00:57,707] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.0760, -1.1497, -3.4051, -3.9879, -3.6978, -2.4849, -3.1621, -2.9803,
        -2.4849, -1.0972, -1.5940, -1.8285, -1.6510, -2.6510, -3.6003])
[2022-10-14 22:00:57,709] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.4926, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.3661, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 22:00:57,808] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 40, batch_idx: 0, global_img_step: 60, aug_ops:[('Hsv', tensor([-0.2059, -0.1736, -0.4365])), ('Hed', tensor([-0.4510, -1.0000, -0.3761]))]
[2022-10-14 22:00:57,809] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048494	gLtNorm 9.6727 (9.6727)	gLvNorm 0.4081 (0.4081)	mvpNorm 13.4625 (13.4625)

[2022-10-14 22:01:54,688] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 40, batch_idx: 0, global_img_step: 61, aug_ops:[('sharpen', tensor([0.3789]))]
[2022-10-14 22:02:37,422] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 40	 Inner Train loss: 0.7537, acc=0.7190, lr=0.000001	
[2022-10-14 22:02:39,072] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 40	 Test loss: 1.0206, score: 0.6358
[2022-10-14 22:02:39,073] exp4_main.py->main line:277 [INFO]20% (41/200)
[2022-10-14 22:02:39,748] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.1635, -1.0987, -3.4799, -3.7989, -4.1611, -2.4849, -3.6447, -2.9803,
        -2.4849, -1.0641, -1.6010, -1.8695, -1.7492, -2.6395, -3.6718])
[2022-10-14 22:02:39,750] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9770, -1.4243,  0.0000, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.3661, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 22:02:39,887] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 41, batch_idx: 0, global_img_step: 62, aug_ops:[('elastic transform', tensor([0.8009])), ('TranslateX', tensor([0.4465]))]
[2022-10-14 22:02:39,887] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048341	gLtNorm 0.2548 (0.2548)	gLvNorm 0.1162 (0.1162)	mvpNorm 0.4910 (0.4910)

[2022-10-14 22:03:36,376] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 41, batch_idx: 0, global_img_step: 63, aug_ops:[('contrast', tensor([0.0310]))]
[2022-10-14 22:04:19,171] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 41	 Inner Train loss: 0.7297, acc=0.7183, lr=0.000001	
[2022-10-14 22:04:20,786] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 41	 Test loss: 0.9877, score: 0.6481
[2022-10-14 22:04:20,787] exp4_main.py->main line:277 [INFO]21% (42/200)
[2022-10-14 22:04:21,471] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.4597, -1.0729, -3.4965, -3.7338, -4.1662, -2.4849, -3.6450, -2.9803,
        -2.4849, -1.0265, -1.7764, -2.3240, -1.8202, -2.7377, -4.1489])
[2022-10-14 22:04:21,473] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9770, -1.4243,  0.4834, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.3661, -0.7138, -0.4976,
        -0.4926, -0.2606])
[2022-10-14 22:04:21,597] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 42, batch_idx: 0, global_img_step: 64, aug_ops:[('contrast', tensor([0.2318])), ('gaussian noise', tensor([-0.2084])), ('ShearX', tensor([0.5385]))]
[2022-10-14 22:04:21,597] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048181	gLtNorm 8.8736 (8.8736)	gLvNorm 0.1095 (0.1095)	mvpNorm 8.8938 (8.8938)

[2022-10-14 22:05:18,332] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 42, batch_idx: 0, global_img_step: 65, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:06:01,006] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 42	 Inner Train loss: 0.7511, acc=0.7160, lr=0.000001	
[2022-10-14 22:06:02,623] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 42	 Test loss: 0.9706, score: 0.6546
[2022-10-14 22:06:02,624] exp4_main.py->main line:277 [INFO]22% (43/200)
[2022-10-14 22:06:03,313] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.9386, -0.5925, -3.5362, -3.9128, -4.1433, -2.4849, -3.7888, -2.9803,
        -2.4849, -0.7853, -1.7529, -2.8027, -1.7792, -2.7363, -4.2546])
[2022-10-14 22:06:03,315] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9770, -1.4243,  0.4834, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.3661, -0.7138, -0.4976,
        -0.0115, -0.2606])
[2022-10-14 22:06:03,464] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 43, batch_idx: 0, global_img_step: 66, aug_ops:[('TranslateX', tensor([0.0511])), ('Equalize', tensor([0.7104]))]
[2022-10-14 22:06:03,464] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.048015	gLtNorm 0.9642 (0.9642)	gLvNorm 0.1216 (0.1216)	mvpNorm 1.6259 (1.6259)

[2022-10-14 22:07:00,103] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 43, batch_idx: 0, global_img_step: 67, aug_ops:[('brightness', tensor([-0.0123])), ('contrast', tensor([-0.3724])), ('ShearX', tensor([0.1286]))]
[2022-10-14 22:07:42,734] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 43	 Inner Train loss: 0.7143, acc=0.7244, lr=0.000001	
[2022-10-14 22:07:44,348] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 43	 Test loss: 0.9864, score: 0.6377
[2022-10-14 22:07:44,349] exp4_main.py->main line:277 [INFO]22% (44/200)
[2022-10-14 22:07:45,033] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.9261, -0.5703, -3.9492, -3.4348, -4.6234, -2.4849, -3.9192, -2.9803,
        -2.4849, -0.3767, -1.2974, -2.7940, -1.3029, -2.7009, -4.2546])
[2022-10-14 22:07:45,035] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.4970, -1.4243,  0.4834, -0.0556,  0.3771, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.8457, -0.7138, -0.4976,
        -0.0115, -0.2606])
[2022-10-14 22:07:45,200] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 44, batch_idx: 0, global_img_step: 68, aug_ops:[('ShearX', tensor([0.8104]))]
[2022-10-14 22:07:45,200] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.047841	gLtNorm 0.2693 (0.2693)	gLvNorm 0.0865 (0.0865)	mvpNorm 0.2674 (0.2674)

[2022-10-14 22:08:41,956] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 44, batch_idx: 0, global_img_step: 69, aug_ops:[('Rotate', tensor([-1.]))]
[2022-10-14 22:09:24,558] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 44	 Inner Train loss: 0.7065, acc=0.7323, lr=0.000001	
[2022-10-14 22:09:26,184] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 44	 Test loss: 1.0640, score: 0.6379
[2022-10-14 22:09:26,185] exp4_main.py->main line:277 [INFO]22% (45/200)
[2022-10-14 22:09:26,880] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-4.1152, -1.0469, -4.3149, -3.0046, -4.2997, -2.4849, -3.8735, -2.9803,
        -2.4849,  0.0828, -1.7442, -2.6080, -0.9171, -2.2256, -3.7765])
[2022-10-14 22:09:26,882] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.4970, -1.4243,  0.4834, -0.0556, -0.1013, -0.9926, -0.4969,
         0.5057, -0.3771, -0.4915, -0.9857,  0.2024, -0.8457, -0.7138, -0.4976,
        -0.0115, -0.2606])
[2022-10-14 22:09:27,027] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 45, batch_idx: 0, global_img_step: 70, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:09:27,027] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.047660	gLtNorm 0.0777 (0.0777)	gLvNorm 0.1749 (0.1749)	mvpNorm 0.0533 (0.0533)

[2022-10-14 22:10:23,681] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 45, batch_idx: 0, global_img_step: 71, aug_ops:[('elastic transform', tensor([0.0015])), ('Rotate', tensor([-0.1468]))]
[2022-10-14 22:11:06,339] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 45	 Inner Train loss: 0.6902, acc=0.7332, lr=0.000001	
[2022-10-14 22:11:07,945] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 45	 Test loss: 0.9096, score: 0.6704
[2022-10-14 22:11:07,946] exp4_main.py->main line:277 [INFO]23% (46/200)
[2022-10-14 22:11:08,631] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-4.2268, -0.7252, -4.7777, -2.6602, -4.3507, -2.4849, -4.0317, -2.9803,
        -2.4849,  0.0757, -1.7439, -2.6089, -0.9233, -2.2268, -3.8597])
[2022-10-14 22:11:08,633] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.4970, -1.4243,  0.4834, -0.0556, -0.1013, -0.9926, -0.4969,
         0.5057, -0.8537, -0.4915, -0.9857,  0.2024, -1.0575, -0.7138, -0.4976,
        -0.0115, -0.2606])
[2022-10-14 22:11:08,887] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 46, batch_idx: 0, global_img_step: 72, aug_ops:[('brightness', tensor([-0.2610])), ('Hsv', tensor([-0.8407,  0.0047,  0.4665])), ('elastic transform', tensor([-0.0988])), ('Rotate', tensor([1.])), ('TranslateY', tensor([-0.0862])), ('ShearX', tensor([0.2049]))]
[2022-10-14 22:11:08,887] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.047472	gLtNorm 3.2538 (3.2538)	gLvNorm 0.3036 (0.3036)	mvpNorm 5.2831 (5.2831)

[2022-10-14 22:12:05,610] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 46, batch_idx: 0, global_img_step: 73, aug_ops:[('brightness', tensor([-0.0083])), ('Hsv', tensor([-0.3831,  1.0000, -0.0817])), ('Hed', tensor([0.1636, 0.1086, 0.1272]))]
[2022-10-14 22:12:48,262] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 46	 Inner Train loss: 0.7256, acc=0.7271, lr=0.000001	
[2022-10-14 22:12:49,893] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 46	 Test loss: 0.9403, score: 0.6531
[2022-10-14 22:12:49,894] exp4_main.py->main line:277 [INFO]24% (47/200)
[2022-10-14 22:12:50,578] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-4.2213, -0.7089, -4.7795, -2.6265, -4.2745, -2.4849, -4.1409, -2.9803,
        -2.4849,  0.0803, -1.6955, -2.6098, -0.9191, -2.2268, -3.8592])
[2022-10-14 22:12:50,579] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.4970, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.8537, -0.4915, -0.9857,  0.2024, -1.0575, -0.2390, -0.0229,
        -0.0115, -0.2606])
[2022-10-14 22:12:50,694] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 47, batch_idx: 0, global_img_step: 74, aug_ops:[('contrast', tensor([0.3464])), ('Rotate', tensor([-0.7231])), ('ShearX', tensor([-0.7749]))]
[2022-10-14 22:12:50,694] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.047278	gLtNorm 3.8753 (3.8753)	gLvNorm 0.0850 (0.0850)	mvpNorm 4.5519 (4.5519)

[2022-10-14 22:13:47,324] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 47, batch_idx: 0, global_img_step: 75, aug_ops:[('gaussian blur', tensor([-0.1018])), ('Rotate', tensor([0.3291])), ('TranslateY', tensor([-0.0130]))]
[2022-10-14 22:14:30,046] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 47	 Inner Train loss: 0.6593, acc=0.7483, lr=0.000001	
[2022-10-14 22:14:31,681] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 47	 Test loss: 0.9542, score: 0.6623
[2022-10-14 22:14:31,683] exp4_main.py->main line:277 [INFO]24% (48/200)
[2022-10-14 22:14:32,369] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.8525, -0.6550, -5.2501, -2.1593, -4.2435, -2.4849, -4.1269, -2.9803,
        -2.4849,  0.0183, -1.6967, -2.6145, -0.9030, -2.2436, -3.9049])
[2022-10-14 22:14:32,370] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9698, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.8727, -0.4915, -0.9857, -0.2704, -1.4040, -0.2390, -0.0229,
        -0.0115, -0.2606])
[2022-10-14 22:14:32,492] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 48, batch_idx: 0, global_img_step: 76, aug_ops:[('Hsv', tensor([-0.3105, -0.0037, -0.3708])), ('gaussian noise', tensor([-0.4075])), ('Rotate', tensor([-0.0548])), ('TranslateY', tensor([1.])), ('ShearX', tensor([-0.6900]))]
[2022-10-14 22:14:32,492] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.047077	gLtNorm 0.6568 (0.6568)	gLvNorm 0.1674 (0.1674)	mvpNorm 1.3050 (1.3050)

[2022-10-14 22:15:29,255] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 48, batch_idx: 0, global_img_step: 77, aug_ops:[('Hed', tensor([0.1993, 0.3849, 0.2503])), ('ShearX', tensor([0.5400]))]
[2022-10-14 22:16:11,859] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 48	 Inner Train loss: 0.7260, acc=0.7325, lr=0.000001	
[2022-10-14 22:16:13,471] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 48	 Test loss: 1.0434, score: 0.6418
[2022-10-14 22:16:13,472] exp4_main.py->main line:277 [INFO]24% (49/200)
[2022-10-14 22:16:14,151] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.3823, -0.2157, -5.4153, -1.7228, -4.2667, -2.4849, -3.6562, -2.9803,
        -2.4849, -0.3163, -2.1283, -2.1520, -1.2932, -2.1394, -3.8619])
[2022-10-14 22:16:14,153] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9698, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.8727, -0.4915, -0.9857, -0.2704, -1.4040,  0.2317, -0.0229,
        -0.0115, -0.2606])
[2022-10-14 22:16:14,306] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 49, batch_idx: 0, global_img_step: 78, aug_ops:[('saturation', tensor([-0.7543])), ('gaussian blur', tensor([0.0797])), ('sharpen', tensor([-0.2851])), ('ShearX', tensor([0.0858])), ('Equalize', tensor([-0.2343]))]
[2022-10-14 22:16:14,306] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.046869	gLtNorm 0.1496 (0.1496)	gLvNorm 0.2932 (0.2932)	mvpNorm 0.4696 (0.4696)

[2022-10-14 22:17:10,989] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 49, batch_idx: 0, global_img_step: 79, aug_ops:[('brightness', tensor([0.1846])), ('ShearX', tensor([0.1804]))]
[2022-10-14 22:17:53,600] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 49	 Inner Train loss: 0.7611, acc=0.7137, lr=0.000001	
[2022-10-14 22:17:55,219] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 49	 Test loss: 1.0640, score: 0.6325
[2022-10-14 22:17:55,220] exp4_main.py->main line:277 [INFO]25% (50/200)
[2022-10-14 22:17:55,908] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-3.2969, -0.6779, -5.4050, -2.1293, -4.2551, -2.4849, -3.8454, -2.9803,
        -2.4849, -0.3414, -2.1112, -2.1589, -1.2986, -2.1887, -3.6236])
[2022-10-14 22:17:55,910] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9698, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.4915, -0.9857, -0.2704, -1.8646,  0.2317,  0.4451,
        -0.0115, -0.2606])
[2022-10-14 22:17:56,105] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 50, batch_idx: 0, global_img_step: 80, aug_ops:[('contrast', tensor([-0.3349])), ('Equalize', tensor([0.4410]))]
[2022-10-14 22:17:56,105] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.046654	gLtNorm 0.7012 (0.7012)	gLvNorm 0.1708 (0.1708)	mvpNorm 0.3528 (0.3528)

[2022-10-14 22:18:52,702] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 50, batch_idx: 0, global_img_step: 81, aug_ops:[('Hsv', tensor([-1.0000, -0.3336,  0.3135])), ('Hed', tensor([ 0.8194,  0.0126, -0.2860])), ('gaussian noise', tensor([-0.0448]))]
[2022-10-14 22:19:35,461] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 50	 Inner Train loss: 0.6992, acc=0.7377, lr=0.000001	
[2022-10-14 22:19:37,069] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 50	 Test loss: 1.1094, score: 0.6322
[2022-10-14 22:19:37,070] exp4_main.py->main line:277 [INFO]26% (51/200)
[2022-10-14 22:19:37,741] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.8359, -0.2164, -5.7978, -2.0032, -4.3912, -2.4849, -3.4719, -2.9803,
        -2.4849,  0.1243, -1.6447, -2.6237, -0.8321, -2.6523, -3.8116])
[2022-10-14 22:19:37,743] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9698, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.4915, -0.9857, -0.2704, -1.8646,  0.2317,  0.4451,
        -0.0115, -0.2606])
[2022-10-14 22:19:37,900] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 51, batch_idx: 0, global_img_step: 82, aug_ops:[('Equalize', tensor([-0.2841]))]
[2022-10-14 22:19:37,901] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.046433	gLtNorm 0.3915 (0.3915)	gLvNorm 0.2812 (0.2812)	mvpNorm 0.3327 (0.3327)

[2022-10-14 22:20:34,545] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 51, batch_idx: 0, global_img_step: 83, aug_ops:[('Hed', tensor([0.3727, 0.7198, 0.5994])), ('elastic transform', tensor([0.1800])), ('Equalize', tensor([0.3947]))]
[2022-10-14 22:21:17,180] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 51	 Inner Train loss: 0.7407, acc=0.7225, lr=0.000001	
[2022-10-14 22:21:18,775] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 51	 Test loss: 0.9611, score: 0.6540
[2022-10-14 22:21:18,776] exp4_main.py->main line:277 [INFO]26% (52/200)
[2022-10-14 22:21:19,452] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.3814, -0.0699, -6.1876, -1.5398, -3.9480, -2.4849, -3.7588, -2.9803,
        -2.4849,  0.1733, -1.6391, -2.5197, -0.8221, -2.5633, -4.2532])
[2022-10-14 22:21:19,453] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -0.9698, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -1.8646,  0.2317,  0.4451,
        -0.4759, -0.2606])
[2022-10-14 22:21:19,651] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 52, batch_idx: 0, global_img_step: 84, aug_ops:[('saturation', tensor([0.1027])), ('gaussian noise', tensor([-0.0627])), ('Equalize', tensor([-0.4789]))]
[2022-10-14 22:21:19,651] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.046205	gLtNorm 0.2390 (0.2390)	gLvNorm 0.1254 (0.1254)	mvpNorm 0.1996 (0.1996)

[2022-10-14 22:22:16,107] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 52, batch_idx: 0, global_img_step: 85, aug_ops:[('saturation', tensor([0.6407])), ('elastic transform', tensor([-0.7205])), ('ShearY', tensor([-0.2152]))]
[2022-10-14 22:22:58,753] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 52	 Inner Train loss: 0.7594, acc=0.7182, lr=0.000001	
[2022-10-14 22:23:00,373] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 52	 Test loss: 1.1009, score: 0.6375
[2022-10-14 22:23:00,374] exp4_main.py->main line:277 [INFO]26% (53/200)
[2022-10-14 22:23:01,068] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.4195, -0.0685, -6.2015, -1.4845, -3.9945, -2.4849, -3.7596, -2.9803,
        -2.4849,  0.1559, -1.6407, -2.5323, -0.8161, -2.7822, -4.2740])
[2022-10-14 22:23:01,070] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4064, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -1.8646,  0.2317,  0.4451,
        -0.4759, -0.2606])
[2022-10-14 22:23:01,223] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 53, batch_idx: 0, global_img_step: 86, aug_ops:[('gaussian noise', tensor([0.9342])), ('ShearX', tensor([0.6676]))]
[2022-10-14 22:23:01,224] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.045971	gLtNorm 0.6184 (0.6184)	gLvNorm 0.2449 (0.2449)	mvpNorm 0.1674 (0.1674)

[2022-10-14 22:23:57,862] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 53, batch_idx: 0, global_img_step: 87, aug_ops:[('contrast', tensor([-0.4500])), ('sharpen', tensor([-0.1906])), ('gaussian noise', tensor([-1.])), ('TranslateX', tensor([0.1992]))]
[2022-10-14 22:24:40,541] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 53	 Inner Train loss: 0.7113, acc=0.7326, lr=0.000001	
[2022-10-14 22:24:42,151] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 53	 Test loss: 1.1639, score: 0.6296
[2022-10-14 22:24:42,152] exp4_main.py->main line:277 [INFO]27% (54/200)
[2022-10-14 22:24:42,839] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.6850, -0.0665, -6.4092, -1.0282, -4.4487, -2.4849, -3.4246, -2.9803,
        -2.4849,  0.1700, -1.2016, -2.3352, -0.4515, -2.8094, -3.8211])
[2022-10-14 22:24:42,841] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4064, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.3243,  0.6914,  0.4451,
        -0.4759, -0.2606])
[2022-10-14 22:24:43,033] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 54, batch_idx: 0, global_img_step: 88, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:24:43,033] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000001, hyper_lr=0.045730	gLtNorm 2.9637 (2.9637)	gLvNorm 0.1509 (0.1509)	mvpNorm 3.6038 (3.6038)

[2022-10-14 22:25:39,483] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 54, batch_idx: 0, global_img_step: 89, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:26:22,101] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 54	 Inner Train loss: 0.6946, acc=0.7315, lr=0.000001	
[2022-10-14 22:26:23,727] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 54	 Test loss: 1.1602, score: 0.6212
[2022-10-14 22:26:23,728] exp4_main.py->main line:277 [INFO]28% (55/200)
[2022-10-14 22:26:24,407] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.6796,  0.3174, -6.4230, -1.0324, -4.3352, -2.4849, -3.8635, -2.9803,
        -2.4849,  0.5961, -1.1999, -2.3504, -0.4381, -2.7835, -3.6657])
[2022-10-14 22:26:24,409] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4064, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.3243,  0.6881,  0.4451,
        -0.0249, -0.2606])
[2022-10-14 22:26:24,513] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 55, batch_idx: 0, global_img_step: 90, aug_ops:[('contrast', tensor([-0.2813])), ('ShearX', tensor([-0.8275]))]
[2022-10-14 22:26:24,514] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.045483	gLtNorm 2.0937 (2.0937)	gLvNorm 0.3866 (0.3866)	mvpNorm 0.7588 (0.7588)

[2022-10-14 22:27:21,133] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 55, batch_idx: 0, global_img_step: 91, aug_ops:[('sharpen', tensor([-0.0261])), ('TranslateY', tensor([-0.2539])), ('ShearY', tensor([0.1379]))]
[2022-10-14 22:28:03,750] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 55	 Inner Train loss: 0.7349, acc=0.7248, lr=0.000000	
[2022-10-14 22:28:05,380] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 55	 Test loss: 1.0257, score: 0.6632
[2022-10-14 22:28:05,381] exp4_main.py->main line:277 [INFO]28% (56/200)
[2022-10-14 22:28:06,071] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.4261,  0.7714, -6.8257, -0.6539, -4.7901, -2.4849, -4.3166, -2.9803,
        -2.4849,  0.4899, -1.2737, -1.9404, -0.5103, -2.9444, -4.1202])
[2022-10-14 22:28:06,072] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4064, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.3894,  0.6205,  0.4451,
        -0.0249, -0.2606])
[2022-10-14 22:28:06,191] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 56, batch_idx: 0, global_img_step: 92, aug_ops:[('Hed', tensor([-0.0422,  0.6088,  0.1477]))]
[2022-10-14 22:28:06,191] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.045230	gLtNorm 1.7782 (1.7782)	gLvNorm 5.6156 (5.6156)	mvpNorm 5.5852 (5.5852)

[2022-10-14 22:29:02,760] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 56, batch_idx: 0, global_img_step: 93, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:29:45,386] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 56	 Inner Train loss: 0.7398, acc=0.7247, lr=0.000000	
[2022-10-14 22:29:47,006] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 56	 Test loss: 0.9064, score: 0.6685
[2022-10-14 22:29:47,007] exp4_main.py->main line:277 [INFO]28% (57/200)
[2022-10-14 22:29:47,692] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.9819,  0.7724, -7.2006, -0.6302, -4.8427, -2.4849, -4.0624, -2.9803,
        -2.4849,  0.3990, -1.2724, -1.8854, -0.5561, -2.9806, -4.1245])
[2022-10-14 22:29:47,694] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.8587, -1.4243,  0.4834, -0.0556,  0.2854, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.3894,  0.6205,  0.4451,
        -0.4749, -0.7129])
[2022-10-14 22:29:47,790] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 57, batch_idx: 0, global_img_step: 94, aug_ops:[('brightness', tensor([0.0288])), ('Hed', tensor([-0.1877, -1.0000, -0.3818])), ('TranslateY', tensor([0.1922])), ('ShearX', tensor([0.1926]))]
[2022-10-14 22:29:47,790] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.044971	gLtNorm 45.2892 (45.2892)	gLvNorm 0.1345 (0.1345)	mvpNorm 47.6020 (47.6020)

[2022-10-14 22:30:44,327] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 57, batch_idx: 0, global_img_step: 95, aug_ops:[('gaussian blur', tensor([0.5503])), ('gaussian noise', tensor([0.6387]))]
[2022-10-14 22:31:26,929] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 57	 Inner Train loss: 0.7006, acc=0.7370, lr=0.000000	
[2022-10-14 22:31:28,582] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 57	 Test loss: 1.0168, score: 0.6435
[2022-10-14 22:31:28,584] exp4_main.py->main line:277 [INFO]29% (58/200)
[2022-10-14 22:31:29,280] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.9819,  0.7724, -7.2006, -0.6996, -4.8427, -2.4849, -4.0638, -2.9803,
        -2.4849,  0.3990, -1.2724, -1.8854, -0.5561, -2.9806, -4.1245])
[2022-10-14 22:31:29,282] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.8587, -1.4243,  0.4834, -0.0556, -0.1643, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.3894,  0.6205,  0.4451,
        -0.4749, -0.7129])
[2022-10-14 22:31:29,437] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 58, batch_idx: 0, global_img_step: 96, aug_ops:[('saturation', tensor([-0.3109])), ('Equalize', tensor([-0.1379]))]
[2022-10-14 22:31:29,437] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.044706	gLtNorm 5.1635 (5.1635)	gLvNorm 2.6962 (2.6962)	mvpNorm 7.9205 (7.9205)

[2022-10-14 22:32:25,965] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 58, batch_idx: 0, global_img_step: 97, aug_ops:[('brightness', tensor([-0.1029]))]
[2022-10-14 22:33:08,565] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 58	 Inner Train loss: 0.7447, acc=0.7275, lr=0.000000	
[2022-10-14 22:33:10,199] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 58	 Test loss: 0.9449, score: 0.6567
[2022-10-14 22:33:10,200] exp4_main.py->main line:277 [INFO]30% (59/200)
[2022-10-14 22:33:10,891] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.6992,  0.7890, -7.2302, -0.6061, -4.3984, -2.4849, -4.4958, -2.9803,
        -2.4849,  0.2326, -1.1331, -1.4405, -0.1667, -2.5417, -4.2425])
[2022-10-14 22:33:10,893] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.6341, -1.4243,  0.4834, -0.0556, -0.5237, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.0071,  0.6205,  0.4451,
        -0.4749, -0.7129])
[2022-10-14 22:33:11,092] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 59, batch_idx: 0, global_img_step: 98, aug_ops:[('gaussian noise', tensor([-0.0325])), ('Equalize', tensor([0.1424]))]
[2022-10-14 22:33:11,093] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.044434	gLtNorm 0.4237 (0.4237)	gLvNorm 0.1779 (0.1779)	mvpNorm 0.7056 (0.7056)

[2022-10-14 22:34:07,824] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 59, batch_idx: 0, global_img_step: 99, aug_ops:[('saturation', tensor([-0.0314])), ('gaussian noise', tensor([-0.1673])), ('ShearX', tensor([0.2650]))]
[2022-10-14 22:34:50,507] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 59	 Inner Train loss: 0.7454, acc=0.7217, lr=0.000000	
[2022-10-14 22:34:52,166] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 59	 Test loss: 0.9895, score: 0.6569
[2022-10-14 22:34:52,168] exp4_main.py->main line:277 [INFO]30% (60/200)
[2022-10-14 22:34:52,863] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.1434,  1.2286, -7.6357, -1.0503, -4.4921, -2.4849, -4.4690, -2.9803,
        -2.4849, -0.2115, -1.5748, -0.9965, -0.6095, -2.9860, -4.6807])
[2022-10-14 22:34:52,865] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.6341, -1.4243,  0.4834, -0.0556, -0.5237, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.0071,  0.6205,  0.4451,
        -0.4749, -0.7129])
[2022-10-14 22:34:53,016] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 60, batch_idx: 0, global_img_step: 100, aug_ops:[('saturation', tensor([-0.6254])), ('sharpen', tensor([-0.2734])), ('elastic transform', tensor([0.3628])), ('TranslateY', tensor([0.1724]))]
[2022-10-14 22:34:53,016] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.044157	gLtNorm 0.0192 (0.0192)	gLvNorm 1.4203 (1.4203)	mvpNorm 1.3283 (1.3283)

[2022-10-14 22:35:49,577] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 60, batch_idx: 0, global_img_step: 101, aug_ops:[('Rotate', tensor([0.1999])), ('Equalize', tensor([-0.2180]))]
[2022-10-14 22:36:32,252] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 60	 Inner Train loss: 0.7453, acc=0.7206, lr=0.000000	
[2022-10-14 22:36:33,886] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 60	 Test loss: 0.9661, score: 0.6523
[2022-10-14 22:36:33,888] exp4_main.py->main line:277 [INFO]30% (61/200)
[2022-10-14 22:36:34,567] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.1413,  1.2213, -7.5701, -0.9957, -4.4221, -2.4849, -4.0998, -2.9803,
        -2.4849, -0.2120, -1.5734, -0.9297, -0.6155, -2.9816, -4.6659])
[2022-10-14 22:36:34,569] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.1927, -1.4243,  0.4834, -0.0556, -0.5237, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.2704, -2.0044,  0.6205,  0.0036,
        -0.4749, -0.7129])
[2022-10-14 22:36:34,719] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 61, batch_idx: 0, global_img_step: 102, aug_ops:[('brightness', tensor([0.3758])), ('gaussian noise', tensor([0.7321])), ('Equalize', tensor([0.3758]))]
[2022-10-14 22:36:34,719] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.043874	gLtNorm 2.5287 (2.5287)	gLvNorm 0.6748 (0.6748)	mvpNorm 0.6689 (0.6689)

[2022-10-14 22:37:31,288] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 61, batch_idx: 0, global_img_step: 103, aug_ops:[('contrast', tensor([0.0920])), ('sharpen', tensor([0.2571]))]
[2022-10-14 22:38:13,855] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 61	 Inner Train loss: 0.7161, acc=0.7320, lr=0.000000	
[2022-10-14 22:38:15,462] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 61	 Test loss: 1.0253, score: 0.6418
[2022-10-14 22:38:15,463] exp4_main.py->main line:277 [INFO]31% (62/200)
[2022-10-14 22:38:16,143] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-2.1674,  1.1915, -7.1324, -1.1871, -4.4690, -2.4849, -3.9092, -2.9803,
        -2.4849, -0.4398, -1.6352, -1.3140, -0.2547, -2.7719, -4.6499])
[2022-10-14 22:38:16,145] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4162, -1.4243,  0.9221,  0.3831, -0.9623, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.7091, -1.5657,  0.6205,  0.0036,
        -0.4749, -0.7129])
[2022-10-14 22:38:16,299] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 62, batch_idx: 0, global_img_step: 104, aug_ops:[('saturation', tensor([-0.5585])), ('TranslateX', tensor([-0.2357])), ('Equalize', tensor([-0.5897]))]
[2022-10-14 22:38:16,299] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.043585	gLtNorm 0.2765 (0.2765)	gLvNorm 0.3153 (0.3153)	mvpNorm 0.5265 (0.5265)

[2022-10-14 22:39:12,860] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 62, batch_idx: 0, global_img_step: 105, aug_ops:[('saturation', tensor([0.4551])), ('Rotate', tensor([0.3099])), ('Equalize', tensor([0.3814]))]
[2022-10-14 22:39:55,497] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 62	 Inner Train loss: 0.8019, acc=0.7053, lr=0.000000	
[2022-10-14 22:39:57,114] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 62	 Test loss: 1.0045, score: 0.6523
[2022-10-14 22:39:57,114] exp4_main.py->main line:277 [INFO]32% (63/200)
[2022-10-14 22:39:57,810] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.9567,  1.6205, -7.1905, -1.0710, -4.5745, -2.4849, -4.0382, -2.9803,
        -2.4849, -0.0529, -1.6073, -1.3602, -0.1020, -2.7793, -4.8182])
[2022-10-14 22:39:57,812] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4162, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.7091, -1.5176,  0.6205,  0.0036,
        -0.0390, -0.7129])
[2022-10-14 22:39:57,988] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 63, batch_idx: 0, global_img_step: 106, aug_ops:[('brightness', tensor([-0.1254])), ('Hsv', tensor([-0.0734,  0.0373,  0.1051])), ('gaussian blur', tensor([0.2203]))]
[2022-10-14 22:39:57,988] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.043291	gLtNorm 0.3238 (0.3238)	gLvNorm 0.2424 (0.2424)	mvpNorm 0.3742 (0.3742)

[2022-10-14 22:40:54,629] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 63, batch_idx: 0, global_img_step: 107, aug_ops:[('gaussian noise', tensor([-0.4362])), ('Equalize', tensor([0.2659]))]
[2022-10-14 22:41:37,157] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 63	 Inner Train loss: 0.7048, acc=0.7329, lr=0.000000	
[2022-10-14 22:41:38,796] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 63	 Test loss: 0.8537, score: 0.6795
[2022-10-14 22:41:38,797] exp4_main.py->main line:277 [INFO]32% (64/200)
[2022-10-14 22:41:39,474] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.9603,  1.6243, -7.5140, -1.0917, -4.6199, -2.4849, -4.4261, -2.9803,
        -2.4849, -0.0539, -1.5936, -1.3642, -0.1044, -2.8067, -5.1052])
[2022-10-14 22:41:39,475] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.2893, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.7091, -1.5180,  0.6205,  0.0036,
        -0.0390, -0.7129])
[2022-10-14 22:41:39,578] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 64, batch_idx: 0, global_img_step: 108, aug_ops:[('contrast', tensor([-0.3123])), ('Hed', tensor([-0.1698,  0.1158, -0.1614])), ('TranslateY', tensor([-0.0610])), ('ShearY', tensor([-1.]))]
[2022-10-14 22:41:39,579] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.042991	gLtNorm 0.7747 (0.7747)	gLvNorm 1.0807 (1.0807)	mvpNorm 1.9724 (1.9724)

[2022-10-14 22:42:36,119] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 64, batch_idx: 0, global_img_step: 109, aug_ops:[('saturation', tensor([-0.5655])), ('gaussian noise', tensor([0.6353])), ('Equalize', tensor([0.0886]))]
[2022-10-14 22:43:18,728] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 64	 Inner Train loss: 0.7575, acc=0.7225, lr=0.000000	
[2022-10-14 22:43:20,338] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 64	 Test loss: 0.9607, score: 0.6594
[2022-10-14 22:43:20,340] exp4_main.py->main line:277 [INFO]32% (65/200)
[2022-10-14 22:43:21,025] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.5975,  1.6305, -7.8611, -0.9908, -4.6200, -2.4849, -4.8539, -2.9803,
        -2.4849, -0.4530, -1.5913, -1.1782, -0.1418, -2.7117, -5.4259])
[2022-10-14 22:43:21,027] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.6238, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.7091, -1.6208,  0.6205,  0.0036,
         0.3479, -0.7129])
[2022-10-14 22:43:21,209] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 65, batch_idx: 0, global_img_step: 110, aug_ops:[('contrast', tensor([-0.0214])), ('saturation', tensor([0.1650])), ('TranslateY', tensor([0.3681])), ('Equalize', tensor([0.0946]))]
[2022-10-14 22:43:21,209] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.042685	gLtNorm 38.6817 (38.6817)	gLvNorm 0.3302 (0.3302)	mvpNorm 39.9925 (39.9925)

[2022-10-14 22:44:17,670] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 65, batch_idx: 0, global_img_step: 111, aug_ops:[('saturation', tensor([0.6916])), ('TranslateX', tensor([0.3090])), ('TranslateY', tensor([0.0306]))]
[2022-10-14 22:45:00,283] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 65	 Inner Train loss: 0.7468, acc=0.7210, lr=0.000000	
[2022-10-14 22:45:01,912] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 65	 Test loss: 0.8622, score: 0.6846
[2022-10-14 22:45:01,913] exp4_main.py->main line:277 [INFO]33% (66/200)
[2022-10-14 22:45:02,611] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.2331,  1.6501, -8.2060, -1.0077, -4.1943, -2.4849, -4.9528, -2.9803,
        -2.4849, -0.8776, -1.9653, -1.5965, -0.5680, -3.1385, -5.5985])
[2022-10-14 22:45:02,612] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.4966, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.7091, -1.6208,  0.6205,  0.0036,
         0.3479, -0.7129])
[2022-10-14 22:45:02,795] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 66, batch_idx: 0, global_img_step: 112, aug_ops:[('sharpen', tensor([0.0153]))]
[2022-10-14 22:45:02,795] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.042374	gLtNorm 0.1308 (0.1308)	gLvNorm 0.1596 (0.1596)	mvpNorm 0.3045 (0.3045)

[2022-10-14 22:45:59,251] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 66, batch_idx: 0, global_img_step: 113, aug_ops:[('contrast', tensor([0.3015])), ('saturation', tensor([0.3287]))]
[2022-10-14 22:46:41,906] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 66	 Inner Train loss: 0.7504, acc=0.7222, lr=0.000000	
[2022-10-14 22:46:43,512] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 66	 Test loss: 1.0750, score: 0.6403
[2022-10-14 22:46:43,513] exp4_main.py->main line:277 [INFO]34% (67/200)
[2022-10-14 22:46:44,198] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9250,  1.6709, -8.6242, -0.8748, -4.5848, -2.4849, -4.9572, -2.9803,
        -2.4849, -1.2082, -2.3877, -1.9977, -0.5350, -3.1575, -5.6053])
[2022-10-14 22:46:44,200] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.1761, -1.1317, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.5571, -0.9558, -0.9857, -0.3040, -1.6208,  0.6205,  0.0036,
         0.3479, -0.7129])
[2022-10-14 22:46:44,344] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 67, batch_idx: 0, global_img_step: 114, aug_ops:[('TranslateY', tensor([-0.3680]))]
[2022-10-14 22:46:44,344] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.042058	gLtNorm 34.6211 (34.6211)	gLvNorm 0.7391 (0.7391)	mvpNorm 42.8434 (42.8434)

[2022-10-14 22:47:40,803] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 67, batch_idx: 0, global_img_step: 115, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:48:23,400] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 67	 Inner Train loss: 0.7301, acc=0.7302, lr=0.000000	
[2022-10-14 22:48:25,058] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 67	 Test loss: 0.8766, score: 0.6820
[2022-10-14 22:48:25,059] exp4_main.py->main line:277 [INFO]34% (68/200)
[2022-10-14 22:48:25,748] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.2834,  1.7452, -9.0243, -0.8558, -4.8811, -2.4849, -4.9524, -2.9803,
        -2.4849, -1.2134, -2.3720, -1.8237, -0.5938, -3.0688, -6.0235])
[2022-10-14 22:48:25,750] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.5966, -0.8156, -1.4243,  0.4940,  0.3838, -1.0271, -0.9926, -0.4969,
         0.0425, -0.1375, -0.9558, -0.9857, -0.3040, -1.6208,  0.6205,  0.0036,
         0.3479, -0.7129])
[2022-10-14 22:48:25,904] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 68, batch_idx: 0, global_img_step: 116, aug_ops:[('idenity', [1.0])]
[2022-10-14 22:48:25,904] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.041737	gLtNorm 0.1323 (0.1323)	gLvNorm 0.1248 (0.1248)	mvpNorm 0.0134 (0.0134)

[2022-10-14 22:49:22,440] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 68, batch_idx: 0, global_img_step: 117, aug_ops:[('brightness', tensor([-0.0877])), ('contrast', tensor([-1.])), ('Hed', tensor([0.1043, 0.0695, 0.1651])), ('sharpen', tensor([0.4089])), ('ShearY', tensor([-0.1285]))]
[2022-10-14 22:50:05,157] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 68	 Inner Train loss: 0.7478, acc=0.7228, lr=0.000000	
[2022-10-14 22:50:06,807] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 68	 Test loss: 0.9371, score: 0.6634
[2022-10-14 22:50:06,808] exp4_main.py->main line:277 [INFO]34% (69/200)
[2022-10-14 22:50:07,504] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.1562,  1.7418, -9.0228, -0.4426, -4.8674, -2.4849, -4.9482, -2.9803,
        -2.4849, -1.6092, -2.3632, -1.9644, -0.5203, -3.2122, -6.0030])
[2022-10-14 22:50:07,506] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.5966, -0.8188, -1.4243,  0.9112,  0.3792, -1.0271, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.9558, -0.9857, -0.3040, -1.6208,  0.6205, -0.4135,
         0.7632, -0.7129])
[2022-10-14 22:50:07,656] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 69, batch_idx: 0, global_img_step: 118, aug_ops:[('saturation', tensor([0.0797])), ('Hed', tensor([ 0.1350, -0.0933,  0.1670])), ('Equalize', tensor([-0.7986]))]
[2022-10-14 22:50:07,657] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.041410	gLtNorm 0.0601 (0.0601)	gLvNorm 1.2127 (1.2127)	mvpNorm 1.0393 (1.0393)

[2022-10-14 22:51:04,256] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 69, batch_idx: 0, global_img_step: 119, aug_ops:[('contrast', tensor([-0.1080])), ('TranslateX', tensor([0.0680])), ('Equalize', tensor([-0.0706]))]
[2022-10-14 22:51:46,871] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 69	 Inner Train loss: 0.7487, acc=0.7244, lr=0.000000	
[2022-10-14 22:51:48,493] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 69	 Test loss: 0.9740, score: 0.6636
[2022-10-14 22:51:48,493] exp4_main.py->main line:277 [INFO]35% (70/200)
[2022-10-14 22:51:49,166] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9308,  1.6970, -9.0207, -0.2936, -4.8691, -2.4849, -4.9595, -2.9803,
        -2.4849, -1.5564, -1.9545, -1.9262, -0.1272, -3.1478, -5.9848])
[2022-10-14 22:51:49,168] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.1915, -1.4243,  0.7803,  0.3794, -0.6141, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.9558, -0.9857, -0.3040, -1.6208,  1.0346, -0.4135,
         0.7632, -0.7129])
[2022-10-14 22:51:49,310] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 70, batch_idx: 0, global_img_step: 120, aug_ops:[('contrast', tensor([0.2315])), ('saturation', tensor([0.1593])), ('Rotate', tensor([0.1139])), ('ShearY', tensor([-0.5190]))]
[2022-10-14 22:51:49,311] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.041079	gLtNorm 0.8365 (0.8365)	gLvNorm 0.0793 (0.0793)	mvpNorm 0.6803 (0.6803)

[2022-10-14 22:52:45,722] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 70, batch_idx: 0, global_img_step: 121, aug_ops:[('saturation', tensor([0.5415])), ('Hed', tensor([0.0924, 0.0132, 0.3823])), ('sharpen', tensor([0.3394])), ('gaussian noise', tensor([-0.8202])), ('TranslateX', tensor([0.0038])), ('TranslateY', tensor([-0.0897]))]
[2022-10-14 22:53:28,252] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 70	 Inner Train loss: 0.7268, acc=0.7321, lr=0.000000	
[2022-10-14 22:53:29,858] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 70	 Test loss: 0.9994, score: 0.6521
[2022-10-14 22:53:29,859] exp4_main.py->main line:277 [INFO]36% (71/200)
[2022-10-14 22:53:30,543] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9308,  1.6970, -9.0207, -0.2936, -4.8531, -2.4849, -4.6710, -2.9803,
        -2.4849, -1.5533, -2.1305, -2.2770,  0.0515, -3.1301, -5.9848])
[2022-10-14 22:53:30,545] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.1915, -1.4243,  0.6804,  0.3794, -0.6141, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.9558, -0.9857, -0.3040, -1.6208,  1.0650, -0.4135,
         0.7632, -0.7129])
[2022-10-14 22:53:30,705] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 71, batch_idx: 0, global_img_step: 122, aug_ops:[('saturation', tensor([-0.0274])), ('Equalize', tensor([-0.0459]))]
[2022-10-14 22:53:30,706] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.040742	gLtNorm 0.2727 (0.2727)	gLvNorm 0.2484 (0.2484)	mvpNorm 0.1852 (0.1852)

[2022-10-14 22:54:27,276] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 71, batch_idx: 0, global_img_step: 123, aug_ops:[('brightness', tensor([0.0290])), ('sharpen', tensor([0.2081])), ('gaussian noise', tensor([-0.1520])), ('TranslateY', tensor([-0.3474])), ('ShearX', tensor([-0.4631])), ('ShearY', tensor([-0.4469])), ('Equalize', tensor([0.0290]))]
[2022-10-14 22:55:09,848] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 71	 Inner Train loss: 0.7602, acc=0.7196, lr=0.000000	
[2022-10-14 22:55:11,462] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 71	 Test loss: 1.0105, score: 0.6420
[2022-10-14 22:55:11,462] exp4_main.py->main line:277 [INFO]36% (72/200)
[2022-10-14 22:55:12,140] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9308,  1.6970, -9.0207, -0.2936, -4.8639, -2.4849, -5.0784, -2.9803,
        -2.4849, -1.9584, -2.2751, -2.6843,  0.1078, -3.5359, -5.9848])
[2022-10-14 22:55:12,142] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.1915, -1.4243,  1.0707,  0.3794, -0.6141, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.9857, -0.3040, -1.6208,  0.7626, -0.4135,
         1.0373, -0.7129])
[2022-10-14 22:55:12,287] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 72, batch_idx: 0, global_img_step: 124, aug_ops:[('Hed', tensor([-0.1126, -0.0214,  1.0000])), ('TranslateY', tensor([-0.0225])), ('Equalize', tensor([-0.1821]))]
[2022-10-14 22:55:12,287] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.040401	gLtNorm 0.0771 (0.0771)	gLvNorm 0.7366 (0.7366)	mvpNorm 0.9155 (0.9155)

[2022-10-14 22:56:08,881] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 72, batch_idx: 0, global_img_step: 125, aug_ops:[('brightness', tensor([0.2451])), ('contrast', tensor([0.1181])), ('saturation', tensor([0.3291])), ('ShearX', tensor([0.0176]))]
[2022-10-14 22:56:51,499] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 72	 Inner Train loss: 0.7227, acc=0.7267, lr=0.000000	
[2022-10-14 22:56:53,134] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 72	 Test loss: 1.0603, score: 0.6487
[2022-10-14 22:56:53,135] exp4_main.py->main line:277 [INFO]36% (73/200)
[2022-10-14 22:56:53,822] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3340,  2.0879, -9.0310,  0.1103, -4.4621, -2.4849, -5.0613, -2.9803,
        -2.4849, -1.6956, -1.8712, -2.6547,  0.5118, -3.1441, -6.3171])
[2022-10-14 22:56:53,825] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.5953, -1.4243,  1.0707,  0.3794, -0.6141, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.9857, -0.3040, -1.6208,  1.1666, -0.4135,
         0.6333, -0.7129])
[2022-10-14 22:56:54,081] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 73, batch_idx: 0, global_img_step: 126, aug_ops:[('Hed', tensor([-0.0144, -0.4410, -0.9312])), ('elastic transform', tensor([-0.2995])), ('ShearY', tensor([0.3080]))]
[2022-10-14 22:56:54,081] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.040055	gLtNorm 17.0121 (17.0121)	gLvNorm 0.2980 (0.2980)	mvpNorm 20.7674 (20.7674)

[2022-10-14 22:57:50,602] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 73, batch_idx: 0, global_img_step: 127, aug_ops:[('contrast', tensor([0.1794])), ('saturation', tensor([0.5237])), ('TranslateY', tensor([0.0539]))]
[2022-10-14 22:58:33,018] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 73	 Inner Train loss: 0.7264, acc=0.7289, lr=0.000000	
[2022-10-14 22:58:34,637] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 73	 Test loss: 0.9748, score: 0.6602
[2022-10-14 22:58:34,638] exp4_main.py->main line:277 [INFO]37% (74/200)
[2022-10-14 22:58:35,330] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.4884,  1.8214, -8.8147, -0.2828, -4.8283, -2.4849, -5.0510, -2.5798,
        -2.4849, -2.0767, -1.8900, -2.3860,  0.4191, -3.2887, -5.9168])
[2022-10-14 22:58:35,333] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.9579, -1.4243,  1.0707,  0.3794, -0.6141, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -1.6208,  1.1666, -0.4135,
         0.5951, -0.7129])
[2022-10-14 22:58:35,473] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 74, batch_idx: 0, global_img_step: 128, aug_ops:[('ShearY', tensor([0.0175])), ('Equalize', tensor([-0.4704]))]
[2022-10-14 22:58:35,473] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.039705	gLtNorm 0.3508 (0.3508)	gLvNorm 0.1467 (0.1467)	mvpNorm 0.3135 (0.3135)

[2022-10-14 22:59:31,984] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 74, batch_idx: 0, global_img_step: 129, aug_ops:[('brightness', tensor([0.5842])), ('saturation', tensor([0.4899])), ('Hed', tensor([0.3314, 1.0000, 0.1737])), ('TranslateX', tensor([0.0682])), ('Equalize', tensor([0.5842]))]
[2022-10-14 23:00:14,583] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 74	 Inner Train loss: 0.7502, acc=0.7244, lr=0.000000	
[2022-10-14 23:00:16,220] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 74	 Test loss: 1.2029, score: 0.6311
[2022-10-14 23:00:16,221] exp4_main.py->main line:277 [INFO]38% (75/200)
[2022-10-14 23:00:16,906] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.4234,  1.4797, -8.7098, -0.5543, -5.2234, -2.4849, -5.0123, -2.5798,
        -2.4849, -2.0907, -1.9081, -2.3919,  0.3761, -3.2208, -5.8860])
[2022-10-14 23:00:16,908] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -2.0078, -1.4243,  0.9403,  0.1483, -1.0111, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -1.6208,  1.0396, -0.4135,
         0.5740, -0.7129])
[2022-10-14 23:00:17,056] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 75, batch_idx: 0, global_img_step: 130, aug_ops:[('Hsv', tensor([-0.9107,  0.0994, -0.5521]))]
[2022-10-14 23:00:17,056] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.039350	gLtNorm 0.2742 (0.2742)	gLvNorm 0.1327 (0.1327)	mvpNorm 0.5833 (0.5833)

[2022-10-14 23:01:13,577] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 75, batch_idx: 0, global_img_step: 131, aug_ops:[('contrast', tensor([0.2216])), ('TranslateX', tensor([-0.1176])), ('Equalize', tensor([0.1121]))]
[2022-10-14 23:01:56,148] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 75	 Inner Train loss: 0.7435, acc=0.7268, lr=0.000000	
[2022-10-14 23:01:57,754] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 75	 Test loss: 1.0654, score: 0.6508
[2022-10-14 23:01:57,755] exp4_main.py->main line:277 [INFO]38% (76/200)
[2022-10-14 23:01:58,438] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.6264,  1.1092, -8.7098, -0.4545, -5.2013, -2.4849, -4.8360, -2.5798,
        -2.4849, -2.0977, -1.9087, -2.3227,  0.3747, -3.2251, -5.8582])
[2022-10-14 23:01:58,440] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.7818, -1.4243,  1.3335, -0.0126, -1.0111, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -1.6208,  1.0396, -0.4135,
         0.5657, -0.7129])
[2022-10-14 23:01:58,544] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 76, batch_idx: 0, global_img_step: 132, aug_ops:[('contrast', tensor([0.7121]))]
[2022-10-14 23:01:58,544] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.038991	gLtNorm 19.3486 (19.3486)	gLvNorm 5.3355 (5.3355)	mvpNorm 12.9728 (12.9728)

[2022-10-14 23:02:55,083] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 76, batch_idx: 0, global_img_step: 133, aug_ops:[('Hed', tensor([-0.1383,  0.1951, -0.3208])), ('sharpen', tensor([-0.7625])), ('TranslateX', tensor([-0.5135]))]
[2022-10-14 23:03:37,651] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 76	 Inner Train loss: 0.7535, acc=0.7202, lr=0.000000	
[2022-10-14 23:03:39,264] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 76	 Test loss: 0.9966, score: 0.6460
[2022-10-14 23:03:39,265] exp4_main.py->main line:277 [INFO]38% (77/200)
[2022-10-14 23:03:39,950] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3745,  1.4348, -9.0996, -0.8415, -4.9714, -2.4849, -4.9005, -2.5798,
        -2.4849, -2.4600, -1.9257, -2.3143,  0.3772, -3.2662, -5.9788])
[2022-10-14 23:03:39,952] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.4079, -1.4243,  1.3335, -0.0126, -1.0111, -0.9926, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -2.0108,  1.0396, -0.4135,
         0.5693, -0.7129])
[2022-10-14 23:03:40,106] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 77, batch_idx: 0, global_img_step: 134, aug_ops:[('saturation', tensor([-0.4646]))]
[2022-10-14 23:03:40,107] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.038627	gLtNorm 0.0393 (0.0393)	gLvNorm 0.2141 (0.2141)	mvpNorm 0.1229 (0.1229)

[2022-10-14 23:04:36,526] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 77, batch_idx: 0, global_img_step: 135, aug_ops:[('contrast', tensor([0.0608])), ('gaussian blur', tensor([0.0562])), ('Rotate', tensor([0.1325]))]
[2022-10-14 23:05:19,052] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 77	 Inner Train loss: 0.7049, acc=0.7322, lr=0.000000	
[2022-10-14 23:05:20,682] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 77	 Test loss: 1.0673, score: 0.6476
[2022-10-14 23:05:20,684] exp4_main.py->main line:277 [INFO]39% (78/200)
[2022-10-14 23:05:21,369] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9902,  1.2116, -8.7135, -0.8441, -4.9173, -2.4849, -5.0532, -2.5798,
        -2.4849, -2.0891, -1.8917, -2.2581,  0.3752, -3.2442, -5.7934])
[2022-10-14 23:05:21,370] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.0291, -1.4243,  0.9592, -0.3907, -1.2454, -0.6064, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -2.0108,  1.0396, -0.4135,
         0.5651, -0.7129])
[2022-10-14 23:05:21,499] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 78, batch_idx: 0, global_img_step: 136, aug_ops:[('gaussian noise', tensor([0.3892])), ('TranslateY', tensor([0.7918])), ('Equalize', tensor([0.2417]))]
[2022-10-14 23:05:21,499] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.038260	gLtNorm 1.7207 (1.7207)	gLvNorm 0.2636 (0.2636)	mvpNorm 0.9497 (0.9497)

[2022-10-14 23:06:18,008] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 78, batch_idx: 0, global_img_step: 137, aug_ops:[('contrast', tensor([-0.8578])), ('TranslateX', tensor([-0.4241]))]
[2022-10-14 23:07:00,501] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 78	 Inner Train loss: 0.7274, acc=0.7291, lr=0.000000	
[2022-10-14 23:07:02,105] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 78	 Test loss: 1.2001, score: 0.6031
[2022-10-14 23:07:02,106] exp4_main.py->main line:277 [INFO]40% (79/200)
[2022-10-14 23:07:02,794] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.6422,  1.5788, -8.7155, -0.6752, -4.8937, -2.4849, -5.0609, -2.5798,
        -2.4849, -2.0889, -1.5367, -1.8787,  0.1651, -3.5965, -5.9618])
[2022-10-14 23:07:02,796] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.6870, -1.0034, -1.4243,  0.9592, -0.3907, -1.2454, -0.6064, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -2.0108,  1.0396, -0.4135,
         0.3950, -0.7129])
[2022-10-14 23:07:02,902] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 79, batch_idx: 0, global_img_step: 138, aug_ops:[('brightness', tensor([0.1964])), ('contrast', tensor([-0.0133])), ('Hed', tensor([-0.1833,  0.3571, -0.4834])), ('ShearY', tensor([0.0012]))]
[2022-10-14 23:07:02,903] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.037888	gLtNorm 25.2837 (25.2837)	gLvNorm 0.0083 (0.0083)	mvpNorm 25.7909 (25.7909)

[2022-10-14 23:07:59,286] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 79, batch_idx: 0, global_img_step: 139, aug_ops:[('TranslateX', tensor([0.1331])), ('ShearY', tensor([1.]))]
[2022-10-14 23:08:41,838] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 79	 Inner Train loss: 0.7116, acc=0.7305, lr=0.000000	
[2022-10-14 23:08:43,451] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 79	 Test loss: 0.8987, score: 0.6622
[2022-10-14 23:08:43,452] exp4_main.py->main line:277 [INFO]40% (80/200)
[2022-10-14 23:08:44,148] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.8882,  1.6066, -8.7156, -0.6028, -4.7162, -2.4849, -5.3542, -2.5798,
        -2.4849, -2.2338, -1.5808, -1.5504,  0.0442, -3.6062, -6.3396])
[2022-10-14 23:08:44,149] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0659, -1.0722, -1.4243,  0.9592, -0.3907, -1.2454, -0.6064, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -2.0108,  1.0396, -0.4135,
         0.0163, -0.7129])
[2022-10-14 23:08:44,324] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 80, batch_idx: 0, global_img_step: 140, aug_ops:[('contrast', tensor([0.3984])), ('saturation', tensor([0.0795]))]
[2022-10-14 23:08:44,324] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.037513	gLtNorm 3.0935 (3.0935)	gLvNorm 1.4315 (1.4315)	mvpNorm 4.5004 (4.5004)

[2022-10-14 23:09:40,829] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 80, batch_idx: 0, global_img_step: 141, aug_ops:[('gaussian noise', tensor([0.1352])), ('TranslateX', tensor([0.3454])), ('TranslateY', tensor([-0.2074]))]
[2022-10-14 23:10:23,337] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 80	 Inner Train loss: 0.7253, acc=0.7282, lr=0.000000	
[2022-10-14 23:10:24,949] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 80	 Test loss: 1.0825, score: 0.6458
[2022-10-14 23:10:24,950] exp4_main.py->main line:277 [INFO]40% (81/200)
[2022-10-14 23:10:25,637] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5132,  1.9782, -8.7373, -0.2589, -4.6927, -2.4849, -5.7292, -2.5798,
        -2.4849, -1.8588, -1.2089, -1.9254, -0.0539, -3.9814, -6.4533])
[2022-10-14 23:10:25,638] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0659, -1.3677, -1.4243,  0.9592, -0.3907, -1.2454, -0.6064, -0.4969,
        -0.3749, -0.1375, -0.5484, -0.5854, -0.3040, -2.0108,  1.3994, -0.4135,
         0.0457, -0.7129])
[2022-10-14 23:10:25,783] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 81, batch_idx: 0, global_img_step: 142, aug_ops:[('TranslateY', tensor([-0.2935])), ('Equalize', tensor([-0.5620]))]
[2022-10-14 23:10:25,784] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.037133	gLtNorm 0.7381 (0.7381)	gLvNorm 0.6625 (0.6625)	mvpNorm 0.3525 (0.3525)

[2022-10-14 23:11:22,247] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 81, batch_idx: 0, global_img_step: 143, aug_ops:[('idenity', [1.0])]
[2022-10-14 23:12:04,810] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 81	 Inner Train loss: 0.7401, acc=0.7250, lr=0.000000	
[2022-10-14 23:12:06,444] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 81	 Test loss: 0.9853, score: 0.6441
[2022-10-14 23:12:06,445] exp4_main.py->main line:277 [INFO]41% (82/200)
[2022-10-14 23:12:07,131] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.4106,  2.1129, -8.7487, -0.3998, -4.3214, -2.4849, -6.0363, -2.5798,
        -2.4849, -1.8746, -1.2142, -1.9444, -0.3933, -3.9821, -6.5794])
[2022-10-14 23:12:07,133] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0659, -1.7343, -1.4243,  0.5885, -0.7618, -1.2454, -0.6064, -0.4969,
        -0.0035, -0.1375, -0.5484, -0.5854, -0.3040, -1.6399,  1.3994, -0.4135,
         0.0457, -0.7129])
[2022-10-14 23:12:07,324] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 82, batch_idx: 0, global_img_step: 144, aug_ops:[('gaussian noise', tensor([1.])), ('TranslateY', tensor([0.0620])), ('Equalize', tensor([-1.]))]
[2022-10-14 23:12:07,324] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.036750	gLtNorm 0.1043 (0.1043)	gLvNorm 0.6066 (0.6066)	mvpNorm 0.3880 (0.3880)

[2022-10-14 23:13:03,716] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 82, batch_idx: 0, global_img_step: 145, aug_ops:[('brightness', tensor([0.3716])), ('contrast', tensor([0.4951])), ('Rotate', tensor([0.3598]))]
[2022-10-14 23:13:46,167] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 82	 Inner Train loss: 0.7372, acc=0.7236, lr=0.000000	
[2022-10-14 23:13:47,795] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 82	 Test loss: 0.8767, score: 0.6685
[2022-10-14 23:13:47,796] exp4_main.py->main line:277 [INFO]42% (83/200)
[2022-10-14 23:13:48,478] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.4192,  2.3578, -8.7733, -0.7320, -4.2747, -2.4849, -6.0331, -2.5798,
        -2.4849, -1.8775, -0.8481, -2.2467, -0.7608, -4.0076, -6.6681])
[2022-10-14 23:13:48,480] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0659, -1.6545, -1.4243,  0.8794, -0.4731, -1.5894, -0.6064, -0.4969,
        -0.0035, -0.1375, -0.5484, -0.5854, -0.3040, -1.6399,  1.3994, -0.4135,
         0.0457, -0.7129])
[2022-10-14 23:13:48,604] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 83, batch_idx: 0, global_img_step: 146, aug_ops:[('contrast', tensor([-0.2962])), ('Rotate', tensor([0.0188]))]
[2022-10-14 23:13:48,604] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.036363	gLtNorm 20.0079 (20.0079)	gLvNorm 0.3252 (0.3252)	mvpNorm 24.4953 (24.4953)

[2022-10-14 23:14:44,933] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 83, batch_idx: 0, global_img_step: 147, aug_ops:[('saturation', tensor([0.1132])), ('ShearY', tensor([-0.0426])), ('Equalize', tensor([0.1432]))]
[2022-10-14 23:15:27,529] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 83	 Inner Train loss: 0.7191, acc=0.7307, lr=0.000000	
[2022-10-14 23:15:29,141] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 83	 Test loss: 1.0375, score: 0.6347
[2022-10-14 23:15:29,142] exp4_main.py->main line:277 [INFO]42% (84/200)
[2022-10-14 23:15:29,835] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2093,  2.0646, -8.6289, -0.3710, -4.2216, -2.4849, -6.0967, -2.5798,
        -2.4849, -1.7875, -0.8088, -2.1843, -0.7161, -4.0443, -6.3620])
[2022-10-14 23:15:29,837] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0659, -1.4906, -1.4243,  0.8794, -0.4731, -1.5894, -0.6064, -0.4969,
        -0.0035, -0.1375, -0.5484, -0.5854, -0.3040, -1.6399,  1.3994, -0.4135,
         0.1401, -0.7129])
[2022-10-14 23:15:29,994] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 84, batch_idx: 0, global_img_step: 148, aug_ops:[('idenity', [1.0])]
[2022-10-14 23:15:29,994] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.035973	gLtNorm 1.2635 (1.2635)	gLvNorm 0.0176 (0.0176)	mvpNorm 1.3731 (1.3731)

[2022-10-14 23:16:26,389] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 84, batch_idx: 0, global_img_step: 149, aug_ops:[('brightness', tensor([0.6085])), ('contrast', tensor([-0.4441])), ('Equalize', tensor([0.6085]))]
[2022-10-14 23:17:08,905] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 84	 Inner Train loss: 0.7170, acc=0.7328, lr=0.000000	
[2022-10-14 23:17:10,525] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 84	 Test loss: 0.8183, score: 0.6864
[2022-10-14 23:17:10,526] exp4_main.py->main line:277 [INFO]42% (85/200)
[2022-10-14 23:17:11,209] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2093,  2.0646, -8.6291, -0.3707, -4.2213, -2.4849, -6.0978, -2.5798,
        -2.4849, -1.7921, -0.8143, -2.1758, -0.7159, -4.0439, -6.3620])
[2022-10-14 23:17:11,211] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0661, -1.4899, -1.4243,  0.8794, -0.4731, -1.5894, -0.6064, -0.4969,
        -0.0035, -0.1375, -0.5484, -0.5854, -0.3040, -1.6399,  1.6200, -0.0538,
         0.1401, -0.7129])
[2022-10-14 23:17:11,344] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 85, batch_idx: 0, global_img_step: 150, aug_ops:[('brightness', tensor([-0.0645])), ('sharpen', tensor([0.4257])), ('TranslateX', tensor([0.8004]))]
[2022-10-14 23:17:11,344] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.035580	gLtNorm 0.2031 (0.2031)	gLvNorm 0.3568 (0.3568)	mvpNorm 0.1542 (0.1542)

[2022-10-14 23:18:07,837] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 85, batch_idx: 0, global_img_step: 151, aug_ops:[('brightness', tensor([-0.0566])), ('Equalize', tensor([-0.0566]))]
[2022-10-14 23:18:50,388] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 85	 Inner Train loss: 0.7378, acc=0.7248, lr=0.000000	
[2022-10-14 23:18:52,003] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 85	 Test loss: 1.0805, score: 0.6330
[2022-10-14 23:18:52,004] exp4_main.py->main line:277 [INFO]43% (86/200)
[2022-10-14 23:18:52,668] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2183,  2.0796, -8.6578, -0.1611, -3.8959, -2.4849, -6.0993, -2.5798,
        -2.4849, -1.8498, -0.6643, -2.1607, -0.7418, -4.0424, -6.6668])
[2022-10-14 23:18:52,670] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2118, -1.4330, -1.4243,  0.5247, -0.4731, -1.5894, -0.6064, -0.8527,
        -0.0035,  0.2173, -0.5484, -0.5854, -0.3040, -1.6399,  1.9728, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:18:52,850] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 86, batch_idx: 0, global_img_step: 152, aug_ops:[('gaussian noise', tensor([1.])), ('TranslateY', tensor([0.0324]))]
[2022-10-14 23:18:52,850] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.035183	gLtNorm 1.8483 (1.8483)	gLvNorm 0.0116 (0.0116)	mvpNorm 1.9113 (1.9113)

[2022-10-14 23:19:49,241] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 86, batch_idx: 0, global_img_step: 153, aug_ops:[('sharpen', tensor([-0.0560])), ('gaussian noise', tensor([0.0643])), ('ShearY', tensor([-0.3482]))]
[2022-10-14 23:20:31,906] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 86	 Inner Train loss: 0.7208, acc=0.7334, lr=0.000000	
[2022-10-14 23:20:33,547] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 86	 Test loss: 0.9250, score: 0.6640
[2022-10-14 23:20:33,548] exp4_main.py->main line:277 [INFO]44% (87/200)
[2022-10-14 23:20:34,232] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.1293,  2.4207, -8.8814, -0.4109, -3.5466, -2.4849, -6.1030, -2.5798,
        -2.4849, -2.1958, -1.0157, -2.3299, -0.7305, -4.3244, -6.8572])
[2022-10-14 23:20:34,233] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2118, -1.1129, -1.4243,  0.8073, -0.1323, -1.5894, -0.6064, -0.8527,
        -0.0035,  0.2173, -0.5484, -0.2336, -0.3040, -1.6399,  1.9728, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:20:34,374] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 87, batch_idx: 0, global_img_step: 154, aug_ops:[('gaussian noise', tensor([0.4455])), ('TranslateY', tensor([0.6533])), ('Equalize', tensor([0.4212]))]
[2022-10-14 23:20:34,374] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.034784	gLtNorm 0.0827 (0.0827)	gLvNorm 0.0429 (0.0429)	mvpNorm 0.0703 (0.0703)

[2022-10-14 23:21:30,664] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 87, batch_idx: 0, global_img_step: 155, aug_ops:[('idenity', [1.0])]
[2022-10-14 23:22:13,101] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 87	 Inner Train loss: 0.7014, acc=0.7351, lr=0.000000	
[2022-10-14 23:22:14,709] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 87	 Test loss: 0.9619, score: 0.6542
[2022-10-14 23:22:14,710] exp4_main.py->main line:277 [INFO]44% (88/200)
[2022-10-14 23:22:15,392] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.1293,  2.4207, -8.8814, -0.4109, -3.2534, -2.4849, -5.7914, -2.5798,
        -2.4849, -2.2764, -1.0157, -2.3300, -0.7356, -4.3168, -6.8572])
[2022-10-14 23:22:15,394] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2118, -1.1129, -1.4243,  0.8073, -0.1323, -1.5894, -0.6064, -0.8527,
        -0.0035,  0.2173, -0.5484, -0.2336, -0.3040, -1.2927,  1.9728, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:22:15,534] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 88, batch_idx: 0, global_img_step: 156, aug_ops:[('sharpen', tensor([0.7047])), ('TranslateX', tensor([-0.1932])), ('ShearX', tensor([0.1997])), ('ShearY', tensor([0.2231])), ('Equalize', tensor([0.1310]))]
[2022-10-14 23:22:15,535] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.034381	gLtNorm 0.1124 (0.1124)	gLvNorm 0.0274 (0.0274)	mvpNorm 0.0691 (0.0691)

[2022-10-14 23:23:11,915] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 88, batch_idx: 0, global_img_step: 157, aug_ops:[('saturation', tensor([0.0765]))]
[2022-10-14 23:23:54,435] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 88	 Inner Train loss: 0.6773, acc=0.7397, lr=0.000000	
[2022-10-14 23:23:56,086] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 88	 Test loss: 0.9861, score: 0.6560
[2022-10-14 23:23:56,087] exp4_main.py->main line:277 [INFO]44% (89/200)
[2022-10-14 23:23:56,772] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.0610,  2.6697, -9.0195, -0.7283, -3.2676, -2.4849, -5.7938, -2.5798,
        -2.4849, -2.6060, -1.2281, -2.0773, -0.7668, -3.9827, -7.1986])
[2022-10-14 23:23:56,774] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.8680, -1.4433, -1.4243,  0.7955,  0.2077, -1.2458, -0.6064, -0.8527,
        -0.0035,  0.2173, -0.5484, -0.2336, -0.3040, -1.2927,  1.6300, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:23:56,902] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 89, batch_idx: 0, global_img_step: 158, aug_ops:[('TranslateX', tensor([1.])), ('TranslateY', tensor([-0.2647]))]
[2022-10-14 23:23:56,903] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.033975	gLtNorm 0.1777 (0.1777)	gLvNorm 2.7786 (2.7786)	mvpNorm 2.6700 (2.6700)

[2022-10-14 23:24:53,336] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 89, batch_idx: 0, global_img_step: 159, aug_ops:[('brightness', tensor([0.4632])), ('saturation', tensor([-0.5328])), ('Hsv', tensor([-0.3574,  0.2711,  0.1228])), ('Hed', tensor([ 0.3945,  0.3031, -0.3090])), ('TranslateX', tensor([-0.4139])), ('TranslateY', tensor([-0.6469]))]
[2022-10-14 23:25:35,925] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 89	 Inner Train loss: 0.7133, acc=0.7314, lr=0.000000	
[2022-10-14 23:25:37,555] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 89	 Test loss: 0.7651, score: 0.7034
[2022-10-14 23:25:37,556] exp4_main.py->main line:277 [INFO]45% (90/200)
[2022-10-14 23:25:38,351] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.0610,  2.6697, -9.0195, -0.7283, -3.2640, -2.4849, -5.8167, -2.5798,
        -2.4849, -2.6060, -1.2300, -2.0857, -0.7336, -3.9654, -7.1986])
[2022-10-14 23:25:38,353] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.8680, -1.4433, -1.4243,  0.7955,  0.2077, -1.2458, -0.6064, -0.8527,
         0.3362,  0.2173, -0.5484, -0.2336, -0.3040, -1.2927,  1.7574, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:25:38,451] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 90, batch_idx: 0, global_img_step: 160, aug_ops:[('brightness', tensor([0.2792])), ('contrast', tensor([0.3272])), ('saturation', tensor([0.0181])), ('Hed', tensor([0.2534, 0.2572, 1.0000])), ('gaussian noise', tensor([0.1068])), ('TranslateY', tensor([0.1457])), ('ShearX', tensor([0.5382])), ('Equalize', tensor([0.2792]))]
[2022-10-14 23:25:38,451] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.033567	gLtNorm 21.4008 (21.4008)	gLvNorm 0.0345 (0.0345)	mvpNorm 21.4728 (21.4728)

[2022-10-14 23:26:34,824] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 90, batch_idx: 0, global_img_step: 161, aug_ops:[('saturation', tensor([0.9491])), ('Hed', tensor([-0.3992,  0.3823, -0.6552])), ('TranslateY', tensor([0.1438])), ('Equalize', tensor([0.0645]))]
[2022-10-14 23:27:17,333] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 90	 Inner Train loss: 0.7270, acc=0.7288, lr=0.000000	
[2022-10-14 23:27:18,942] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 90	 Test loss: 0.9458, score: 0.6712
[2022-10-14 23:27:18,943] exp4_main.py->main line:277 [INFO]46% (91/200)
[2022-10-14 23:27:19,620] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.3435,  2.7865, -9.3466, -1.0631, -3.5821, -2.4849, -5.7665, -2.5798,
        -2.4849, -2.6127, -0.9580, -1.7558, -0.3980, -3.7301, -7.4454])
[2022-10-14 23:27:19,621] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.8680, -1.1544, -1.4243,  0.6676,  0.2077, -1.2458, -0.6064, -0.8527,
         0.3362,  0.2173, -0.5484, -0.2336, -0.3040, -1.2927,  1.7574, -0.0538,
         0.0194, -0.7129])
[2022-10-14 23:27:19,774] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 91, batch_idx: 0, global_img_step: 162, aug_ops:[('brightness', tensor([-0.6658])), ('Rotate', tensor([-0.3460])), ('TranslateX', tensor([-0.2145])), ('Equalize', tensor([-0.6658]))]
[2022-10-14 23:27:19,774] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.033156	gLtNorm 2.7722 (2.7722)	gLvNorm 0.2294 (0.2294)	mvpNorm 2.2114 (2.2114)

[2022-10-14 23:28:16,164] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 91, batch_idx: 0, global_img_step: 163, aug_ops:[('saturation', tensor([-0.0908])), ('Equalize', tensor([0.4768]))]
[2022-10-14 23:28:58,694] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 91	 Inner Train loss: 0.7282, acc=0.7293, lr=0.000000	
[2022-10-14 23:29:00,309] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 91	 Test loss: 1.0552, score: 0.6328
[2022-10-14 23:29:00,310] exp4_main.py->main line:277 [INFO]46% (92/200)
[2022-10-14 23:29:00,994] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.6748,  3.1018, -9.6776, -0.8034, -3.4175, -2.4849, -5.5912, -2.5798,
        -2.4849, -2.3443, -1.0900, -1.4442, -0.3762, -4.0598, -7.7768])
[2022-10-14 23:29:00,995] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.8680, -0.8236, -1.4243,  0.9985,  0.5188, -1.2458, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484, -0.2336,  0.0275, -1.2927,  1.4352, -0.0538,
         0.3446, -0.7129])
[2022-10-14 23:29:01,217] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 92, batch_idx: 0, global_img_step: 164, aug_ops:[('Hed', tensor([-0.3987, -0.6182, -1.0000])), ('gaussian blur', tensor([-0.4376])), ('Rotate', tensor([-0.7392]))]
[2022-10-14 23:29:01,217] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.032743	gLtNorm 0.0727 (0.0727)	gLvNorm 6.7953 (6.7953)	mvpNorm 6.0145 (6.0145)

[2022-10-14 23:29:57,535] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 92, batch_idx: 0, global_img_step: 165, aug_ops:[('contrast', tensor([-0.0845])), ('saturation', tensor([-0.5499])), ('ShearX', tensor([-0.3680])), ('ShearY', tensor([0.0528]))]
[2022-10-14 23:30:40,073] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 92	 Inner Train loss: 0.7653, acc=0.7194, lr=0.000000	
[2022-10-14 23:30:41,713] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 92	 Test loss: 1.0098, score: 0.6437
[2022-10-14 23:30:41,714] exp4_main.py->main line:277 [INFO]46% (93/200)
[2022-10-14 23:30:42,404] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.0015,  3.4292, -9.6922, -0.5935, -3.7142, -2.4849, -5.3071, -2.5798,
        -2.4849, -2.0182, -0.7627, -1.1191, -0.3688, -3.9045, -8.0066])
[2022-10-14 23:30:42,406] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.8680, -0.8236, -1.4243,  0.9985,  0.5188, -1.2458, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938,  0.0275, -1.2927,  1.7627,  0.2737,
         0.3446, -0.7129])
[2022-10-14 23:30:42,556] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 93, batch_idx: 0, global_img_step: 166, aug_ops:[('brightness', tensor([0.0086])), ('Hed', tensor([-0.0885,  0.0563, -0.7380]))]
[2022-10-14 23:30:42,556] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.032327	gLtNorm 1.1828 (1.1828)	gLvNorm 0.6317 (0.6317)	mvpNorm 2.7650 (2.7650)

[2022-10-14 23:31:39,096] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 93, batch_idx: 0, global_img_step: 167, aug_ops:[('Hsv', tensor([-0.0442,  0.0915, -0.0873])), ('sharpen', tensor([0.0978])), ('ShearY', tensor([-0.0397]))]
[2022-10-14 23:32:21,561] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 93	 Inner Train loss: 0.7430, acc=0.7222, lr=0.000000	
[2022-10-14 23:32:23,169] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 93	 Test loss: 1.1070, score: 0.6287
[2022-10-14 23:32:23,170] exp4_main.py->main line:277 [INFO]47% (94/200)
[2022-10-14 23:32:23,856] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9966,  3.4292, -9.6902, -0.6249, -3.5604, -2.4849, -4.9847, -2.5798,
        -2.4849, -1.7392, -0.7249, -0.9238, -0.0485, -3.8337, -8.0095])
[2022-10-14 23:32:23,857] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1906, -0.5582, -1.4243,  0.8512,  0.8410, -1.5690, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938, -0.2920, -1.2927,  1.7627,  0.5532,
         0.3446, -0.7129])
[2022-10-14 23:32:24,020] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 94, batch_idx: 0, global_img_step: 168, aug_ops:[('Hsv', tensor([0.0678, 0.0449, 0.0578])), ('gaussian noise', tensor([0.6872])), ('TranslateY', tensor([0.0392])), ('ShearY', tensor([0.1754])), ('Equalize', tensor([1.]))]
[2022-10-14 23:32:24,020] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.031909	gLtNorm 4.5354 (4.5354)	gLvNorm 1.3634 (1.3634)	mvpNorm 5.0119 (5.0119)

[2022-10-14 23:33:20,509] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 94, batch_idx: 0, global_img_step: 169, aug_ops:[('brightness', tensor([0.1777])), ('Hsv', tensor([0.3451, 0.1139, 0.1855])), ('sharpen', tensor([0.1870])), ('TranslateY', tensor([-0.0240])), ('ShearY', tensor([0.1792]))]
[2022-10-14 23:34:02,991] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 94	 Inner Train loss: 0.6576, acc=0.7505, lr=0.000000	
[2022-10-14 23:34:04,611] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 94	 Test loss: 0.8697, score: 0.6834
[2022-10-14 23:34:04,612] exp4_main.py->main line:277 [INFO]48% (95/200)
[2022-10-14 23:34:05,312] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.9966,  3.4292, -9.6902, -0.6336, -3.4932, -2.4849, -5.0279, -2.5798,
        -2.4849, -1.7483, -0.6842, -0.8785, -0.0481, -3.8375, -8.0095])
[2022-10-14 23:34:05,314] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1906, -0.5582, -1.4243,  0.5324,  1.1599, -1.5690, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938, -0.2920, -1.2927,  1.7627,  0.5824,
         0.3446, -0.7129])
[2022-10-14 23:34:05,471] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 95, batch_idx: 0, global_img_step: 170, aug_ops:[('contrast', tensor([0.4500])), ('saturation', tensor([0.1367])), ('Hed', tensor([-0.0442, -0.1245, -0.7744]))]
[2022-10-14 23:34:05,471] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.031489	gLtNorm 6.5188 (6.5188)	gLvNorm 0.8749 (0.8749)	mvpNorm 10.6458 (10.6458)

[2022-10-14 23:35:01,741] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 95, batch_idx: 0, global_img_step: 171, aug_ops:[('contrast', tensor([-0.0007])), ('gaussian noise', tensor([-0.3668])), ('Rotate', tensor([0.2368]))]
[2022-10-14 23:35:44,167] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 95	 Inner Train loss: 0.7018, acc=0.7325, lr=0.000000	
[2022-10-14 23:35:45,769] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 95	 Test loss: 1.0065, score: 0.6486
[2022-10-14 23:35:45,770] exp4_main.py->main line:277 [INFO]48% (96/200)
[2022-10-14 23:35:46,448] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.0978,  3.4090, -9.3821, -0.9151, -3.7965, -2.4849, -4.7134, -2.5798,
        -2.4849, -1.4439, -0.9982, -0.9933,  0.2667, -3.7995, -7.7228])
[2022-10-14 23:35:46,450] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1906, -0.8679, -1.4243,  0.5324,  1.1599, -1.5690, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938, -0.2920, -1.2927,  1.7313,  0.5824,
         0.3446, -0.7129])
[2022-10-14 23:35:46,593] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 96, batch_idx: 0, global_img_step: 172, aug_ops:[('saturation', tensor([-0.3511])), ('sharpen', tensor([-0.9231])), ('gaussian noise', tensor([-0.8468])), ('Equalize', tensor([-0.4446]))]
[2022-10-14 23:35:46,593] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.031067	gLtNorm 0.0924 (0.0924)	gLvNorm 0.4261 (0.4261)	mvpNorm 0.2037 (0.2037)

[2022-10-14 23:36:42,981] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 96, batch_idx: 0, global_img_step: 173, aug_ops:[('contrast', tensor([0.4118]))]
[2022-10-14 23:37:25,400] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 96	 Inner Train loss: 0.7364, acc=0.7260, lr=0.000000	
[2022-10-14 23:37:27,009] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 96	 Test loss: 0.9890, score: 0.6492
[2022-10-14 23:37:27,010] exp4_main.py->main line:277 [INFO]48% (97/200)
[2022-10-14 23:37:27,695] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3449,  3.3961, -9.0967, -1.2227, -3.5123, -2.4849, -4.8268, -2.5798,
        -2.4849, -1.4650, -1.0269, -1.3037,  0.2553, -3.4893, -7.4125])
[2022-10-14 23:37:27,697] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.5013, -1.1668, -1.4243,  0.5324,  0.8570, -1.5690, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938, -0.2920, -1.2927,  1.7313,  0.5824,
         0.0340, -0.7129])
[2022-10-14 23:37:27,842] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 97, batch_idx: 0, global_img_step: 174, aug_ops:[('contrast', tensor([-0.4655])), ('Equalize', tensor([-0.1533]))]
[2022-10-14 23:37:27,842] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.030643	gLtNorm 21.2124 (21.2124)	gLvNorm 0.7773 (0.7773)	mvpNorm 29.2491 (29.2491)

[2022-10-14 23:38:24,192] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 97, batch_idx: 0, global_img_step: 175, aug_ops:[('brightness', tensor([0.2836])), ('TranslateX', tensor([0.2446])), ('ShearY', tensor([-0.8655])), ('Equalize', tensor([0.2836]))]
[2022-10-14 23:39:06,629] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 97	 Inner Train loss: 0.7663, acc=0.7165, lr=0.000000	
[2022-10-14 23:39:08,267] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 97	 Test loss: 0.9325, score: 0.6653
[2022-10-14 23:39:08,268] exp4_main.py->main line:277 [INFO]49% (98/200)
[2022-10-14 23:39:08,956] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.6350,  3.3941, -8.8166, -1.1308, -3.2059, -2.4849, -4.5406, -2.5798,
        -2.4849, -1.1732, -1.3012, -1.0599,  0.5064, -3.4849, -7.3764])
[2022-10-14 23:39:08,959] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6319, -0.8612, -1.4243,  0.2261,  0.8570, -1.5690, -0.6064, -0.8527,
         0.3350,  0.2173, -0.5484,  0.0938, -0.2920, -1.2927,  1.7313,  0.5824,
         0.0340, -0.7129])
[2022-10-14 23:39:09,153] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 98, batch_idx: 0, global_img_step: 176, aug_ops:[('saturation', tensor([-0.8218])), ('sharpen', tensor([0.1381])), ('gaussian noise', tensor([-0.1417])), ('Equalize', tensor([0.7073]))]
[2022-10-14 23:39:09,153] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.030218	gLtNorm 0.1756 (0.1756)	gLvNorm 0.1014 (0.1014)	mvpNorm 0.1284 (0.1284)

[2022-10-14 23:40:05,556] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 98, batch_idx: 0, global_img_step: 177, aug_ops:[('brightness', tensor([0.0437])), ('saturation', tensor([0.3232])), ('Rotate', tensor([-0.1573])), ('TranslateX', tensor([-0.6503])), ('Equalize', tensor([0.0437]))]
[2022-10-14 23:40:47,998] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 98	 Inner Train loss: 0.7202, acc=0.7322, lr=0.000000	
[2022-10-14 23:40:49,613] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 98	 Test loss: 1.0834, score: 0.6297
[2022-10-14 23:40:49,613] exp4_main.py->main line:277 [INFO]50% (99/200)
[2022-10-14 23:40:50,293] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.6360,  3.4036, -8.8276, -1.1278, -3.2005, -2.4849, -4.5633, -2.5798,
        -2.4849, -1.1617, -1.3025, -1.0792,  0.5061, -3.3150, -7.3773])
[2022-10-14 23:40:50,295] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6319, -0.8544, -1.4243,  0.2261,  0.8570, -1.5690, -0.6064, -0.8527,
         0.3350,  0.5187, -0.5484,  0.0938, -0.2920, -1.2927,  1.6253,  0.3958,
         0.0340, -0.7129])
[2022-10-14 23:40:50,417] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 99, batch_idx: 0, global_img_step: 178, aug_ops:[('contrast', tensor([0.5218])), ('Rotate', tensor([0.0773])), ('ShearY', tensor([0.5333]))]
[2022-10-14 23:40:50,418] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.029790	gLtNorm 1.3322 (1.3322)	gLvNorm 0.0192 (0.0192)	mvpNorm 1.3002 (1.3002)

[2022-10-14 23:41:46,713] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 99, batch_idx: 0, global_img_step: 179, aug_ops:[('contrast', tensor([0.2956])), ('Rotate', tensor([0.0542])), ('ShearX', tensor([0.3888]))]
[2022-10-14 23:42:29,108] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 99	 Inner Train loss: 0.7215, acc=0.7265, lr=0.000000	
[2022-10-14 23:42:30,709] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 99	 Test loss: 1.1395, score: 0.6227
[2022-10-14 23:42:30,710] exp4_main.py->main line:277 [INFO]50% (100/200)
[2022-10-14 23:42:31,392] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.6077,  3.4111, -8.8911, -1.1287, -3.2005, -2.4849, -4.5200, -2.5798,
        -2.4849, -1.1489, -1.3017, -1.0099,  0.5062, -3.0272, -7.3774])
[2022-10-14 23:42:31,393] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.8725, -1.4243,  0.2261,  0.8570, -1.5690, -0.6064, -0.8527,
         0.3350,  0.8166, -0.5484,  0.0938, -0.2920, -1.2927,  1.6253,  0.3958,
         0.0443, -0.7129])
[2022-10-14 23:42:31,551] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 100, batch_idx: 0, global_img_step: 180, aug_ops:[('Equalize', tensor([0.2261]))]
[2022-10-14 23:42:31,552] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.029362	gLtNorm 0.3920 (0.3920)	gLvNorm 0.0881 (0.0881)	mvpNorm 0.4484 (0.4484)

[2022-10-14 23:43:27,825] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 100, batch_idx: 0, global_img_step: 181, aug_ops:[('contrast', tensor([-0.3261])), ('Hsv', tensor([0.0116, 0.3980, 0.0122]))]
[2022-10-14 23:44:10,291] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 100	 Inner Train loss: 0.7167, acc=0.7323, lr=0.000000	
[2022-10-14 23:44:11,907] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 100	 Test loss: 0.9014, score: 0.6628
[2022-10-14 23:44:11,908] exp4_main.py->main line:277 [INFO]50% (101/200)
[2022-10-14 23:44:12,597] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.5757,  3.4530, -8.9809, -0.8384, -3.1925, -2.4849, -4.8136, -2.5798,
        -2.4849, -0.8781, -1.2175, -0.7324,  0.3839, -3.3207, -7.5778])
[2022-10-14 23:44:12,599] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -1.0883, -1.4243,  0.2261,  0.8570, -1.5690, -0.6064, -0.8527,
         0.3350,  0.8200, -0.5484,  0.0938, -0.2920, -1.2927,  1.6253,  0.3958,
         0.0443, -0.7129])
[2022-10-14 23:44:12,756] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 101, batch_idx: 0, global_img_step: 182, aug_ops:[('gaussian noise', tensor([-0.2649])), ('TranslateX', tensor([0.1265]))]
[2022-10-14 23:44:12,756] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.028932	gLtNorm 0.2008 (0.2008)	gLvNorm 0.2751 (0.2751)	mvpNorm 0.0164 (0.0164)

[2022-10-14 23:45:09,171] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 101, batch_idx: 0, global_img_step: 183, aug_ops:[('contrast', tensor([0.2535])), ('ShearX', tensor([0.0808])), ('ShearY', tensor([0.2164]))]
[2022-10-14 23:45:51,562] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 101	 Inner Train loss: 0.7204, acc=0.7320, lr=0.000000	
[2022-10-14 23:45:53,180] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 101	 Test loss: 0.9933, score: 0.6546
[2022-10-14 23:45:53,180] exp4_main.py->main line:277 [INFO]51% (102/200)
[2022-10-14 23:45:53,854] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3734,  3.4323, -8.6928, -1.1262, -2.9278, -2.4849, -4.6581, -2.5798,
        -2.4849, -0.6456, -1.1795, -0.7363,  0.3657, -3.3402, -7.3899])
[2022-10-14 23:45:53,856] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.8744, -1.4243, -0.0607,  1.1463, -1.8583, -0.6064, -0.8527,
         0.3350,  0.5307, -0.5484,  0.0938, -0.2920, -1.2927,  1.6253,  0.3958,
        -0.2448, -1.0022])
[2022-10-14 23:45:54,009] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 102, batch_idx: 0, global_img_step: 184, aug_ops:[('Rotate', tensor([0.0719])), ('TranslateY', tensor([0.3852]))]
[2022-10-14 23:45:54,010] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.028501	gLtNorm 0.2913 (0.2913)	gLvNorm 0.5385 (0.5385)	mvpNorm 0.0428 (0.0428)

[2022-10-14 23:46:50,459] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 102, batch_idx: 0, global_img_step: 185, aug_ops:[('contrast', tensor([0.3895])), ('sharpen', tensor([-0.1714])), ('gaussian noise', tensor([-0.7613])), ('TranslateY', tensor([-0.4510]))]
[2022-10-14 23:47:32,885] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 102	 Inner Train loss: 0.7659, acc=0.7180, lr=0.000000	
[2022-10-14 23:47:34,499] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 102	 Test loss: 1.0695, score: 0.6340
[2022-10-14 23:47:34,500] exp4_main.py->main line:277 [INFO]52% (103/200)
[2022-10-14 23:47:35,181] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.4599,  3.2864, -8.6917, -1.0920, -2.6799, -2.4849, -4.6629, -2.5798,
        -2.4849, -0.4429, -1.1763, -0.6256,  0.3503, -3.3316, -7.3764])
[2022-10-14 23:47:35,182] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.8349, -1.4243, -0.0607,  1.1463, -1.8583, -0.6064, -0.8527,
         0.3350,  0.5307, -0.5484,  0.0938, -0.2920, -1.2927,  1.6253,  0.3958,
        -0.3704, -1.0022])
[2022-10-14 23:47:35,348] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 103, batch_idx: 0, global_img_step: 186, aug_ops:[('saturation', tensor([-0.2719])), ('sharpen', tensor([0.1885])), ('Equalize', tensor([0.3836]))]
[2022-10-14 23:47:35,348] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.028069	gLtNorm 0.0968 (0.0968)	gLvNorm 0.6632 (0.6632)	mvpNorm 1.1421 (1.1421)

[2022-10-14 23:48:31,772] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 103, batch_idx: 0, global_img_step: 187, aug_ops:[('gaussian blur', tensor([0.6861])), ('TranslateY', tensor([-0.2267]))]
[2022-10-14 23:49:14,239] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 103	 Inner Train loss: 0.6837, acc=0.7428, lr=0.000000	
[2022-10-14 23:49:15,881] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 103	 Test loss: 1.0156, score: 0.6501
[2022-10-14 23:49:15,882] exp4_main.py->main line:277 [INFO]52% (104/200)
[2022-10-14 23:49:16,564] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3008,  3.1993, -8.5997, -0.8199, -2.7621, -2.4849, -4.9003, -2.2991,
        -2.4849, -0.4963, -1.1817, -0.3475,  0.3755, -3.2095, -7.1175])
[2022-10-14 23:49:16,565] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.7015, -1.4243, -0.0654,  1.1463, -1.8583, -0.8870, -0.8527,
         0.3350,  0.5307, -0.5484,  0.1603, -0.2920, -1.2927,  1.4417,  0.3958,
        -0.2905, -1.0022])
[2022-10-14 23:49:16,678] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 104, batch_idx: 0, global_img_step: 188, aug_ops:[('brightness', tensor([-0.0199])), ('contrast', tensor([-0.1583])), ('Rotate', tensor([0.6705]))]
[2022-10-14 23:49:16,678] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.027636	gLtNorm 4.6189 (4.6189)	gLvNorm 0.0026 (0.0026)	mvpNorm 4.6184 (4.6184)

[2022-10-14 23:50:12,967] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 104, batch_idx: 0, global_img_step: 189, aug_ops:[('idenity', [1.0])]
[2022-10-14 23:50:55,444] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 104	 Inner Train loss: 0.7553, acc=0.7215, lr=0.000000	
[2022-10-14 23:50:57,065] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 104	 Test loss: 1.0026, score: 0.6578
[2022-10-14 23:50:57,066] exp4_main.py->main line:277 [INFO]52% (105/200)
[2022-10-14 23:50:57,754] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.2999,  3.2164, -8.6708, -0.8188, -2.9656, -2.4849, -5.0995, -2.2991,
        -2.4849, -0.7348, -1.0983, -0.3479,  0.3498, -3.2086, -7.1182])
[2022-10-14 23:50:57,756] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.7014, -1.4243, -0.3372,  1.1463, -1.8583, -0.8870, -0.8527,
         0.3350,  0.5307, -0.5484,  0.1603, -0.2920, -1.5690,  1.7181,  0.1195,
        -0.1819, -1.0022])
[2022-10-14 23:50:57,909] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 105, batch_idx: 0, global_img_step: 190, aug_ops:[('saturation', tensor([-0.6795])), ('Equalize', tensor([-0.6036]))]
[2022-10-14 23:50:57,909] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.027202	gLtNorm 0.0297 (0.0297)	gLvNorm 0.2298 (0.2298)	mvpNorm 0.1206 (0.1206)

[2022-10-14 23:51:54,220] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 105, batch_idx: 0, global_img_step: 191, aug_ops:[('contrast', tensor([-0.0405])), ('saturation', tensor([0.4359])), ('gaussian noise', tensor([-0.3400])), ('TranslateY', tensor([-0.2897]))]
[2022-10-14 23:52:36,749] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 105	 Inner Train loss: 0.6713, acc=0.7453, lr=0.000000	
[2022-10-14 23:52:38,413] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 105	 Test loss: 1.0818, score: 0.6353
[2022-10-14 23:52:38,414] exp4_main.py->main line:277 [INFO]53% (106/200)
[2022-10-14 23:52:39,092] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.5718,  3.4836, -8.9255, -1.0674, -3.0807, -2.4849, -5.1061, -2.2991,
        -2.4849, -0.4628, -1.3703, -0.6198,  0.6217, -3.3777, -7.2578])
[2022-10-14 23:52:39,093] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.4298, -1.4243, -0.3551,  1.1272, -2.1298, -0.8870, -0.8527,
         0.3350,  0.5307, -0.5484,  0.1603, -0.2920, -1.5690,  1.4586, -0.1525,
        -0.1819, -1.0022])
[2022-10-14 23:52:39,185] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 106, batch_idx: 0, global_img_step: 192, aug_ops:[('contrast', tensor([0.1876])), ('TranslateY', tensor([0.1608]))]
[2022-10-14 23:52:39,186] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.026767	gLtNorm 0.4255 (0.4255)	gLvNorm 0.3314 (0.3314)	mvpNorm 1.3657 (1.3657)

[2022-10-14 23:53:35,560] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 106, batch_idx: 0, global_img_step: 193, aug_ops:[('saturation', tensor([0.3698])), ('sharpen', tensor([0.1354])), ('Equalize', tensor([0.6458]))]
[2022-10-14 23:54:17,973] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 106	 Inner Train loss: 0.7125, acc=0.7344, lr=0.000000	
[2022-10-14 23:54:19,602] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 106	 Test loss: 1.1546, score: 0.6092
[2022-10-14 23:54:19,603] exp4_main.py->main line:277 [INFO]54% (107/200)
[2022-10-14 23:54:20,283] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.5543,  3.7430, -9.1217, -0.9130, -2.8131, -2.4849, -4.9338, -2.2991,
        -2.4849, -0.4616, -1.3719, -0.6188,  0.6246, -3.1485, -7.5217])
[2022-10-14 23:54:20,285] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.4109, -1.4243, -0.3551,  1.3523, -2.1298, -0.8870, -0.8527,
         0.3350,  0.5299, -0.5484,  0.1603, -0.2920, -1.3016,  1.4586, -0.1525,
        -0.3782, -0.7347])
[2022-10-14 23:54:20,438] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 107, batch_idx: 0, global_img_step: 194, aug_ops:[('brightness', tensor([-0.6201])), ('contrast', tensor([-0.2879])), ('Hsv', tensor([-0.2594, -0.3546, -0.9406]))]
[2022-10-14 23:54:20,439] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.026332	gLtNorm 2.3166 (2.3166)	gLvNorm 0.3933 (0.3933)	mvpNorm 3.8749 (3.8749)

[2022-10-14 23:55:16,811] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 107, batch_idx: 0, global_img_step: 195, aug_ops:[('contrast', tensor([-0.3716])), ('Equalize', tensor([-0.0756]))]
[2022-10-14 23:55:59,270] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 107	 Inner Train loss: 0.6806, acc=0.7426, lr=0.000000	
[2022-10-14 23:56:00,912] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 107	 Test loss: 1.0219, score: 0.6409
[2022-10-14 23:56:00,914] exp4_main.py->main line:277 [INFO]54% (108/200)
[2022-10-14 23:56:01,602] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.4414,  3.8992, -9.3850, -0.9122, -2.8283, -2.4849, -4.8873, -2.5623,
        -2.4849, -0.4662, -1.3714, -0.6141,  0.6186, -3.1514, -7.7314])
[2022-10-14 23:56:01,604] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.3022, -1.4243, -0.3551,  1.3523, -2.1298, -0.8870, -0.8527,
         0.3350,  0.5299, -0.5484,  0.4173, -0.2920, -1.2641,  1.4586, -0.1525,
        -0.5675, -0.7347])
[2022-10-14 23:56:01,758] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 108, batch_idx: 0, global_img_step: 196, aug_ops:[('saturation', tensor([-0.1607])), ('gaussian blur', tensor([-0.7344])), ('gaussian noise', tensor([0.1701])), ('ShearX', tensor([1.]))]
[2022-10-14 23:56:01,758] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.025897	gLtNorm 0.3854 (0.3854)	gLvNorm 1.2021 (1.2021)	mvpNorm 2.7773 (2.7773)

[2022-10-14 23:56:58,098] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 108, batch_idx: 0, global_img_step: 197, aug_ops:[('saturation', tensor([-0.0902])), ('gaussian noise', tensor([0.8199])), ('ShearY', tensor([-0.1313]))]
[2022-10-14 23:57:40,486] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 108	 Inner Train loss: 0.6847, acc=0.7390, lr=0.000000	
[2022-10-14 23:57:42,112] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 108	 Test loss: 1.0538, score: 0.6367
[2022-10-14 23:57:42,113] exp4_main.py->main line:277 [INFO]54% (109/200)
[2022-10-14 23:57:42,803] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.3087,  3.6561, -9.3789, -1.0431, -2.8414, -2.4849, -4.6739, -2.5623,
        -2.4849, -0.4666, -1.3812, -0.5980,  0.6148, -3.1489, -7.5935])
[2022-10-14 23:57:42,805] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.4955, -1.4243, -0.3167,  1.1799, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5678, -0.1354,
        -0.4947, -0.7347])
[2022-10-14 23:57:42,965] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 109, batch_idx: 0, global_img_step: 198, aug_ops:[('ShearY', tensor([0.1259]))]
[2022-10-14 23:57:42,965] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.025461	gLtNorm 0.1800 (0.1800)	gLvNorm 1.5315 (1.5315)	mvpNorm 0.8394 (0.8394)

[2022-10-14 23:58:39,280] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 109, batch_idx: 0, global_img_step: 199, aug_ops:[('contrast', tensor([-1.])), ('TranslateY', tensor([0.0777]))]
[2022-10-14 23:59:21,736] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 109	 Inner Train loss: 0.7325, acc=0.7262, lr=0.000000	
[2022-10-14 23:59:23,359] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 109	 Test loss: 0.9641, score: 0.6462
[2022-10-14 23:59:23,360] exp4_main.py->main line:277 [INFO]55% (110/200)
[2022-10-14 23:59:24,035] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.1084,  3.7372, -9.3795, -1.1128, -2.8573, -2.4849, -4.4195, -2.5623,
        -2.4849, -0.5165, -1.3914, -0.3905,  0.5696, -2.9013, -7.8371])
[2022-10-14 23:59:24,037] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.3557, -1.4243, -0.3521,  0.9254, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5937, -0.0147,
        -0.7492, -0.7347])
[2022-10-14 23:59:24,247] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 110, batch_idx: 0, global_img_step: 200, aug_ops:[('contrast', tensor([0.0560])), ('saturation', tensor([-0.5693])), ('gaussian noise', tensor([0.1615])), ('Equalize', tensor([0.4256]))]
[2022-10-14 23:59:24,248] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.025025	gLtNorm 0.4929 (0.4929)	gLvNorm 0.3733 (0.3733)	mvpNorm 0.6728 (0.6728)

[2022-10-15 00:00:20,775] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 110, batch_idx: 0, global_img_step: 201, aug_ops:[('ShearX', tensor([0.0343]))]
[2022-10-15 00:01:03,177] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 110	 Inner Train loss: 0.7065, acc=0.7332, lr=0.000000	
[2022-10-15 00:01:04,790] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 110	 Test loss: 0.8867, score: 0.6603
[2022-10-15 00:01:04,791] exp4_main.py->main line:277 [INFO]56% (111/200)
[2022-10-15 00:01:05,473] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-1.1289,  3.8426, -9.4570, -0.8918, -2.7702, -2.4849, -4.3826, -2.5623,
        -2.4849, -0.6070, -1.3987, -0.2910,  0.5607, -3.1513, -7.8598])
[2022-10-15 00:01:05,475] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.6027, -1.4243, -0.3521,  0.9254, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5937,  0.1471,
        -0.7689, -0.7347])
[2022-10-15 00:01:05,683] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 111, batch_idx: 0, global_img_step: 202, aug_ops:[('contrast', tensor([0.1202])), ('gaussian noise', tensor([0.2050])), ('ShearX', tensor([0.6408]))]
[2022-10-15 00:01:05,684] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.024589	gLtNorm 0.3109 (0.3109)	gLvNorm 0.5234 (0.5234)	mvpNorm 0.8004 (0.8004)

[2022-10-15 00:02:01,954] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 111, batch_idx: 0, global_img_step: 203, aug_ops:[('contrast', tensor([-0.1428])), ('Hsv', tensor([-0.7074, -0.6060, -0.4264])), ('gaussian blur', tensor([-0.0874]))]
[2022-10-15 00:02:44,358] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 111	 Inner Train loss: 0.7250, acc=0.7287, lr=0.000000	
[2022-10-15 00:02:45,980] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 111	 Test loss: 0.8761, score: 0.6713
[2022-10-15 00:02:45,981] exp4_main.py->main line:277 [INFO]56% (112/200)
[2022-10-15 00:02:46,668] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.8832,  3.8598, -9.6097, -0.6606, -2.5981, -2.4849, -4.6264, -2.5623,
        -2.4849, -0.4248, -1.2042, -0.5128,  0.3153, -3.3497, -7.8629])
[2022-10-15 00:02:46,670] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.5391, -1.4243, -0.3521,  0.9254, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5937,  0.1471,
        -0.5230, -0.7347])
[2022-10-15 00:02:46,795] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 112, batch_idx: 0, global_img_step: 204, aug_ops:[('contrast', tensor([-0.2337])), ('Rotate', tensor([-0.0314]))]
[2022-10-15 00:02:46,796] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.024153	gLtNorm 6.1814 (6.1814)	gLvNorm 0.0835 (0.0835)	mvpNorm 7.3584 (7.3584)

[2022-10-15 00:03:43,198] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 112, batch_idx: 0, global_img_step: 205, aug_ops:[('ShearY', tensor([-0.4056])), ('Equalize', tensor([-0.1593]))]
[2022-10-15 00:04:25,758] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 112	 Inner Train loss: 0.7267, acc=0.7312, lr=0.000000	
[2022-10-15 00:04:27,376] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 112	 Test loss: 0.9688, score: 0.6551
[2022-10-15 00:04:27,377] exp4_main.py->main line:277 [INFO]56% (113/200)
[2022-10-15 00:04:28,067] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.7531,  3.8598, -9.6120, -0.6341, -2.4507, -2.4849, -4.6310, -2.5623,
        -2.4849, -0.4254, -1.1926, -0.3696,  0.2120, -3.4191, -7.6291])
[2022-10-15 00:04:28,068] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.2975, -1.4243, -0.3521,  0.9254, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5937,  0.1471,
        -0.5699, -0.7347])
[2022-10-15 00:04:28,197] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 113, batch_idx: 0, global_img_step: 206, aug_ops:[('contrast', tensor([-0.3413])), ('TranslateX', tensor([0.4751])), ('ShearY', tensor([0.2687]))]
[2022-10-15 00:04:28,197] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.023718	gLtNorm 0.0224 (0.0224)	gLvNorm 0.1616 (0.1616)	mvpNorm 0.1382 (0.1382)

[2022-10-15 00:05:24,559] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 113, batch_idx: 0, global_img_step: 207, aug_ops:[('contrast', tensor([0.6266]))]
[2022-10-15 00:06:06,965] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 113	 Inner Train loss: 0.6832, acc=0.7388, lr=0.000000	
[2022-10-15 00:06:08,567] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 113	 Test loss: 0.9424, score: 0.6572
[2022-10-15 00:06:08,568] exp4_main.py->main line:277 [INFO]57% (114/200)
[2022-10-15 00:06:09,268] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.8375,  4.0961, -9.8491, -0.3970, -2.6829, -2.4849, -4.6346, -2.5623,
        -2.4849, -0.1977, -1.2419, -0.5518,  0.3786, -3.5388, -7.8663])
[2022-10-15 00:06:09,270] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.4127, -1.4243, -0.3521,  0.9254, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.5095,  1.5937,  0.1471,
        -0.5699, -0.7347])
[2022-10-15 00:06:09,421] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 114, batch_idx: 0, global_img_step: 208, aug_ops:[('brightness', tensor([-0.3844])), ('contrast', tensor([-0.5961])), ('sharpen', tensor([-0.8483])), ('ShearX', tensor([-0.3080])), ('Equalize', tensor([-0.3844]))]
[2022-10-15 00:06:09,421] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.023283	gLtNorm 37.5427 (37.5427)	gLvNorm 7.3282 (7.3282)	mvpNorm 21.0202 (21.0202)

[2022-10-15 00:07:05,894] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 114, batch_idx: 0, global_img_step: 209, aug_ops:[('contrast', tensor([-0.1093])), ('saturation', tensor([-0.0483])), ('Hed', tensor([-0.0158,  0.0842,  0.3126])), ('sharpen', tensor([1.])), ('Equalize', tensor([-0.0889]))]
[2022-10-15 00:07:48,367] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 114	 Inner Train loss: 0.7703, acc=0.7183, lr=0.000000	
[2022-10-15 00:07:49,992] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 114	 Test loss: 0.9859, score: 0.6431
[2022-10-15 00:07:49,993] exp4_main.py->main line:277 [INFO]58% (115/200)
[2022-10-15 00:07:50,677] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.6082,  4.1323, -9.8889, -0.3031, -2.7329, -2.4849, -4.5952, -2.5623,
        -2.4849, -0.1994, -1.2544, -0.6253,  0.3804, -3.3705, -7.8665])
[2022-10-15 00:07:50,678] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.6196, -0.3991, -1.4243, -0.3521,  1.1549, -2.3748, -0.8870, -0.8527,
         0.3350,  0.2711, -0.5484,  0.4173, -0.2920, -1.2768,  1.5937,  0.1471,
        -0.5652, -0.9676])
[2022-10-15 00:07:50,807] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 115, batch_idx: 0, global_img_step: 210, aug_ops:[('TranslateX', tensor([1.])), ('Equalize', tensor([0.1730]))]
[2022-10-15 00:07:50,808] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.022848	gLtNorm 7.6532 (7.6532)	gLvNorm 0.2003 (0.2003)	mvpNorm 9.3544 (9.3544)

[2022-10-15 00:08:47,085] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 115, batch_idx: 0, global_img_step: 211, aug_ops:[('saturation', tensor([1.])), ('gaussian blur', tensor([0.1064])), ('elastic transform', tensor([0.1011])), ('Rotate', tensor([-0.2007])), ('Equalize', tensor([-0.0648]))]
[2022-10-15 00:09:29,521] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 115	 Inner Train loss: 0.7497, acc=0.7222, lr=0.000000	
[2022-10-15 00:09:31,159] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 115	 Test loss: 0.9939, score: 0.6501
[2022-10-15 00:09:31,160] exp4_main.py->main line:277 [INFO]58% (116/200)
[2022-10-15 00:09:31,855] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.6955,  3.9445, -9.8012, -0.2676, -2.9096, -2.4849, -4.8182, -2.5623,
        -2.4849, -0.4276, -1.4683, -0.4766,  0.1885, -3.1424, -7.8634])
[2022-10-15 00:09:31,857] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.3911, -0.3393, -1.4243, -0.3521,  1.1549, -2.3748, -1.1155, -0.6242,
         0.1066,  0.0426, -0.5484,  0.6458, -0.2920, -1.2768,  1.5937,  0.3753,
        -0.7557, -0.9676])
[2022-10-15 00:09:32,065] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 116, batch_idx: 0, global_img_step: 212, aug_ops:[('contrast', tensor([0.2149])), ('saturation', tensor([-0.1793])), ('Equalize', tensor([0.3094]))]
[2022-10-15 00:09:32,065] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.022414	gLtNorm 0.1986 (0.1986)	gLvNorm 0.4329 (0.4329)	mvpNorm 0.1099 (0.1099)

[2022-10-15 00:10:28,291] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 116, batch_idx: 0, global_img_step: 213, aug_ops:[('contrast', tensor([0.4666])), ('Hsv', tensor([0.0310, 0.0610, 0.0559]))]
[2022-10-15 00:11:10,695] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 116	 Inner Train loss: 0.7320, acc=0.7265, lr=0.000000	
[2022-10-15 00:11:12,312] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 116	 Test loss: 0.8991, score: 0.6677
[2022-10-15 00:11:12,314] exp4_main.py->main line:277 [INFO]58% (117/200)
[2022-10-15 00:11:13,007] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5936,  3.7313, -9.7316, -0.0442, -2.6855, -2.4849, -4.9037, -2.5623,
        -2.4849, -0.4275, -1.2778, -0.6580,  0.2523, -3.1421, -7.8634])
[2022-10-15 00:11:13,009] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.3911, -0.3665, -1.4243, -0.3521,  1.1549, -2.3748, -1.1155, -0.6242,
         0.1066,  0.0426, -0.5484,  0.6458, -0.2920, -1.2768,  1.3696,  0.3753,
        -0.6970, -0.9676])
[2022-10-15 00:11:13,169] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 117, batch_idx: 0, global_img_step: 214, aug_ops:[('saturation', tensor([0.5775])), ('Hed', tensor([ 0.8833, -0.4126, -0.2417])), ('gaussian blur', tensor([0.2022])), ('ShearY', tensor([-0.0723])), ('Equalize', tensor([-0.1936]))]
[2022-10-15 00:11:13,169] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.021981	gLtNorm 0.0517 (0.0517)	gLvNorm 5.3916 (5.3916)	mvpNorm 5.3250 (5.3250)

[2022-10-15 00:12:09,709] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 117, batch_idx: 0, global_img_step: 215, aug_ops:[('contrast', tensor([-0.1030])), ('gaussian noise', tensor([-0.0194])), ('ShearX', tensor([-0.2871])), ('Equalize', tensor([-0.1863]))]
[2022-10-15 00:12:52,263] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 117	 Inner Train loss: 0.7164, acc=0.7310, lr=0.000000	
[2022-10-15 00:12:53,889] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 117	 Test loss: 0.7764, score: 0.6889
[2022-10-15 00:12:53,890] exp4_main.py->main line:277 [INFO]59% (118/200)
[2022-10-15 00:12:54,570] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5946,  3.6548, -9.7324, -0.0447, -2.6847, -2.4849, -4.9308, -2.7821,
        -2.4849, -0.4335, -1.4974, -0.8775,  0.4693, -3.1460, -7.8605])
[2022-10-15 00:12:54,572] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.3911, -0.3620, -1.4243, -0.3521,  1.1549, -2.3748, -1.1155, -0.6242,
         0.1066,  0.0426, -0.5484,  0.6462, -0.2920, -1.2768,  1.3696,  0.3832,
        -0.6970, -0.9676])
[2022-10-15 00:12:54,844] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 118, batch_idx: 0, global_img_step: 216, aug_ops:[('contrast', tensor([0.0614])), ('sharpen', tensor([-0.6382]))]
[2022-10-15 00:12:54,844] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.021549	gLtNorm 0.1141 (0.1141)	gLvNorm 0.1839 (0.1839)	mvpNorm 0.1457 (0.1457)

[2022-10-15 00:13:51,182] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 118, batch_idx: 0, global_img_step: 217, aug_ops:[('gaussian blur', tensor([0.3007])), ('gaussian noise', tensor([0.1797]))]
[2022-10-15 00:14:33,569] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 118	 Inner Train loss: 0.6474, acc=0.7510, lr=0.000000	
[2022-10-15 00:14:35,211] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 118	 Test loss: 0.8441, score: 0.6856
[2022-10-15 00:14:35,213] exp4_main.py->main line:277 [INFO]60% (119/200)
[2022-10-15 00:14:35,900] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-4.2922e-01,  3.4398e+00, -9.7301e+00,  2.8873e-03, -2.6388e+00,
        -2.4849e+00, -4.8900e+00, -2.7821e+00, -2.4849e+00, -6.4397e-01,
        -1.4958e+00, -9.1347e-01,  4.6996e-01, -3.1400e+00, -7.8595e+00])
[2022-10-15 00:14:35,901] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4499, -0.1783, -1.4243, -0.1367,  1.1629, -2.1593, -1.1155, -0.6242,
        -0.1089,  0.1581, -0.5484,  0.6462, -0.2920, -1.2768,  1.3696,  0.3832,
        -0.6816, -0.9676])
[2022-10-15 00:14:36,010] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 119, batch_idx: 0, global_img_step: 218, aug_ops:[('brightness', tensor([-0.9793])), ('TranslateY', tensor([-0.7587])), ('Equalize', tensor([-0.9793]))]
[2022-10-15 00:14:36,010] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.021118	gLtNorm 16.3589 (16.3589)	gLvNorm 0.1522 (0.1522)	mvpNorm 16.6931 (16.6931)

[2022-10-15 00:15:32,262] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 119, batch_idx: 0, global_img_step: 219, aug_ops:[('TranslateX', tensor([-0.3821])), ('Equalize', tensor([-0.1862]))]
[2022-10-15 00:16:14,616] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 119	 Inner Train loss: 0.7358, acc=0.7268, lr=0.000000	
[2022-10-15 00:16:16,239] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 119	 Test loss: 0.9299, score: 0.6558
[2022-10-15 00:16:16,240] exp4_main.py->main line:277 [INFO]60% (120/200)
[2022-10-15 00:16:16,928] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2273,  3.4291, -9.7004,  0.1214, -2.6612, -2.4849, -4.8778, -2.7821,
        -2.4849, -0.6370, -1.4958, -0.9143,  0.4689, -3.1421, -7.8501])
[2022-10-15 00:16:16,930] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4604, -0.2529, -1.4243, -0.3429,  0.9997, -2.1495, -1.1155, -0.6242,
        -0.1089,  0.1581, -0.5484,  0.8571, -0.2920, -1.0657,  1.3696,  0.3764,
        -0.6816, -0.9676])
[2022-10-15 00:16:17,084] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 120, batch_idx: 0, global_img_step: 220, aug_ops:[('TranslateX', tensor([-0.2130]))]
[2022-10-15 00:16:17,085] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.020688	gLtNorm 0.0788 (0.0788)	gLvNorm 3.7364 (3.7364)	mvpNorm 4.8191 (4.8191)

[2022-10-15 00:17:13,312] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 120, batch_idx: 0, global_img_step: 221, aug_ops:[('contrast', tensor([0.4495])), ('Hed', tensor([0.1453, 0.7687, 0.5080])), ('Rotate', tensor([-0.1056]))]
[2022-10-15 00:17:55,707] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 120	 Inner Train loss: 0.7337, acc=0.7233, lr=0.000000	
[2022-10-15 00:17:57,332] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 120	 Test loss: 0.8532, score: 0.6795
[2022-10-15 00:17:57,333] exp4_main.py->main line:277 [INFO]60% (121/200)
[2022-10-15 00:17:58,025] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.0257,  3.4179, -9.5717, -0.0799, -2.8626, -2.4849, -4.9644, -2.7821,
        -2.4849, -0.5374, -1.2945, -1.0021,  0.6756, -2.9381, -7.7929])
[2022-10-15 00:17:58,026] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4604, -0.0537, -1.4243, -0.3429,  0.9997, -2.1495, -1.1155, -0.6242,
        -0.1089,  0.0246, -0.5484,  0.8571, -0.2920, -1.0657,  1.3696,  0.5782,
        -0.6816, -0.9676])
[2022-10-15 00:17:58,178] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 121, batch_idx: 0, global_img_step: 222, aug_ops:[('saturation', tensor([-0.6743]))]
[2022-10-15 00:17:58,179] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.020260	gLtNorm 0.5326 (0.5326)	gLvNorm 1.5293 (1.5293)	mvpNorm 3.7718 (3.7718)

[2022-10-15 00:18:54,502] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 121, batch_idx: 0, global_img_step: 223, aug_ops:[('Hsv', tensor([ 0.5154,  0.2604, -0.2540])), ('Rotate', tensor([0.2963])), ('TranslateX', tensor([-0.6063])), ('ShearX', tensor([-0.0535])), ('Equalize', tensor([-0.0549]))]
[2022-10-15 00:19:36,890] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 121	 Inner Train loss: 0.7142, acc=0.7322, lr=0.000000	
[2022-10-15 00:19:38,533] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 121	 Test loss: 0.9438, score: 0.6552
[2022-10-15 00:19:38,534] exp4_main.py->main line:277 [INFO]61% (122/200)
[2022-10-15 00:19:39,222] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.0097,  3.5411, -9.5732, -0.0682, -2.8538, -2.4849, -4.9712, -2.7821,
        -2.4849, -0.5969, -1.4624, -1.1879,  0.6537, -2.9826, -7.8916])
[2022-10-15 00:19:39,223] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2677, -0.2475, -1.4243, -0.3429,  0.9997, -2.1495, -1.2300, -0.4217,
        -0.0917,  0.0246, -0.5484,  0.8571, -0.2920, -1.0657,  1.1799,  0.5782,
        -0.6816, -0.9676])
[2022-10-15 00:19:39,362] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 122, batch_idx: 0, global_img_step: 224, aug_ops:[('brightness', tensor([0.1456])), ('contrast', tensor([-0.0131])), ('TranslateY', tensor([0.3257])), ('Equalize', tensor([0.1456]))]
[2022-10-15 00:19:39,362] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.019832	gLtNorm 0.1909 (0.1909)	gLvNorm 1.0918 (1.0918)	mvpNorm 0.6835 (0.6835)

[2022-10-15 00:20:35,701] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 122, batch_idx: 0, global_img_step: 225, aug_ops:[('brightness', tensor([0.6295])), ('TranslateY', tensor([0.3110])), ('ShearX', tensor([0.5765])), ('Equalize', tensor([0.6295]))]
[2022-10-15 00:21:18,239] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 122	 Inner Train loss: 0.7064, acc=0.7370, lr=0.000000	
[2022-10-15 00:21:19,867] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 122	 Test loss: 0.9140, score: 0.6667
[2022-10-15 00:21:19,868] exp4_main.py->main line:277 [INFO]62% (123/200)
[2022-10-15 00:21:20,562] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.1377,  3.7057, -9.7689, -0.0536, -2.6556, -2.4849, -4.7749, -2.7821,
        -2.4849, -0.3992, -1.5628, -1.3861,  0.6300, -3.1785, -8.0481])
[2022-10-15 00:21:20,564] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4636, -0.2946, -1.4243, -0.3429,  0.9997, -2.1495, -1.2300, -0.4217,
        -0.0917,  0.0246, -0.5484,  0.8571, -0.2920, -1.0657,  1.3778,  0.5782,
        -0.8793, -0.9676])
[2022-10-15 00:21:20,697] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 123, batch_idx: 0, global_img_step: 226, aug_ops:[('TranslateX', tensor([-0.8572])), ('ShearY', tensor([-0.1124]))]
[2022-10-15 00:21:20,698] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.019407	gLtNorm 0.4353 (0.4353)	gLvNorm 0.0959 (0.0959)	mvpNorm 0.6715 (0.6715)

[2022-10-15 00:22:17,162] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 123, batch_idx: 0, global_img_step: 227, aug_ops:[('brightness', tensor([-0.5572])), ('gaussian blur', tensor([-0.4491])), ('Rotate', tensor([-0.0433]))]
[2022-10-15 00:22:59,679] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 123	 Inner Train loss: 0.7473, acc=0.7189, lr=0.000000	
[2022-10-15 00:23:01,306] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 123	 Test loss: 0.9539, score: 0.6671
[2022-10-15 00:23:01,307] exp4_main.py->main line:277 [INFO]62% (124/200)
[2022-10-15 00:23:01,997] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.1376,  3.7057, -9.7689,  0.0508, -2.6559, -2.4849, -4.8226, -2.7821,
        -2.4849, -0.3951, -1.5704, -1.3735,  0.6272, -3.1662, -8.0481])
[2022-10-15 00:23:01,999] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4636, -0.2946, -1.4243, -0.3429,  0.9997, -1.9554, -1.2300, -0.4217,
        -0.0917,  0.0246, -0.5484,  0.8571, -0.2920, -1.0657,  1.3158,  0.5782,
        -0.8956, -0.9676])
[2022-10-15 00:23:02,248] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 124, batch_idx: 0, global_img_step: 228, aug_ops:[('brightness', tensor([-0.1929])), ('contrast', tensor([0.5461])), ('saturation', tensor([-1.])), ('Hed', tensor([-0.6071,  0.5844, -0.3305])), ('sharpen', tensor([0.2674])), ('elastic transform', tensor([-0.3021]))]
[2022-10-15 00:23:02,248] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.018983	gLtNorm 0.3930 (0.3930)	gLvNorm 0.5331 (0.5331)	mvpNorm 0.2143 (0.2143)

[2022-10-15 00:23:58,631] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 124, batch_idx: 0, global_img_step: 229, aug_ops:[('idenity', [1.0])]
[2022-10-15 00:24:41,206] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 124	 Inner Train loss: 0.6724, acc=0.7434, lr=0.000000	
[2022-10-15 00:24:42,815] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 124	 Test loss: 0.9230, score: 0.6670
[2022-10-15 00:24:42,816] exp4_main.py->main line:277 [INFO]62% (125/200)
[2022-10-15 00:24:43,499] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.1494,  3.6891, -9.7657,  0.0444, -2.6560, -2.4849, -4.7292, -2.7821,
        -2.4849, -0.3638, -1.5711, -1.4225,  0.5005, -3.1588, -8.0402])
[2022-10-15 00:24:43,501] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4599, -0.2816, -1.4243, -0.3429,  0.9997, -1.9554, -1.0404, -0.5531,
        -0.0914,  0.0251, -0.5484,  0.8571, -0.2920, -1.0657,  1.3158,  0.7395,
        -0.8956, -0.9676])
[2022-10-15 00:24:43,770] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 125, batch_idx: 0, global_img_step: 230, aug_ops:[('contrast', tensor([1.])), ('sharpen', tensor([0.0635])), ('gaussian noise', tensor([0.0395]))]
[2022-10-15 00:24:43,770] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.018561	gLtNorm 0.0564 (0.0564)	gLvNorm 0.2431 (0.2431)	mvpNorm 0.4058 (0.4058)

[2022-10-15 00:25:40,088] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 125, batch_idx: 0, global_img_step: 231, aug_ops:[('saturation', tensor([0.1957])), ('sharpen', tensor([-0.3599]))]
[2022-10-15 00:26:22,596] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 125	 Inner Train loss: 0.7516, acc=0.7213, lr=0.000000	
[2022-10-15 00:26:24,221] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 125	 Test loss: 0.8631, score: 0.6775
[2022-10-15 00:26:24,222] exp4_main.py->main line:277 [INFO]63% (126/200)
[2022-10-15 00:26:24,900] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.0113,  3.8714, -9.9040,  0.2204, -2.6496, -2.4849, -4.7597, -2.7821,
        -2.4849, -0.3786, -1.5200, -1.3645,  0.5698, -3.1603, -8.0821])
[2022-10-15 00:26:24,902] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4864, -0.2055, -1.4243, -0.3429,  0.9997, -1.9554, -1.0404, -0.7388,
        -0.0914,  0.0251, -0.5484,  0.8571, -0.2920, -1.0657,  1.3158,  0.9250,
        -0.7149, -0.9676])
[2022-10-15 00:26:25,004] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 126, batch_idx: 0, global_img_step: 232, aug_ops:[('contrast', tensor([0.4525])), ('Hsv', tensor([-0.6646, -0.4659, -0.6973]))]
[2022-10-15 00:26:25,004] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.018141	gLtNorm 0.2667 (0.2667)	gLvNorm 1.9242 (1.9242)	mvpNorm 1.4934 (1.4934)

[2022-10-15 00:27:21,378] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 126, batch_idx: 0, global_img_step: 233, aug_ops:[('contrast', tensor([-1.])), ('Equalize', tensor([-0.1369]))]
[2022-10-15 00:28:03,789] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 126	 Inner Train loss: 0.7049, acc=0.7318, lr=0.000000	
[2022-10-15 00:28:05,412] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 126	 Test loss: 0.8665, score: 0.6742
[2022-10-15 00:28:05,413] exp4_main.py->main line:277 [INFO]64% (127/200)
[2022-10-15 00:28:06,109] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1691,   4.0498, -10.0848,   0.4013,  -2.6375,  -2.4849,  -4.9408,
         -2.7821,  -2.4849,  -0.5524,  -1.3415,  -1.3529,   0.4186,  -3.0734,
         -8.2621])
[2022-10-15 00:28:06,111] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.4864, -0.3867, -1.4243, -0.3429,  0.9997, -1.9554, -1.0404, -0.7388,
        -0.0914,  0.0251, -0.5484,  0.8571, -0.2920, -1.2471,  1.1346,  1.0463,
        -0.5502, -0.9676])
[2022-10-15 00:28:06,270] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 127, batch_idx: 0, global_img_step: 234, aug_ops:[('contrast', tensor([-0.3658])), ('Equalize', tensor([-0.2151]))]
[2022-10-15 00:28:06,271] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.017723	gLtNorm 0.5787 (0.5787)	gLvNorm 0.4245 (0.4245)	mvpNorm 0.0738 (0.0738)

[2022-10-15 00:29:02,768] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 127, batch_idx: 0, global_img_step: 235, aug_ops:[('idenity', [1.0])]
[2022-10-15 00:29:45,097] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 127	 Inner Train loss: 0.7115, acc=0.7331, lr=0.000000	
[2022-10-15 00:29:46,701] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 127	 Test loss: 1.0582, score: 0.6447
[2022-10-15 00:29:46,702] exp4_main.py->main line:277 [INFO]64% (128/200)
[2022-10-15 00:29:47,379] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.3377,   3.9380, -10.0154,   0.2337,  -2.4603,  -2.4849,  -5.1109,
         -2.7821,  -2.4849,  -0.7287,  -1.5187,  -1.5299,   0.2414,  -2.8970,
         -8.0968])
[2022-10-15 00:29:47,381] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.3092, -0.3253, -1.4243, -0.5201,  0.8225, -2.1327, -1.0404, -0.7388,
        -0.2687,  0.0251, -0.5484,  0.8571, -0.2920, -1.2471,  1.3118,  1.0463,
        -0.5502, -0.9676])
[2022-10-15 00:29:47,512] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 128, batch_idx: 0, global_img_step: 236, aug_ops:[('Hed', tensor([ 0.3350, -0.4122,  0.7664])), ('TranslateY', tensor([0.6438]))]
[2022-10-15 00:29:47,512] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.017307	gLtNorm 0.0559 (0.0559)	gLvNorm 0.1955 (0.1955)	mvpNorm 0.0770 (0.0770)

[2022-10-15 00:30:43,794] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 128, batch_idx: 0, global_img_step: 237, aug_ops:[('gaussian noise', tensor([-0.0545])), ('Equalize', tensor([-0.2957]))]
[2022-10-15 00:31:26,240] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 128	 Inner Train loss: 0.7007, acc=0.7336, lr=0.000000	
[2022-10-15 00:31:27,873] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 128	 Test loss: 0.9521, score: 0.6637
[2022-10-15 00:31:27,874] exp4_main.py->main line:277 [INFO]64% (129/200)
[2022-10-15 00:31:28,557] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5060,  3.7779, -9.9331,  0.2269, -2.3820, -2.4849, -5.1296, -2.7821,
        -2.4849, -0.8999, -1.5174, -1.6983,  0.2299, -2.7252, -7.9237])
[2022-10-15 00:31:28,559] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1366, -0.4766, -1.4243, -0.6113,  0.8355, -2.1327, -1.0404, -0.7388,
        -0.2687,  0.0251, -0.5484,  0.8571, -0.2920, -1.2471,  1.3118,  0.8733,
        -0.3773, -0.9676])
[2022-10-15 00:31:28,721] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 129, batch_idx: 0, global_img_step: 238, aug_ops:[('saturation', tensor([0.2575]))]
[2022-10-15 00:31:28,721] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.016894	gLtNorm 0.2924 (0.2924)	gLvNorm 0.1557 (0.1557)	mvpNorm 0.3503 (0.3503)

[2022-10-15 00:32:25,200] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 129, batch_idx: 0, global_img_step: 239, aug_ops:[('contrast', tensor([0.0827])), ('Hsv', tensor([-0.1788, -0.2847, -0.1855]))]
[2022-10-15 00:33:07,791] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 129	 Inner Train loss: 0.7125, acc=0.7354, lr=0.000000	
[2022-10-15 00:33:09,389] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 129	 Test loss: 0.9995, score: 0.6491
[2022-10-15 00:33:09,389] exp4_main.py->main line:277 [INFO]65% (130/200)
[2022-10-15 00:33:10,074] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5438,  3.7395, -9.7693,  0.1302, -2.4276, -2.4849, -4.9654, -2.7821,
        -2.4849, -0.8984, -1.5962, -1.6987,  0.1451, -2.6451, -7.9233])
[2022-10-15 00:33:10,076] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1366, -0.4089, -1.4243, -0.5918,  0.6770, -2.1327, -1.0404, -0.7388,
        -0.2687,  0.0251, -0.5484,  0.8571, -0.2920, -1.2471,  1.1739,  0.8733,
        -0.3773, -0.7986])
[2022-10-15 00:33:10,178] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 130, batch_idx: 0, global_img_step: 240, aug_ops:[('brightness', tensor([0.0991])), ('contrast', tensor([0.3469])), ('Hed', tensor([ 0.0655,  0.0310, -1.0000]))]
[2022-10-15 00:33:10,178] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.016483	gLtNorm 3.2458 (3.2458)	gLvNorm 0.7087 (0.7087)	mvpNorm 5.4607 (5.4607)

[2022-10-15 00:34:06,372] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 130, batch_idx: 0, global_img_step: 241, aug_ops:[('Rotate', tensor([0.0755]))]
[2022-10-15 00:34:48,932] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 130	 Inner Train loss: 0.7723, acc=0.7156, lr=0.000000	
[2022-10-15 00:34:50,565] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 130	 Test loss: 0.9317, score: 0.6741
[2022-10-15 00:34:50,565] exp4_main.py->main line:277 [INFO]66% (131/200)
[2022-10-15 00:34:51,250] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.4248,  3.5768, -9.6398, -0.0302, -2.3050, -2.4849, -4.9820, -2.7821,
        -2.4849, -0.9048, -1.7578, -1.8632,  0.1305, -2.4812, -7.9194])
[2022-10-15 00:34:51,251] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1366, -0.5696, -1.4243, -0.7562,  0.5915, -2.2912, -1.0404, -0.7388,
        -0.2687,  0.1899, -0.5484,  0.8571, -0.2920, -1.2471,  1.1739,  0.8733,
        -0.3773, -0.7986])
[2022-10-15 00:34:51,432] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 131, batch_idx: 0, global_img_step: 242, aug_ops:[('contrast', tensor([-0.6700])), ('saturation', tensor([-0.2754])), ('Equalize', tensor([0.4184]))]
[2022-10-15 00:34:51,432] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.016075	gLtNorm 0.1210 (0.1210)	gLvNorm 0.2437 (0.2437)	mvpNorm 0.0704 (0.0704)

[2022-10-15 00:35:47,677] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 131, batch_idx: 0, global_img_step: 243, aug_ops:[('brightness', tensor([0.1332])), ('contrast', tensor([0.0571])), ('Hsv', tensor([ 0.0565,  0.1560, -0.0815])), ('TranslateY', tensor([-0.8613]))]
[2022-10-15 00:36:30,238] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 131	 Inner Train loss: 0.7493, acc=0.7258, lr=0.000000	
[2022-10-15 00:36:31,861] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 131	 Test loss: 0.8643, score: 0.6838
[2022-10-15 00:36:31,862] exp4_main.py->main line:277 [INFO]66% (132/200)
[2022-10-15 00:36:32,551] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.3637,  3.4311, -9.5582, -0.0309, -2.2870, -2.4849, -4.9867, -2.7821,
        -2.4849, -0.9091, -1.7472, -1.8612,  0.1321, -2.4753, -7.9193])
[2022-10-15 00:36:32,552] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1366, -0.5734, -1.4243, -0.7787,  0.5927, -2.2959, -1.0404, -0.7388,
        -0.2687,  0.1899, -0.5484,  0.8571, -0.2920, -1.2471,  1.1295,  1.0300,
        -0.3079, -0.7986])
[2022-10-15 00:36:32,680] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 132, batch_idx: 0, global_img_step: 244, aug_ops:[('Hed', tensor([ 0.1552, -0.0800,  0.1701])), ('Rotate', tensor([-0.0794])), ('TranslateX', tensor([-0.6465])), ('ShearX', tensor([-0.4569])), ('Equalize', tensor([0.1402]))]
[2022-10-15 00:36:32,680] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.015669	gLtNorm 0.2713 (0.2713)	gLvNorm 0.4437 (0.4437)	mvpNorm 0.0488 (0.0488)

[2022-10-15 00:37:28,972] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 132, batch_idx: 0, global_img_step: 245, aug_ops:[('contrast', tensor([-0.0640])), ('saturation', tensor([-0.1460])), ('TranslateX', tensor([-0.1914])), ('ShearY', tensor([-0.0405]))]
[2022-10-15 00:38:11,336] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 132	 Inner Train loss: 0.7352, acc=0.7246, lr=0.000000	
[2022-10-15 00:38:12,971] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 132	 Test loss: 0.8493, score: 0.6793
[2022-10-15 00:38:12,972] exp4_main.py->main line:277 [INFO]66% (133/200)
[2022-10-15 00:38:13,665] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2097,  3.5275, -9.7148, -0.0305, -2.2878, -2.4849, -5.1272, -2.9388,
        -2.4849, -0.8751, -1.7461, -1.8842,  0.1407, -2.4657, -7.9424])
[2022-10-15 00:38:13,667] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0006, -0.7300, -1.4243, -0.7787,  0.5927, -2.2959, -1.0404, -0.7388,
        -0.2687,  0.1899, -0.5484,  1.0138, -0.2920, -1.2471,  1.1295,  0.9376,
        -0.4335, -0.7986])
[2022-10-15 00:38:13,819] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 133, batch_idx: 0, global_img_step: 246, aug_ops:[('elastic transform', tensor([0.9008])), ('TranslateX', tensor([-0.4477])), ('Equalize', tensor([0.1908]))]
[2022-10-15 00:38:13,819] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.015266	gLtNorm 0.0913 (0.0913)	gLvNorm 0.2024 (0.2024)	mvpNorm 0.2130 (0.2130)

[2022-10-15 00:39:10,137] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 133, batch_idx: 0, global_img_step: 247, aug_ops:[('contrast', tensor([-0.0210])), ('ShearY', tensor([-0.2018])), ('Equalize', tensor([-0.2883]))]
[2022-10-15 00:39:52,656] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 133	 Inner Train loss: 0.6755, acc=0.7478, lr=0.000000	
[2022-10-15 00:39:54,257] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 133	 Test loss: 0.8406, score: 0.6781
[2022-10-15 00:39:54,258] exp4_main.py->main line:277 [INFO]67% (134/200)
[2022-10-15 00:39:54,935] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.1988,  3.6739, -9.7247, -0.0304, -2.4187, -2.4849, -5.1146, -2.9388,
        -2.4849, -0.9319, -1.7365, -1.8899,  0.0624, -2.5033, -7.9577])
[2022-10-15 00:39:54,937] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0006, -0.7369, -1.4243, -0.7736,  0.5891, -2.2959, -1.0404, -0.7388,
        -0.2687,  0.1899, -0.5484,  1.1641, -0.2920, -1.2471,  1.1696,  0.9376,
        -0.4335, -0.9439])
[2022-10-15 00:39:55,070] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 134, batch_idx: 0, global_img_step: 248, aug_ops:[('contrast', tensor([0.3164])), ('saturation', tensor([0.4773])), ('sharpen', tensor([0.1117])), ('Rotate', tensor([0.4906])), ('TranslateY', tensor([0.8735])), ('ShearY', tensor([0.2494]))]
[2022-10-15 00:39:55,070] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.014867	gLtNorm 0.1224 (0.1224)	gLvNorm 0.3731 (0.3731)	mvpNorm 0.8788 (0.8788)

[2022-10-15 00:40:51,362] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 134, batch_idx: 0, global_img_step: 249, aug_ops:[('Equalize', tensor([0.2136]))]
[2022-10-15 00:41:33,940] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 134	 Inner Train loss: 0.7365, acc=0.7257, lr=0.000000	
[2022-10-15 00:41:35,571] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 134	 Test loss: 1.0372, score: 0.6410
[2022-10-15 00:41:35,572] exp4_main.py->main line:277 [INFO]68% (135/200)
[2022-10-15 00:41:36,253] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.3472,  3.7000, -9.7556,  0.1182, -2.4216, -2.4849, -5.2616, -2.9388,
        -2.4849, -0.8260, -1.6816, -1.8744, -0.0514, -2.6237, -8.0891])
[2022-10-15 00:41:36,255] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1491, -0.7789, -1.4243, -0.7736,  0.5891, -2.2959, -1.0404, -0.7388,
        -0.2687,  0.1899, -0.5484,  1.1641, -0.2920, -1.2471,  1.3088,  0.9376,
        -0.5821, -1.0911])
[2022-10-15 00:41:36,410] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 135, batch_idx: 0, global_img_step: 250, aug_ops:[('saturation', tensor([-0.2185])), ('gaussian noise', tensor([-0.0951])), ('ShearY', tensor([-0.4468])), ('Equalize', tensor([-0.4768]))]
[2022-10-15 00:41:36,411] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.014470	gLtNorm 0.0962 (0.0962)	gLvNorm 0.5432 (0.5432)	mvpNorm 0.2675 (0.2675)

[2022-10-15 00:42:32,651] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 135, batch_idx: 0, global_img_step: 251, aug_ops:[('contrast', tensor([-0.3960])), ('Hed', tensor([-0.4229, -0.4341, -0.5014])), ('gaussian noise', tensor([-0.8025])), ('elastic transform', tensor([-0.4970])), ('TranslateX', tensor([0.1062])), ('ShearY', tensor([-0.1772]))]
[2022-10-15 00:43:15,163] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 135	 Inner Train loss: 0.7311, acc=0.7265, lr=0.000000	
[2022-10-15 00:43:16,798] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 135	 Test loss: 1.0085, score: 0.6360
[2022-10-15 00:43:16,799] exp4_main.py->main line:277 [INFO]68% (136/200)
[2022-10-15 00:43:17,487] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.3511,  3.7399, -9.7630,  0.0975, -2.4794, -2.4849, -5.2607, -2.9388,
        -2.4849, -0.8246, -1.6800, -1.8754, -0.0488, -2.6238, -8.1342])
[2022-10-15 00:43:17,490] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1491, -0.8260, -1.4243, -0.7269,  0.5552, -2.3755, -1.0404, -0.7388,
        -0.2687,  0.1896, -0.5484,  1.1641, -0.2920, -1.1053,  1.3124,  0.9376,
        -0.5760, -1.0911])
[2022-10-15 00:43:17,621] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 136, batch_idx: 0, global_img_step: 252, aug_ops:[('contrast', tensor([-0.1949])), ('TranslateY', tensor([0.3277])), ('Equalize', tensor([-0.2685]))]
[2022-10-15 00:43:17,622] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.014077	gLtNorm 1.6474 (1.6474)	gLvNorm 0.4228 (0.4228)	mvpNorm 1.6405 (1.6405)

[2022-10-15 00:44:13,990] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 136, batch_idx: 0, global_img_step: 253, aug_ops:[('contrast', tensor([-0.0703])), ('saturation', tensor([-0.2150])), ('Equalize', tensor([-0.5460]))]
[2022-10-15 00:44:56,350] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 136	 Inner Train loss: 0.7078, acc=0.7323, lr=0.000000	
[2022-10-15 00:44:57,985] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 136	 Test loss: 1.0259, score: 0.6370
[2022-10-15 00:44:57,986] exp4_main.py->main line:277 [INFO]68% (137/200)
[2022-10-15 00:44:58,665] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.4310,  3.8793, -9.8356,  0.2220, -2.3422, -2.4849, -5.2642, -2.9388,
        -2.4849, -0.7497, -1.6181, -1.7851, -0.1377, -2.4902, -8.2747])
[2022-10-15 00:44:58,666] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.8143, -1.4243, -0.7269,  0.5552, -2.3755, -1.0404, -0.7388,
        -0.2687,  0.1896, -0.5484,  1.1641, -0.2920, -1.1053,  1.3124,  1.0761,
        -0.6100, -1.0911])
[2022-10-15 00:44:58,861] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 137, batch_idx: 0, global_img_step: 254, aug_ops:[('contrast', tensor([0.4487])), ('gaussian blur', tensor([0.7097])), ('Equalize', tensor([-0.2445]))]
[2022-10-15 00:44:58,861] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.013687	gLtNorm 0.6175 (0.6175)	gLvNorm 0.4998 (0.4998)	mvpNorm 1.6570 (1.6570)

[2022-10-15 00:45:55,038] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 137, batch_idx: 0, global_img_step: 255, aug_ops:[('brightness', tensor([-1.])), ('saturation', tensor([0.3287])), ('ShearX', tensor([-0.1965])), ('Equalize', tensor([-1.]))]
[2022-10-15 00:46:37,381] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 137	 Inner Train loss: 0.7014, acc=0.7350, lr=0.000000	
[2022-10-15 00:46:39,006] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 137	 Test loss: 0.9370, score: 0.6643
[2022-10-15 00:46:39,007] exp4_main.py->main line:277 [INFO]69% (138/200)
[2022-10-15 00:46:39,691] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.5046,  4.0113, -9.9186,  0.2670, -2.2117, -2.4849, -5.3861, -3.0757,
        -2.4849, -0.6207, -1.7519, -1.6486, -0.2746, -2.5866, -8.2767])
[2022-10-15 00:46:39,693] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.6977, -1.4243, -0.7269,  0.5552, -2.3755, -1.1772, -0.6019,
        -0.4029,  0.1896, -0.5484,  1.2893, -0.2920, -1.1053,  1.3124,  0.9444,
        -0.6100, -1.0911])
[2022-10-15 00:46:39,841] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 138, batch_idx: 0, global_img_step: 256, aug_ops:[('elastic transform', tensor([-0.8298])), ('Rotate', tensor([-0.3574])), ('Equalize', tensor([-0.3564]))]
[2022-10-15 00:46:39,841] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.013300	gLtNorm 0.0882 (0.0882)	gLvNorm 0.3141 (0.3141)	mvpNorm 0.1323 (0.1323)

[2022-10-15 00:47:36,129] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 138, batch_idx: 0, global_img_step: 257, aug_ops:[('ShearY', tensor([0.2674]))]
[2022-10-15 00:48:18,545] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 138	 Inner Train loss: 0.7237, acc=0.7326, lr=0.000000	
[2022-10-15 00:48:20,151] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 138	 Test loss: 1.0404, score: 0.6354
[2022-10-15 00:48:20,152] exp4_main.py->main line:277 [INFO]70% (139/200)
[2022-10-15 00:48:20,838] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.3946,   4.0202, -10.0339,   0.3312,  -2.0966,  -2.4849,  -5.3199,
         -3.0757,  -2.4849,  -0.7492,  -1.8271,  -1.7025,  -0.2748,  -2.5452,
         -8.4009])
[2022-10-15 00:48:20,839] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.7691, -1.4243, -0.7269,  0.5552, -2.3755, -1.1772, -0.6019,
        -0.4029,  0.1896, -0.5484,  1.2893, -0.2920, -1.1053,  1.3124,  0.9444,
        -0.6782, -1.0911])
[2022-10-15 00:48:20,992] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 139, batch_idx: 0, global_img_step: 258, aug_ops:[('contrast', tensor([0.3228])), ('saturation', tensor([-0.1547])), ('sharpen', tensor([0.4099])), ('Rotate', tensor([-0.2378])), ('Equalize', tensor([-0.2184]))]
[2022-10-15 00:48:20,992] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.012917	gLtNorm 0.5692 (0.5692)	gLvNorm 0.3864 (0.3864)	mvpNorm 0.1862 (0.1862)

[2022-10-15 00:49:17,283] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 139, batch_idx: 0, global_img_step: 259, aug_ops:[('gaussian noise', tensor([0.1061])), ('Rotate', tensor([0.1187]))]
[2022-10-15 00:49:59,715] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 139	 Inner Train loss: 0.6901, acc=0.7401, lr=0.000000	
[2022-10-15 00:50:01,334] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 139	 Test loss: 0.9934, score: 0.6482
[2022-10-15 00:50:01,335] exp4_main.py->main line:277 [INFO]70% (140/200)
[2022-10-15 00:50:02,015] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2723,  4.0155, -9.9102,  0.2022, -2.2248, -2.4849, -5.1919, -3.0757,
        -2.4849, -0.6591, -1.9263, -1.6536, -0.2202, -2.6744, -8.3960])
[2022-10-15 00:50:02,017] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.6405, -1.4243, -0.5977,  0.4260, -2.5046, -1.1772, -0.6019,
        -0.4029,  0.3187, -0.5484,  1.2893, -0.2920, -1.1053,  1.3124,  0.8152,
        -0.5493, -1.0911])
[2022-10-15 00:50:02,178] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 140, batch_idx: 0, global_img_step: 260, aug_ops:[('saturation', tensor([-0.3911])), ('gaussian noise', tensor([-0.1500]))]
[2022-10-15 00:50:02,179] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.012538	gLtNorm 3.8170 (3.8170)	gLvNorm 1.7363 (1.7363)	mvpNorm 7.6264 (7.6264)

[2022-10-15 00:50:58,498] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 140, batch_idx: 0, global_img_step: 261, aug_ops:[('contrast', tensor([0.1533])), ('gaussian noise', tensor([0.2553])), ('TranslateX', tensor([0.4049]))]
[2022-10-15 00:51:40,947] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 140	 Inner Train loss: 0.6721, acc=0.7462, lr=0.000000	
[2022-10-15 00:51:42,558] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 140	 Test loss: 0.9013, score: 0.6710
[2022-10-15 00:51:42,559] exp4_main.py->main line:277 [INFO]70% (141/200)
[2022-10-15 00:51:43,246] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.2252,  4.0088, -9.8616,  0.1675, -2.1678, -2.4849, -5.1952, -2.9546,
        -2.4849, -0.7834, -2.0073, -1.6428, -0.3221, -2.7167, -8.3949])
[2022-10-15 00:51:43,247] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.6465, -1.4243, -0.5838,  0.3528, -2.4741, -1.1772, -0.6019,
        -0.4029,  0.3187, -0.5484,  1.1655, -0.2920, -1.1053,  1.3124,  0.8152,
        -0.5493, -1.0911])
[2022-10-15 00:51:43,404] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 141, batch_idx: 0, global_img_step: 262, aug_ops:[('saturation', tensor([-0.3247])), ('sharpen', tensor([0.6156])), ('Equalize', tensor([-0.4527]))]
[2022-10-15 00:51:43,404] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.012162	gLtNorm 2.6942 (2.6942)	gLvNorm 4.3363 (4.3363)	mvpNorm 0.6237 (0.6237)

[2022-10-15 00:52:39,615] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 141, batch_idx: 0, global_img_step: 263, aug_ops:[('contrast', tensor([-0.1419])), ('Hsv', tensor([ 0.8971, -0.1348,  0.1442])), ('gaussian noise', tensor([0.2979])), ('Rotate', tensor([0.3427]))]
[2022-10-15 00:53:22,037] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 141	 Inner Train loss: 0.6539, acc=0.7467, lr=0.000000	
[2022-10-15 00:53:23,689] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 141	 Test loss: 0.8959, score: 0.6633
[2022-10-15 00:53:23,690] exp4_main.py->main line:277 [INFO]71% (142/200)
[2022-10-15 00:53:24,386] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.1881,  3.9939, -9.7944,  0.1835, -2.1673, -2.4849, -5.1975, -2.9638,
        -2.4849, -0.7788, -2.1064, -1.6438, -0.3103, -2.7156, -8.3938])
[2022-10-15 00:53:24,388] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.6619, -1.4243, -0.5748,  0.3547, -2.4762, -1.1772, -0.6019,
        -0.4029,  0.3187, -0.5484,  1.1833, -0.2920, -0.9837,  1.4337,  0.8152,
        -0.5493, -1.0911])
[2022-10-15 00:53:24,546] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 142, batch_idx: 0, global_img_step: 264, aug_ops:[('gaussian noise', tensor([0.9279])), ('elastic transform', tensor([0.3559])), ('ShearX', tensor([0.8390]))]
[2022-10-15 00:53:24,546] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.011790	gLtNorm 0.1309 (0.1309)	gLvNorm 0.2991 (0.2991)	mvpNorm 0.5897 (0.5897)

[2022-10-15 00:54:21,021] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 142, batch_idx: 0, global_img_step: 265, aug_ops:[('saturation', tensor([0.0949])), ('sharpen', tensor([0.4227])), ('gaussian noise', tensor([0.1358])), ('ShearX', tensor([0.0307])), ('Equalize', tensor([0.0543]))]
[2022-10-15 00:55:03,398] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 142	 Inner Train loss: 0.7238, acc=0.7328, lr=0.000000	
[2022-10-15 00:55:05,005] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 142	 Test loss: 0.8717, score: 0.6759
[2022-10-15 00:55:05,006] exp4_main.py->main line:277 [INFO]72% (143/200)
[2022-10-15 00:55:05,691] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.1896,  3.9989, -9.8027,  0.0761, -2.2840, -2.4849, -5.3154, -2.9638,
        -2.4849, -0.8967, -2.2230, -1.5259, -0.1933, -2.6667, -8.3942])
[2022-10-15 00:55:05,692] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.6578, -1.4243, -0.5748,  0.3547, -2.4762, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.3012, -0.2920, -0.9837,  1.4337,  0.8152,
        -0.4316, -1.0911])
[2022-10-15 00:55:05,821] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 143, batch_idx: 0, global_img_step: 266, aug_ops:[('brightness', tensor([-0.1414])), ('contrast', tensor([1.])), ('gaussian blur', tensor([-0.1429])), ('Rotate', tensor([0.4543]))]
[2022-10-15 00:55:05,821] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.011423	gLtNorm 0.2278 (0.2278)	gLvNorm 0.3545 (0.3545)	mvpNorm 0.4175 (0.4175)

[2022-10-15 00:56:02,293] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 143, batch_idx: 0, global_img_step: 267, aug_ops:[('saturation', tensor([0.5916])), ('Equalize', tensor([0.3948]))]
[2022-10-15 00:56:44,630] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 143	 Inner Train loss: 0.6882, acc=0.7427, lr=0.000000	
[2022-10-15 00:56:46,252] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 143	 Test loss: 0.7515, score: 0.7055
[2022-10-15 00:56:46,253] exp4_main.py->main line:277 [INFO]72% (144/200)
[2022-10-15 00:56:46,932] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-0.3019,  4.1130, -9.8926,  0.0285, -2.2941, -2.4849, -5.3154, -2.9638,
        -2.4849, -0.8956, -2.2100, -1.5261, -0.2914, -2.6663, -8.4164])
[2022-10-15 00:56:46,934] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.7681, -1.4243, -0.4623,  0.3132, -2.5378, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.3012, -0.2920, -0.9837,  1.4337,  0.8152,
        -0.4316, -1.0911])
[2022-10-15 00:56:47,039] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 144, batch_idx: 0, global_img_step: 268, aug_ops:[('contrast', tensor([-0.1719])), ('Hed', tensor([-0.3899, -0.1874, -0.5741]))]
[2022-10-15 00:56:47,040] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.011059	gLtNorm 0.1431 (0.1431)	gLvNorm 0.2659 (0.2659)	mvpNorm 0.1708 (0.1708)

[2022-10-15 00:57:43,385] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 144, batch_idx: 0, global_img_step: 269, aug_ops:[('contrast', tensor([0.1327])), ('TranslateX', tensor([0.1488]))]
[2022-10-15 00:58:25,853] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 144	 Inner Train loss: 0.7234, acc=0.7310, lr=0.000000	
[2022-10-15 00:58:27,479] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 144	 Test loss: 0.8838, score: 0.6770
[2022-10-15 00:58:27,480] exp4_main.py->main line:277 [INFO]72% (145/200)
[2022-10-15 00:58:28,159] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1951,   4.1656, -10.0025,   0.0359,  -2.3292,  -2.4849,  -5.3158,
         -2.9638,  -2.4849,  -0.9366,  -2.1285,  -1.5312,  -0.1811,  -2.6235,
         -8.4718])
[2022-10-15 00:58:28,161] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.2516, -0.8023, -1.4243, -0.4623,  0.3132, -2.5378, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.3012, -0.2920, -0.9837,  1.4337,  0.8152,
        -0.4316, -1.0911])
[2022-10-15 00:58:28,322] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 145, batch_idx: 0, global_img_step: 270, aug_ops:[('brightness', tensor([-0.3640])), ('contrast', tensor([-0.6520])), ('saturation', tensor([-0.4261])), ('gaussian noise', tensor([-1.])), ('Rotate', tensor([-0.4165])), ('Equalize', tensor([-0.3640]))]
[2022-10-15 00:58:28,322] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.010700	gLtNorm 2.7962 (2.7962)	gLvNorm 0.2097 (0.2097)	mvpNorm 4.2083 (4.2083)

[2022-10-15 00:59:24,665] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 145, batch_idx: 0, global_img_step: 271, aug_ops:[('saturation', tensor([0.1160])), ('TranslateX', tensor([0.1227])), ('TranslateY', tensor([0.3538]))]
[2022-10-15 01:00:07,059] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 145	 Inner Train loss: 0.7081, acc=0.7318, lr=0.000000	
[2022-10-15 01:00:08,683] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 145	 Test loss: 1.1249, score: 0.6300
[2022-10-15 01:00:08,684] exp4_main.py->main line:277 [INFO]73% (146/200)
[2022-10-15 01:00:09,376] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-9.5092e-02,  4.0591e+00, -1.0002e+01,  6.4547e-03, -2.4224e+00,
        -2.4849e+00, -5.3158e+00, -2.9638e+00, -2.4849e+00, -9.3726e-01,
        -2.1299e+00, -1.5294e+00, -1.8050e-01, -2.6732e+00, -8.3656e+00])
[2022-10-15 01:00:09,378] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1446, -0.6953, -1.4243, -0.4623,  0.2063, -2.4458, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.3012, -0.2920, -1.0906,  1.4337,  0.8152,
        -0.4009, -1.0911])
[2022-10-15 01:00:09,520] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 146, batch_idx: 0, global_img_step: 272, aug_ops:[('saturation', tensor([0.1686])), ('sharpen', tensor([0.1916])), ('elastic transform', tensor([0.1260])), ('TranslateX', tensor([0.1837])), ('Equalize', tensor([-0.2872]))]
[2022-10-15 01:00:09,521] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.010345	gLtNorm 0.7337 (0.7337)	gLvNorm 1.0818 (1.0818)	mvpNorm 1.6675 (1.6675)

[2022-10-15 01:01:05,909] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 146, batch_idx: 0, global_img_step: 273, aug_ops:[('saturation', tensor([-0.2535])), ('gaussian noise', tensor([-0.0837])), ('ShearX', tensor([-0.2007])), ('ShearY', tensor([-0.5463]))]
[2022-10-15 01:01:48,241] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 146	 Inner Train loss: 0.7388, acc=0.7218, lr=0.000000	
[2022-10-15 01:01:49,873] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 146	 Test loss: 1.1656, score: 0.6113
[2022-10-15 01:01:49,874] exp4_main.py->main line:277 [INFO]74% (147/200)
[2022-10-15 01:01:50,553] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0855,   4.0622, -10.0771,  -0.0102,  -2.4258,  -2.4849,  -5.3158,
         -2.9638,  -2.4849,  -0.9531,  -2.0733,  -1.5303,  -0.1812,  -2.6685,
         -8.4423])
[2022-10-15 01:01:50,555] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1446, -0.6959, -1.4243, -0.5201,  0.2087, -2.3880, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.2179, -0.2920, -1.0906,  1.4337,  0.8152,
        -0.3933, -1.0911])
[2022-10-15 01:01:50,669] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 147, batch_idx: 0, global_img_step: 274, aug_ops:[('contrast', tensor([0.9766])), ('saturation', tensor([-0.4245]))]
[2022-10-15 01:01:50,669] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.009995	gLtNorm 0.5838 (0.5838)	gLvNorm 0.2565 (0.2565)	mvpNorm 0.1286 (0.1286)

[2022-10-15 01:02:47,063] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 147, batch_idx: 0, global_img_step: 275, aug_ops:[('brightness', tensor([0.1138])), ('contrast', tensor([0.4535])), ('saturation', tensor([-0.3233])), ('Hed', tensor([0.2898, 0.1035, 0.3961])), ('elastic transform', tensor([0.4504])), ('TranslateX', tensor([0.2802]))]
[2022-10-15 01:03:29,387] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 147	 Inner Train loss: 0.7138, acc=0.7318, lr=0.000000	
[2022-10-15 01:03:30,999] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 147	 Test loss: 0.9125, score: 0.6688
[2022-10-15 01:03:31,000] exp4_main.py->main line:277 [INFO]74% (148/200)
[2022-10-15 01:03:31,683] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0855,   4.0622, -10.0771,  -0.1035,  -2.3789,  -2.4849,  -5.3157,
         -2.9638,  -2.4849,  -0.9897,  -2.0099,  -1.5289,  -0.1812,  -2.6645,
         -8.4423])
[2022-10-15 01:03:31,684] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.1446, -0.6959, -1.4243, -0.5201,  0.2950, -2.3770, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.2179, -0.2920, -1.0906,  1.4337,  0.8152,
        -0.3933, -1.0911])
[2022-10-15 01:03:31,856] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 148, batch_idx: 0, global_img_step: 276, aug_ops:[('contrast', tensor([0.0173])), ('saturation', tensor([0.9624])), ('Rotate', tensor([-0.0008])), ('ShearX', tensor([-0.5284])), ('Equalize', tensor([-0.5372]))]
[2022-10-15 01:03:31,856] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.009649	gLtNorm 3.1153 (3.1153)	gLvNorm 0.6483 (0.6483)	mvpNorm 2.9937 (2.9937)

[2022-10-15 01:04:28,302] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 148, batch_idx: 0, global_img_step: 277, aug_ops:[('contrast', tensor([-0.6515])), ('saturation', tensor([-0.3779])), ('Hed', tensor([-0.3564, -0.5885, -0.7211])), ('Rotate', tensor([-0.4828])), ('ShearX', tensor([-0.6045])), ('Equalize', tensor([-0.4333]))]
[2022-10-15 01:05:10,800] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 148	 Inner Train loss: 0.7002, acc=0.7309, lr=0.000000	
[2022-10-15 01:05:12,428] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 148	 Test loss: 1.1255, score: 0.6222
[2022-10-15 01:05:12,429] exp4_main.py->main line:277 [INFO]74% (149/200)
[2022-10-15 01:05:13,120] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.0108,  4.0560, -9.9810, -0.0128, -2.4692, -2.4849, -5.3160, -2.9638,
        -2.4849, -1.0849, -1.9134, -1.4332, -0.2776, -2.7608, -8.3482])
[2022-10-15 01:05:13,121] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0485, -0.7611, -1.4243, -0.5201,  0.2950, -2.3770, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.2179, -0.2920, -1.0906,  1.4337,  0.7192,
        -0.3933, -1.0911])
[2022-10-15 01:05:13,271] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 149, batch_idx: 0, global_img_step: 278, aug_ops:[('brightness', tensor([0.4121])), ('saturation', tensor([0.4420])), ('Hed', tensor([0.4701, 0.8397, 0.3265])), ('sharpen', tensor([0.7485])), ('TranslateX', tensor([0.2627]))]
[2022-10-15 01:05:13,271] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.009308	gLtNorm 0.0093 (0.0093)	gLvNorm 0.0171 (0.0171)	mvpNorm 0.0048 (0.0048)

[2022-10-15 01:06:09,626] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 149, batch_idx: 0, global_img_step: 279, aug_ops:[('TranslateY', tensor([0.2676])), ('ShearY', tensor([-0.0545]))]
[2022-10-15 01:06:52,019] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 149	 Inner Train loss: 0.7373, acc=0.7228, lr=0.000000	
[2022-10-15 01:06:53,664] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 149	 Test loss: 0.9100, score: 0.6632
[2022-10-15 01:06:53,665] exp4_main.py->main line:277 [INFO]75% (150/200)
[2022-10-15 01:06:54,350] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.0154,  4.0378, -9.8888,  0.0149, -2.4752, -2.4849, -5.3128, -2.9638,
        -2.4849, -1.0960, -1.8724, -1.4339, -0.2808, -2.8436, -8.3168])
[2022-10-15 01:06:54,352] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0205, -0.7021, -1.4243, -0.4271,  0.3249, -2.4695, -1.1772, -0.6019,
        -0.4029,  0.2116, -0.4305,  1.2179, -0.2920, -1.0906,  1.3406,  0.7192,
        -0.3933, -1.0911])
[2022-10-15 01:06:54,463] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 150, batch_idx: 0, global_img_step: 280, aug_ops:[('contrast', tensor([0.0294])), ('TranslateY', tensor([-0.0193])), ('ShearX', tensor([-1.])), ('ShearY', tensor([0.0177]))]
[2022-10-15 01:06:54,463] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.008971	gLtNorm 0.2518 (0.2518)	gLvNorm 6.4062 (6.4062)	mvpNorm 7.6825 (7.6825)

[2022-10-15 01:07:50,829] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 150, batch_idx: 0, global_img_step: 281, aug_ops:[('saturation', tensor([-0.3773])), ('Hsv', tensor([ 0.2557,  1.0000, -0.1127])), ('Hed', tensor([ 0.2240, -0.5890,  0.0520])), ('sharpen', tensor([0.2434])), ('TranslateX', tensor([0.2486])), ('ShearY', tensor([0.0756])), ('Equalize', tensor([-0.0164]))]
[2022-10-15 01:08:33,440] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 150	 Inner Train loss: 0.7004, acc=0.7365, lr=0.000000	
[2022-10-15 01:08:35,047] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 150	 Test loss: 0.9391, score: 0.6566
[2022-10-15 01:08:35,048] exp4_main.py->main line:277 [INFO]76% (151/200)
[2022-10-15 01:08:35,714] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.0931,  4.1375, -9.9454,  0.1048, -2.4288, -2.4849, -5.2830, -2.9638,
        -2.4849, -1.0587, -1.8555, -1.4132, -0.2770, -2.7505, -8.4229])
[2022-10-15 01:08:35,715] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0205, -0.7814, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2318, -0.2920, -1.0906,  1.3406,  0.7192,
        -0.4240, -1.0911])
[2022-10-15 01:08:35,827] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 151, batch_idx: 0, global_img_step: 282, aug_ops:[('brightness', tensor([0.1805])), ('saturation', tensor([0.6011]))]
[2022-10-15 01:08:35,827] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.008640	gLtNorm 3.6724 (3.6724)	gLvNorm 0.2123 (0.2123)	mvpNorm 2.5994 (2.5994)

[2022-10-15 01:09:32,288] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 151, batch_idx: 0, global_img_step: 283, aug_ops:[('Hsv', tensor([-0.3077,  0.3846, -0.2005])), ('sharpen', tensor([-0.5021])), ('TranslateX', tensor([-0.0385]))]
[2022-10-15 01:10:14,753] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 151	 Inner Train loss: 0.6965, acc=0.7386, lr=0.000000	
[2022-10-15 01:10:16,382] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 151	 Test loss: 0.8678, score: 0.6764
[2022-10-15 01:10:16,383] exp4_main.py->main line:277 [INFO]76% (152/200)
[2022-10-15 01:10:17,068] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 0.0931,  4.1375, -9.9454,  0.1048, -2.4288, -2.4849, -5.2830, -2.9638,
        -2.4849, -1.0587, -1.8555, -1.4132, -0.2770, -2.7505, -8.4229])
[2022-10-15 01:10:17,070] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0205, -0.7814, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2318, -0.2920, -1.0906,  1.3406,  0.7192,
        -0.4240, -1.0911])
[2022-10-15 01:10:17,301] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 152, batch_idx: 0, global_img_step: 284, aug_ops:[('contrast', tensor([0.0544])), ('saturation', tensor([0.2133])), ('gaussian noise', tensor([0.2561])), ('TranslateY', tensor([0.0346])), ('ShearY', tensor([0.2401])), ('Equalize', tensor([0.2840]))]
[2022-10-15 01:10:17,301] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.008313	gLtNorm 0.0866 (0.0866)	gLvNorm 0.3534 (0.3534)	mvpNorm 0.1871 (0.1871)

[2022-10-15 01:11:13,603] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 152, batch_idx: 0, global_img_step: 285, aug_ops:[('contrast', tensor([0.2815])), ('TranslateX', tensor([-0.0033])), ('ShearY', tensor([-0.0075]))]
[2022-10-15 01:11:55,956] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 152	 Inner Train loss: 0.7001, acc=0.7362, lr=0.000000	
[2022-10-15 01:11:57,566] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 152	 Test loss: 0.9469, score: 0.6594
[2022-10-15 01:11:57,567] exp4_main.py->main line:277 [INFO]76% (153/200)
[2022-10-15 01:11:58,253] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([  0.0664,   4.1787, -10.0069,   0.1841,  -2.3476,  -2.4849,  -5.2841,
         -2.9638,  -2.4849,  -1.0100,  -1.8938,  -1.3795,  -0.2717,  -2.7573,
         -8.4252])
[2022-10-15 01:11:58,255] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0205, -0.7150, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2090, -0.2920, -1.0906,  1.3406,  0.7192,
        -0.4074, -1.0911])
[2022-10-15 01:11:58,408] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 153, batch_idx: 0, global_img_step: 286, aug_ops:[('saturation', tensor([1.])), ('gaussian blur', tensor([0.2663])), ('sharpen', tensor([-0.5350])), ('ShearX', tensor([0.8543]))]
[2022-10-15 01:11:58,408] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.007992	gLtNorm 0.2671 (0.2671)	gLvNorm 1.0112 (1.0112)	mvpNorm 1.5049 (1.5049)

[2022-10-15 01:12:54,747] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 153, batch_idx: 0, global_img_step: 287, aug_ops:[('brightness', tensor([0.2977])), ('ShearY', tensor([0.0850])), ('Equalize', tensor([0.2977]))]
[2022-10-15 01:13:37,125] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 153	 Inner Train loss: 0.6955, acc=0.7409, lr=0.000000	
[2022-10-15 01:13:38,770] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 153	 Test loss: 0.9037, score: 0.6771
[2022-10-15 01:13:38,771] exp4_main.py->main line:277 [INFO]77% (154/200)
[2022-10-15 01:13:39,469] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0102,   4.2312, -10.0867,   0.1497,  -2.4231,  -2.4849,  -5.3003,
         -2.9638,  -2.4849,  -0.9311,  -1.9726,  -1.3106,  -0.1965,  -2.6853,
         -8.4762])
[2022-10-15 01:13:39,471] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0205, -0.6491, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2090, -0.2920, -1.0906,  1.3406,  0.7991,
        -0.4074, -1.0911])
[2022-10-15 01:13:39,633] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 154, batch_idx: 0, global_img_step: 288, aug_ops:[('contrast', tensor([-0.1426])), ('Rotate', tensor([0.0444])), ('Equalize', tensor([-0.6406]))]
[2022-10-15 01:13:39,634] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.007676	gLtNorm 0.0312 (0.0312)	gLvNorm 0.3078 (0.3078)	mvpNorm 0.2348 (0.2348)

[2022-10-15 01:14:36,047] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 154, batch_idx: 0, global_img_step: 289, aug_ops:[('contrast', tensor([0.4247])), ('saturation', tensor([-0.2092])), ('Hed', tensor([0.2434, 0.1051, 0.4029])), ('Rotate', tensor([0.0941])), ('TranslateX', tensor([0.0956])), ('TranslateY', tensor([0.3454]))]
[2022-10-15 01:15:18,508] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 154	 Inner Train loss: 0.6783, acc=0.7420, lr=0.000000	
[2022-10-15 01:15:20,140] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 154	 Test loss: 1.0553, score: 0.6357
[2022-10-15 01:15:20,141] exp4_main.py->main line:277 [INFO]78% (155/200)
[2022-10-15 01:15:20,827] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([  0.0104,   4.3079, -10.0872,   0.1499,  -2.3613,  -2.4849,  -5.2694,
         -2.9638,  -2.4849,  -0.9897,  -1.9432,  -1.2362,  -0.1888,  -2.7180,
         -8.5216])
[2022-10-15 01:15:20,829] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9449, -0.5821, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2090, -0.2920, -1.0906,  1.3406,  0.8756,
        -0.4074, -1.0911])
[2022-10-15 01:15:21,010] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 155, batch_idx: 0, global_img_step: 290, aug_ops:[('gaussian noise', tensor([0.1526])), ('ShearX', tensor([0.1500])), ('Equalize', tensor([-0.3623]))]
[2022-10-15 01:15:21,010] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.007365	gLtNorm 0.4199 (0.4199)	gLvNorm 1.5652 (1.5652)	mvpNorm 0.9026 (0.9026)

[2022-10-15 01:16:17,202] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 155, batch_idx: 0, global_img_step: 291, aug_ops:[('gaussian blur', tensor([-0.3316])), ('Equalize', tensor([-0.5169]))]
[2022-10-15 01:16:59,482] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 155	 Inner Train loss: 0.7147, acc=0.7330, lr=0.000000	
[2022-10-15 01:17:01,097] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 155	 Test loss: 0.9599, score: 0.6632
[2022-10-15 01:17:01,098] exp4_main.py->main line:277 [INFO]78% (156/200)
[2022-10-15 01:17:01,783] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([  0.0104,   4.3079, -10.0872,   0.1499,  -2.3613,  -2.4849,  -5.2735,
         -2.9638,  -2.4849,  -0.9879,  -1.8790,  -1.2848,  -0.2399,  -2.7050,
         -8.5216])
[2022-10-15 01:17:01,785] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9449, -0.5821, -1.4243, -0.4266,  0.3459, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2090, -0.2920, -1.0906,  1.3406,  0.8756,
        -0.4074, -1.0911])
[2022-10-15 01:17:01,893] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 156, batch_idx: 0, global_img_step: 292, aug_ops:[('contrast', tensor([0.4560])), ('ShearX', tensor([1.])), ('Equalize', tensor([0.6331]))]
[2022-10-15 01:17:01,893] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.007059	gLtNorm 37.9011 (37.9011)	gLvNorm 0.3002 (0.3002)	mvpNorm 41.1230 (41.1230)

[2022-10-15 01:17:58,085] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 156, batch_idx: 0, global_img_step: 293, aug_ops:[('saturation', tensor([-0.2980])), ('sharpen', tensor([-0.1156])), ('Equalize', tensor([-0.2363]))]
[2022-10-15 01:18:40,361] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 156	 Inner Train loss: 0.7212, acc=0.7311, lr=0.000000	
[2022-10-15 01:18:41,993] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 156	 Test loss: 0.9163, score: 0.6626
[2022-10-15 01:18:41,994] exp4_main.py->main line:277 [INFO]78% (157/200)
[2022-10-15 01:18:42,679] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0495,   4.2375, -10.0167,   0.1830,  -2.2922,  -2.4849,  -5.2029,
         -2.9638,  -2.4849,  -0.9886,  -1.8786,  -1.2857,  -0.2367,  -2.7388,
         -8.5146])
[2022-10-15 01:18:42,680] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0145, -0.6495, -1.4243, -0.4857,  0.4163, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2090, -0.2920, -1.1611,  1.3406,  0.8756,
        -0.4074, -1.1617])
[2022-10-15 01:18:42,851] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 157, batch_idx: 0, global_img_step: 294, aug_ops:[('Hsv', tensor([ 0.0090, -0.2677, -0.0994])), ('gaussian noise', tensor([-0.4313])), ('Equalize', tensor([0.5294]))]
[2022-10-15 01:18:42,851] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.006759	gLtNorm 1.0879 (1.0879)	gLvNorm 2.6919 (2.6919)	mvpNorm 1.8476 (1.8476)

[2022-10-15 01:19:39,070] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 157, batch_idx: 0, global_img_step: 295, aug_ops:[('contrast', tensor([0.6565])), ('saturation', tensor([0.4337]))]
[2022-10-15 01:20:21,428] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 157	 Inner Train loss: 0.7696, acc=0.7192, lr=0.000000	
[2022-10-15 01:20:23,039] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 157	 Test loss: 0.8309, score: 0.6819
[2022-10-15 01:20:23,040] exp4_main.py->main line:277 [INFO]79% (158/200)
[2022-10-15 01:20:23,725] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0998,   4.2622, -10.0337,   0.2498,  -2.2251,  -2.4849,  -5.1993,
         -3.0314,  -2.4849,  -0.9988,  -1.9370,  -1.3226,  -0.2000,  -2.6755,
         -8.5822])
[2022-10-15 01:20:23,727] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0820, -0.7164, -1.4243, -0.4857,  0.4163, -2.4695, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2655, -0.3596, -1.0935,  1.3406,  0.8756,
        -0.4074, -1.1617])
[2022-10-15 01:20:23,931] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 158, batch_idx: 0, global_img_step: 296, aug_ops:[('contrast', tensor([-0.0269])), ('saturation', tensor([0.1383])), ('TranslateY', tensor([0.4401]))]
[2022-10-15 01:20:23,932] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.006465	gLtNorm 0.8293 (0.8293)	gLvNorm 0.2569 (0.2569)	mvpNorm 1.8237 (1.8237)

[2022-10-15 01:21:20,240] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 158, batch_idx: 0, global_img_step: 297, aug_ops:[('contrast', tensor([0.0555])), ('Hsv', tensor([ 0.5156, -0.0812,  0.4614])), ('Rotate', tensor([-0.2754])), ('TranslateX', tensor([0.3490]))]
[2022-10-15 01:22:02,671] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 158	 Inner Train loss: 0.6829, acc=0.7419, lr=0.000000	
[2022-10-15 01:22:04,282] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 158	 Test loss: 0.8787, score: 0.6832
[2022-10-15 01:22:04,282] exp4_main.py->main line:277 [INFO]80% (159/200)
[2022-10-15 01:22:04,969] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1631,   4.2818, -10.0456,   0.3136,  -2.2009,  -2.4849,  -5.1894,
         -3.0314,  -2.4849,  -1.0632,  -1.9182,  -1.3871,  -0.2646,  -2.6108,
         -8.5838])
[2022-10-15 01:22:04,971] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0820, -0.7806, -1.4243, -0.5503,  0.3517, -2.4712, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2008, -0.3596, -1.0935,  1.2759,  0.8756,
        -0.4074, -1.1617])
[2022-10-15 01:22:05,199] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 159, batch_idx: 0, global_img_step: 298, aug_ops:[('contrast', tensor([-0.0054])), ('sharpen', tensor([-0.9160])), ('Equalize', tensor([0.1002]))]
[2022-10-15 01:22:05,199] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.006176	gLtNorm 0.3908 (0.3908)	gLvNorm 0.1968 (0.1968)	mvpNorm 0.1085 (0.1085)

[2022-10-15 01:23:01,549] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 159, batch_idx: 0, global_img_step: 299, aug_ops:[('saturation', tensor([-0.4018])), ('Hsv', tensor([ 0.1837, -0.3017,  0.0179])), ('TranslateX', tensor([-0.1960])), ('TranslateY', tensor([-0.0613]))]
[2022-10-15 01:23:44,002] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 159	 Inner Train loss: 0.7321, acc=0.7265, lr=0.000000	
[2022-10-15 01:23:45,619] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 159	 Test loss: 1.1129, score: 0.6278
[2022-10-15 01:23:45,620] exp4_main.py->main line:277 [INFO]80% (160/200)
[2022-10-15 01:23:46,305] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1044,   4.2204, -10.0460,   0.3413,  -2.2036,  -2.4849,  -5.1885,
         -3.0314,  -2.4849,  -1.0756,  -1.9344,  -1.3864,  -0.2646,  -2.6108,
         -8.5424])
[2022-10-15 01:23:46,307] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0466, -0.7806, -1.4243, -0.5271,  0.3468, -2.5329, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2008, -0.3596, -1.1412,  1.2781,  0.8756,
        -0.3459, -1.1617])
[2022-10-15 01:23:46,452] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 160, batch_idx: 0, global_img_step: 300, aug_ops:[('brightness', tensor([0.3967])), ('saturation', tensor([-0.5306])), ('TranslateY', tensor([0.4284])), ('Equalize', tensor([0.3967]))]
[2022-10-15 01:23:46,453] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.005893	gLtNorm 0.1640 (0.1640)	gLvNorm 0.1762 (0.1762)	mvpNorm 0.5195 (0.5195)

[2022-10-15 01:24:42,716] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 160, batch_idx: 0, global_img_step: 301, aug_ops:[('contrast', tensor([0.7460])), ('saturation', tensor([0.3615])), ('gaussian noise', tensor([-0.8695]))]
[2022-10-15 01:25:25,003] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 160	 Inner Train loss: 0.6907, acc=0.7400, lr=0.000000	
[2022-10-15 01:25:26,612] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 160	 Test loss: 0.8817, score: 0.6766
[2022-10-15 01:25:26,613] exp4_main.py->main line:277 [INFO]80% (161/200)
[2022-10-15 01:25:27,313] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1469,   4.2242, -10.0519,   0.3962,  -2.2486,  -2.4849,  -5.1300,
         -3.0314,  -2.4849,  -1.0501,  -1.9928,  -1.3398,  -0.2136,  -2.5537,
         -8.5427])
[2022-10-15 01:25:27,315] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0466, -0.7838, -1.4243, -0.5271,  0.3468, -2.5329, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2008, -0.3596, -1.1412,  1.2781,  0.8756,
        -0.3459, -1.1617])
[2022-10-15 01:25:27,412] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 161, batch_idx: 0, global_img_step: 302, aug_ops:[('contrast', tensor([-0.0447]))]
[2022-10-15 01:25:27,412] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.005616	gLtNorm 0.0640 (0.0640)	gLvNorm 0.2258 (0.2258)	mvpNorm 0.2802 (0.2802)

[2022-10-15 01:26:23,849] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 161, batch_idx: 0, global_img_step: 303, aug_ops:[('contrast', tensor([0.3790])), ('gaussian noise', tensor([0.1830])), ('ShearY', tensor([0.2839]))]
[2022-10-15 01:27:06,249] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 161	 Inner Train loss: 0.6877, acc=0.7401, lr=0.000000	
[2022-10-15 01:27:07,855] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 161	 Test loss: 0.9910, score: 0.6485
[2022-10-15 01:27:07,856] exp4_main.py->main line:277 [INFO]81% (162/200)
[2022-10-15 01:27:08,540] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1988,   4.2227, -10.0294,   0.3587,  -2.1956,  -2.4849,  -5.1288,
         -3.0314,  -2.4849,  -1.0997,  -1.9929,  -1.3443,  -0.2161,  -2.5497,
         -8.5423])
[2022-10-15 01:27:08,542] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.7679, -1.4243, -0.5374,  0.3074, -2.5329, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2008, -0.3596, -1.0917,  1.2781,  0.8756,
        -0.3459, -1.2178])
[2022-10-15 01:27:08,772] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 162, batch_idx: 0, global_img_step: 304, aug_ops:[('gaussian blur', tensor([0.2041]))]
[2022-10-15 01:27:08,772] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.005344	gLtNorm 0.5373 (0.5373)	gLvNorm 0.2072 (0.2072)	mvpNorm 0.2389 (0.2389)

[2022-10-15 01:28:05,158] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 162, batch_idx: 0, global_img_step: 305, aug_ops:[('brightness', tensor([0.2264])), ('saturation', tensor([0.2459])), ('Hsv', tensor([-1.0000,  0.8161,  0.2620])), ('sharpen', tensor([0.8657])), ('gaussian noise', tensor([0.5209])), ('Equalize', tensor([0.2264]))]
[2022-10-15 01:28:47,583] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 162	 Inner Train loss: 0.6820, acc=0.7406, lr=0.000000	
[2022-10-15 01:28:49,207] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 162	 Test loss: 0.9273, score: 0.6568
[2022-10-15 01:28:49,208] exp4_main.py->main line:277 [INFO]82% (163/200)
[2022-10-15 01:28:49,897] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.2021,   4.2228, -10.0609,   0.3860,  -2.1925,  -2.4849,  -5.1322,
         -3.0314,  -2.4849,  -1.1090,  -1.9406,  -1.3972,  -0.2185,  -2.5381,
         -8.5423])
[2022-10-15 01:28:49,898] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.7701, -1.4243, -0.5374,  0.3074, -2.5329, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.4305,  1.2542, -0.3596, -1.0917,  1.2781,  0.8756,
        -0.3459, -1.2178])
[2022-10-15 01:28:50,039] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 163, batch_idx: 0, global_img_step: 306, aug_ops:[('contrast', tensor([-0.3768])), ('saturation', tensor([0.2392])), ('Rotate', tensor([0.1282])), ('TranslateY', tensor([-0.1009]))]
[2022-10-15 01:28:50,040] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.005079	gLtNorm 0.3170 (0.3170)	gLvNorm 2.8100 (2.8100)	mvpNorm 3.7105 (3.7105)

[2022-10-15 01:29:46,369] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 163, batch_idx: 0, global_img_step: 307, aug_ops:[('saturation', tensor([-0.4601])), ('Hsv', tensor([-0.1273, -0.4576, -1.0000])), ('Hed', tensor([-0.4890, -0.2132, -0.2018])), ('gaussian noise', tensor([-0.0270])), ('Rotate', tensor([1.])), ('TranslateY', tensor([0.4221])), ('Equalize', tensor([-0.1963]))]
[2022-10-15 01:30:28,685] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 163	 Inner Train loss: 0.7265, acc=0.7273, lr=0.000000	
[2022-10-15 01:30:30,288] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 163	 Test loss: 0.9552, score: 0.6428
[2022-10-15 01:30:30,289] exp4_main.py->main line:277 [INFO]82% (164/200)
[2022-10-15 01:30:30,981] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.2023,   4.2278, -10.0784,   0.3970,  -2.1935,  -2.4849,  -5.1364,
         -3.0314,  -2.4849,  -1.0958,  -1.9407,  -1.3962,  -0.2186,  -2.5355,
         -8.5425])
[2022-10-15 01:30:30,983] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9884, -0.7666, -1.4243, -0.5322,  0.3407, -2.4821, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.3797,  1.2542, -0.3596, -1.0917,  1.2781,  0.8756,
        -0.3659, -1.2178])
[2022-10-15 01:30:31,082] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 164, batch_idx: 0, global_img_step: 308, aug_ops:[('brightness', tensor([0.1898])), ('contrast', tensor([0.7024]))]
[2022-10-15 01:30:31,083] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.004820	gLtNorm 6.1635 (6.1635)	gLvNorm 0.6467 (0.6467)	mvpNorm 9.3513 (9.3513)

[2022-10-15 01:31:27,399] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 164, batch_idx: 0, global_img_step: 309, aug_ops:[('gaussian noise', tensor([-0.6594])), ('Equalize', tensor([0.3804]))]
[2022-10-15 01:32:09,969] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 164	 Inner Train loss: 0.6539, acc=0.7528, lr=0.000000	
[2022-10-15 01:32:11,573] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 164	 Test loss: 0.7845, score: 0.7014
[2022-10-15 01:32:11,573] exp4_main.py->main line:277 [INFO]82% (165/200)
[2022-10-15 01:32:12,261] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1579,   4.2280, -10.1260,   0.3497,  -2.1483,  -2.4849,  -5.1178,
         -3.0314,  -2.4849,  -1.0478,  -1.9869,  -1.3974,  -0.1716,  -2.5348,
         -8.5462])
[2022-10-15 01:32:12,263] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0364, -0.8143, -1.4243, -0.5797,  0.3888, -2.4821, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.3797,  1.2542, -0.3596, -1.0435,  1.2781,  0.8756,
        -0.3659, -1.2178])
[2022-10-15 01:32:12,372] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 165, batch_idx: 0, global_img_step: 310, aug_ops:[('contrast', tensor([-0.2278])), ('TranslateY', tensor([-0.2300])), ('ShearY', tensor([0.2814]))]
[2022-10-15 01:32:12,372] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.004567	gLtNorm 5.5600 (5.5600)	gLvNorm 0.5291 (0.5291)	mvpNorm 9.3758 (9.3758)

[2022-10-15 01:33:08,709] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 165, batch_idx: 0, global_img_step: 311, aug_ops:[('Hsv', tensor([-0.2584, -0.3161, -0.3507])), ('gaussian noise', tensor([-0.2561])), ('Rotate', tensor([-0.1002])), ('ShearX', tensor([-0.6875])), ('Equalize', tensor([1.]))]
[2022-10-15 01:33:51,064] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 165	 Inner Train loss: 0.6704, acc=0.7449, lr=0.000000	
[2022-10-15 01:33:52,703] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 165	 Test loss: 0.9972, score: 0.6511
[2022-10-15 01:33:52,704] exp4_main.py->main line:277 [INFO]83% (166/200)
[2022-10-15 01:33:53,403] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1133,   4.2679, -10.1577,   0.3050,  -2.1364,  -2.4849,  -5.0913,
         -3.0314,  -2.4849,  -1.0021,  -1.9787,  -1.4430,  -0.1380,  -2.5805,
         -8.5658])
[2022-10-15 01:33:53,405] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0364, -0.7796, -1.4243, -0.6204,  0.3750, -2.4821, -1.2636, -0.5155,
        -0.4893,  0.2116, -0.3797,  1.2542, -0.3596, -1.0435,  1.2781,  0.8756,
        -0.3202, -1.2178])
[2022-10-15 01:33:53,547] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 166, batch_idx: 0, global_img_step: 312, aug_ops:[('saturation', tensor([0.4870])), ('gaussian blur', tensor([0.3682])), ('Equalize', tensor([0.6969]))]
[2022-10-15 01:33:53,547] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.004320	gLtNorm 0.2399 (0.2399)	gLvNorm 1.9095 (1.9095)	mvpNorm 2.0126 (2.0126)

[2022-10-15 01:34:49,816] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 166, batch_idx: 0, global_img_step: 313, aug_ops:[('saturation', tensor([-0.1221])), ('gaussian noise', tensor([-0.2069])), ('Rotate', tensor([-0.0754])), ('ShearX', tensor([-0.2845])), ('Equalize', tensor([-0.1807]))]
[2022-10-15 01:35:32,188] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 166	 Inner Train loss: 0.6983, acc=0.7374, lr=0.000000	
[2022-10-15 01:35:33,791] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 166	 Test loss: 0.8216, score: 0.6828
[2022-10-15 01:35:33,792] exp4_main.py->main line:277 [INFO]84% (167/200)
[2022-10-15 01:35:34,463] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.1034,   4.3089, -10.1730,   0.3463,  -2.1622,  -2.4849,  -5.1342,
         -3.0314,  -2.4849,  -1.0028,  -1.9808,  -1.4450,  -0.1377,  -2.5805,
         -8.5883])
[2022-10-15 01:35:34,465] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0364, -0.8129, -1.4243, -0.6204,  0.3750, -2.4821, -1.2636, -0.5155,
        -0.4893,  0.1684, -0.3797,  1.2542, -0.3596, -1.0435,  1.2781,  0.8324,
        -0.3194, -1.2178])
[2022-10-15 01:35:34,661] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 167, batch_idx: 0, global_img_step: 314, aug_ops:[('contrast', tensor([-0.2817])), ('saturation', tensor([-0.4349])), ('gaussian blur', tensor([-0.7564])), ('gaussian noise', tensor([-0.8732]))]
[2022-10-15 01:35:34,661] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.004079	gLtNorm 0.4152 (0.4152)	gLvNorm 0.0505 (0.0505)	mvpNorm 0.4077 (0.4077)

[2022-10-15 01:36:30,963] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 167, batch_idx: 0, global_img_step: 315, aug_ops:[('contrast', tensor([-0.3694])), ('saturation', tensor([0.1052])), ('gaussian noise', tensor([-0.3995])), ('TranslateY', tensor([-0.4040]))]
[2022-10-15 01:37:13,485] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 167	 Inner Train loss: 0.6646, acc=0.7488, lr=0.000000	
[2022-10-15 01:37:15,102] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 167	 Test loss: 0.8841, score: 0.6758
[2022-10-15 01:37:15,103] exp4_main.py->main line:277 [INFO]84% (168/200)
[2022-10-15 01:37:15,784] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0742,   4.3468, -10.1832,   0.3522,  -2.1987,  -2.4849,  -5.1441,
         -3.0314,  -2.4849,  -1.0035,  -1.9646,  -1.4496,  -0.1782,  -2.5645,
         -8.6106])
[2022-10-15 01:37:15,786] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0364, -0.7901, -1.4243, -0.6290,  0.3803, -2.4821, -1.2636, -0.5155,
        -0.4893,  0.1684, -0.3797,  1.2513, -0.3596, -1.0435,  1.2781,  0.8324,
        -0.3194, -1.2178])
[2022-10-15 01:37:16,041] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 168, batch_idx: 0, global_img_step: 316, aug_ops:[('contrast', tensor([-0.2104])), ('saturation', tensor([-0.1391])), ('elastic transform', tensor([-0.5496])), ('Rotate', tensor([0.0378])), ('ShearY', tensor([-1.]))]
[2022-10-15 01:37:16,041] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.003845	gLtNorm 0.2645 (0.2645)	gLvNorm 0.0695 (0.0695)	mvpNorm 0.4888 (0.4888)

[2022-10-15 01:38:12,373] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 168, batch_idx: 0, global_img_step: 317, aug_ops:[('contrast', tensor([0.0069])), ('Hsv', tensor([ 0.4462, -0.0952,  0.2828])), ('Hed', tensor([ 0.2151,  0.0547, -0.7969])), ('TranslateY', tensor([-0.0959]))]
[2022-10-15 01:38:54,933] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 168	 Inner Train loss: 0.7362, acc=0.7266, lr=0.000000	
[2022-10-15 01:38:56,555] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 168	 Test loss: 0.8558, score: 0.6756
[2022-10-15 01:38:56,556] exp4_main.py->main line:277 [INFO]84% (169/200)
[2022-10-15 01:38:57,227] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0488,   4.3560, -10.1924,   0.3510,  -2.1837,  -2.4849,  -5.1124,
         -3.0314,  -2.4849,  -1.0052,  -1.9287,  -1.4490,  -0.1775,  -2.5678,
         -8.6107])
[2022-10-15 01:38:57,229] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0193, -0.8112, -1.4243, -0.6290,  0.3803, -2.4821, -1.2636, -0.5155,
        -0.5277,  0.1684, -0.3797,  1.2513, -0.3596, -1.0435,  1.2781,  0.8324,
        -0.3194, -1.2178])
[2022-10-15 01:38:57,341] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 169, batch_idx: 0, global_img_step: 318, aug_ops:[('contrast', tensor([-0.3978])), ('ShearY', tensor([-0.4308]))]
[2022-10-15 01:38:57,341] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.003617	gLtNorm 1.7178 (1.7178)	gLvNorm 0.2433 (0.2433)	mvpNorm 1.8422 (1.8422)

[2022-10-15 01:39:53,590] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 169, batch_idx: 0, global_img_step: 319, aug_ops:[('Equalize', tensor([0.1745]))]
[2022-10-15 01:40:36,234] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 169	 Inner Train loss: 0.7155, acc=0.7374, lr=0.000000	
[2022-10-15 01:40:37,868] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 169	 Test loss: 0.8398, score: 0.6802
[2022-10-15 01:40:37,869] exp4_main.py->main line:277 [INFO]85% (170/200)
[2022-10-15 01:40:38,551] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0488,   4.3560, -10.1924,   0.3510,  -2.2074,  -2.4849,  -5.0834,
         -3.0314,  -2.4849,  -1.0040,  -1.9293,  -1.4490,  -0.1769,  -2.5674,
         -8.6107])
[2022-10-15 01:40:38,553] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-2.0193, -0.8112, -1.4243, -0.6651,  0.3803, -2.4821, -1.2636, -0.5155,
        -0.5277,  0.1684, -0.3797,  1.2513, -0.3596, -1.0234,  1.3142,  0.8324,
        -0.3191, -1.2178])
[2022-10-15 01:40:38,662] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 170, batch_idx: 0, global_img_step: 320, aug_ops:[('contrast', tensor([0.5943])), ('saturation', tensor([0.5677])), ('TranslateX', tensor([-0.0907]))]
[2022-10-15 01:40:38,663] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.003396	gLtNorm 3.2506 (3.2506)	gLvNorm 0.3381 (0.3381)	mvpNorm 3.9869 (3.9869)

[2022-10-15 01:41:35,015] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 170, batch_idx: 0, global_img_step: 321, aug_ops:[('brightness', tensor([0.4737])), ('saturation', tensor([-0.2008])), ('Hed', tensor([-0.1180, -0.0995,  0.1184])), ('Rotate', tensor([-1.]))]
[2022-10-15 01:42:17,431] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 170	 Inner Train loss: 0.6871, acc=0.7404, lr=0.000000	
[2022-10-15 01:42:19,042] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 170	 Test loss: 0.9937, score: 0.6449
[2022-10-15 01:42:19,044] exp4_main.py->main line:277 [INFO]86% (171/200)
[2022-10-15 01:42:19,732] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0154,   4.3221, -10.1584,   0.3740,  -2.2408,  -2.4849,  -5.0593,
         -3.0314,  -2.4849,  -0.9713,  -1.9630,  -1.4798,  -0.2108,  -2.6012,
         -8.5780])
[2022-10-15 01:42:19,733] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9853, -0.7794, -1.4243, -0.6645,  0.4142, -2.4481, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2174, -0.3596, -1.0234,  1.3142,  0.8324,
        -0.3191, -1.2178])
[2022-10-15 01:42:19,984] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 171, batch_idx: 0, global_img_step: 322, aug_ops:[('contrast', tensor([0.0414])), ('sharpen', tensor([-0.2281]))]
[2022-10-15 01:42:19,985] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.003181	gLtNorm 1.0653 (1.0653)	gLvNorm 4.2353 (4.2353)	mvpNorm 1.2081 (1.2081)

[2022-10-15 01:43:16,461] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 171, batch_idx: 0, global_img_step: 323, aug_ops:[('TranslateY', tensor([0.0523])), ('ShearY', tensor([0.1273]))]
[2022-10-15 01:43:58,955] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 171	 Inner Train loss: 0.6938, acc=0.7392, lr=0.000000	
[2022-10-15 01:44:00,579] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 171	 Test loss: 0.8411, score: 0.6842
[2022-10-15 01:44:00,580] exp4_main.py->main line:277 [INFO]86% (172/200)
[2022-10-15 01:44:01,281] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0154,   4.3221, -10.1584,   0.3740,  -2.2408,  -2.4849,  -5.0617,
         -3.0314,  -2.4849,  -0.9978,  -1.9916,  -1.4687,  -0.2045,  -2.6011,
         -8.5780])
[2022-10-15 01:44:01,284] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9853, -0.7794, -1.4243, -0.6645,  0.4142, -2.4481, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2174, -0.3278, -1.0234,  1.3142,  0.8324,
        -0.3191, -1.2178])
[2022-10-15 01:44:01,424] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 172, batch_idx: 0, global_img_step: 324, aug_ops:[('Hsv', tensor([ 0.3603, -0.1040,  0.2389])), ('TranslateX', tensor([0.4136])), ('ShearX', tensor([-0.4960])), ('ShearY', tensor([-1.]))]
[2022-10-15 01:44:01,425] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002973	gLtNorm 5.4892 (5.4892)	gLvNorm 0.0696 (0.0696)	mvpNorm 6.4834 (6.4834)

[2022-10-15 01:44:57,839] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 172, batch_idx: 0, global_img_step: 325, aug_ops:[('TranslateX', tensor([-0.2743]))]
[2022-10-15 01:45:40,379] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 172	 Inner Train loss: 0.7096, acc=0.7335, lr=0.000000	
[2022-10-15 01:45:42,010] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 172	 Test loss: 0.8728, score: 0.6721
[2022-10-15 01:45:42,012] exp4_main.py->main line:277 [INFO]86% (173/200)
[2022-10-15 01:45:42,703] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 9.3904e-03,  4.3363e+00, -1.0187e+01,  3.8077e-01, -2.2704e+00,
        -2.4849e+00, -5.0603e+00, -3.0314e+00, -2.4849e+00, -9.9550e-01,
        -2.0120e+00, -1.4618e+00, -2.0256e-01, -2.6007e+00, -8.5902e+00])
[2022-10-15 01:45:42,705] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9853, -0.8091, -1.4243, -0.6785,  0.3911, -2.4481, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2042, -0.3278, -1.0234,  1.3142,  0.8324,
        -0.3191, -1.2178])
[2022-10-15 01:45:42,871] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 173, batch_idx: 0, global_img_step: 326, aug_ops:[('contrast', tensor([-0.1899])), ('gaussian blur', tensor([0.1541])), ('Equalize', tensor([-0.2342]))]
[2022-10-15 01:45:42,872] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002772	gLtNorm 0.2190 (0.2190)	gLvNorm 0.2360 (0.2360)	mvpNorm 0.1293 (0.1293)

[2022-10-15 01:46:39,192] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 173, batch_idx: 0, global_img_step: 327, aug_ops:[('brightness', tensor([-0.1419])), ('contrast', tensor([0.0922])), ('Rotate', tensor([0.1730])), ('ShearY', tensor([0.5573]))]
[2022-10-15 01:47:21,578] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 173	 Inner Train loss: 0.6730, acc=0.7458, lr=0.000000	
[2022-10-15 01:47:23,220] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 173	 Test loss: 0.9296, score: 0.6695
[2022-10-15 01:47:23,221] exp4_main.py->main line:277 [INFO]87% (174/200)
[2022-10-15 01:47:23,903] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 4.6981e-03,  4.3348e+00, -1.0182e+01,  4.0809e-01, -2.2914e+00,
        -2.4849e+00, -5.0877e+00, -3.0314e+00, -2.4849e+00, -9.6803e-01,
        -2.0173e+00, -1.4341e+00, -2.0265e-01, -2.5804e+00, -8.6160e+00])
[2022-10-15 01:47:23,905] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9696, -0.8020, -1.4243, -0.6507,  0.4085, -2.4204, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2042, -0.3278, -1.0234,  1.2865,  0.8324,
        -0.3468, -1.2178])
[2022-10-15 01:47:24,069] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 174, batch_idx: 0, global_img_step: 328, aug_ops:[('idenity', [1.0])]
[2022-10-15 01:47:24,069] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002578	gLtNorm 2.0368 (2.0368)	gLvNorm 0.2950 (0.2950)	mvpNorm 3.8068 (3.8068)

[2022-10-15 01:48:20,472] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 174, batch_idx: 0, global_img_step: 329, aug_ops:[('contrast', tensor([0.4475])), ('saturation', tensor([0.0205]))]
[2022-10-15 01:49:02,885] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 174	 Inner Train loss: 0.6664, acc=0.7496, lr=0.000000	
[2022-10-15 01:49:04,510] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 174	 Test loss: 1.0627, score: 0.6277
[2022-10-15 01:49:04,511] exp4_main.py->main line:277 [INFO]88% (175/200)
[2022-10-15 01:49:05,200] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([  0.0303,   4.3202, -10.1648,   0.3824,  -2.3155,  -2.4849,  -5.0875,
         -3.0314,  -2.4849,  -0.9592,  -2.0430,  -1.4283,  -0.2201,  -2.6046,
         -8.5906])
[2022-10-15 01:49:05,202] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9696, -0.7775, -1.4243, -0.6658,  0.4314, -2.4204, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2042, -0.3278, -1.0234,  1.2865,  0.8324,
        -0.3468, -1.2178])
[2022-10-15 01:49:05,346] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 175, batch_idx: 0, global_img_step: 330, aug_ops:[('contrast', tensor([0.0620])), ('sharpen', tensor([0.0903])), ('elastic transform', tensor([-0.1800])), ('TranslateY', tensor([0.3004])), ('Equalize', tensor([0.1584]))]
[2022-10-15 01:49:05,347] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002390	gLtNorm 1.6889 (1.6889)	gLvNorm 0.4910 (0.4910)	mvpNorm 0.3865 (0.3865)

[2022-10-15 01:50:01,753] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 175, batch_idx: 0, global_img_step: 331, aug_ops:[('brightness', tensor([0.4680])), ('sharpen', tensor([0.0896])), ('Equalize', tensor([0.4680]))]
[2022-10-15 01:50:44,334] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 175	 Inner Train loss: 0.6850, acc=0.7430, lr=0.000000	
[2022-10-15 01:50:45,953] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 175	 Test loss: 0.7628, score: 0.6947
[2022-10-15 01:50:45,955] exp4_main.py->main line:277 [INFO]88% (176/200)
[2022-10-15 01:50:46,639] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ 7.8572e-03,  4.3008e+00, -1.0162e+01,  3.8884e-01, -2.3107e+00,
        -2.4849e+00, -5.0636e+00, -3.0314e+00, -2.4849e+00, -9.6459e-01,
        -2.0486e+00, -1.4257e+00, -2.1273e-01, -2.6024e+00, -8.5835e+00])
[2022-10-15 01:50:46,641] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9696, -0.7893, -1.4243, -0.6675,  0.4510, -2.4204, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.2042, -0.3278, -1.0234,  1.2860,  0.8085,
        -0.3229, -1.2178])
[2022-10-15 01:50:46,783] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 176, batch_idx: 0, global_img_step: 332, aug_ops:[('gaussian noise', tensor([-0.3829])), ('Rotate', tensor([-0.2697])), ('TranslateX', tensor([0.1554])), ('ShearX', tensor([-0.6585])), ('Equalize', tensor([-1.]))]
[2022-10-15 01:50:46,783] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002209	gLtNorm 0.0263 (0.0263)	gLvNorm 0.4072 (0.4072)	mvpNorm 0.2980 (0.2980)

[2022-10-15 01:51:43,189] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 176, batch_idx: 0, global_img_step: 333, aug_ops:[('gaussian blur', tensor([-0.1193])), ('sharpen', tensor([-0.0123])), ('Rotate', tensor([0.6518])), ('Equalize', tensor([-0.1077]))]
[2022-10-15 01:52:25,650] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 176	 Inner Train loss: 0.7016, acc=0.7383, lr=0.000000	
[2022-10-15 01:52:27,282] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 176	 Test loss: 0.9290, score: 0.6575
[2022-10-15 01:52:27,282] exp4_main.py->main line:277 [INFO]88% (177/200)
[2022-10-15 01:52:27,965] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([  0.0108,   4.2995, -10.1542,   0.3669,  -2.3325,  -2.4849,  -5.0636,
         -3.0314,  -2.4849,  -0.9437,  -2.0473,  -1.4389,  -0.2080,  -2.6102,
         -8.5828])
[2022-10-15 01:52:27,967] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9696, -0.7880, -1.4243, -0.6680,  0.4558, -2.4420, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.3797,  1.1821, -0.3278, -1.0234,  1.2860,  0.8085,
        -0.3296, -1.2178])
[2022-10-15 01:52:28,130] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 177, batch_idx: 0, global_img_step: 334, aug_ops:[('saturation', tensor([-0.2602])), ('gaussian noise', tensor([-0.3443])), ('ShearX', tensor([-0.2693])), ('Equalize', tensor([-0.0571]))]
[2022-10-15 01:52:28,130] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.002035	gLtNorm 0.3601 (0.3601)	gLvNorm 0.1783 (0.1783)	mvpNorm 0.1097 (0.1097)

[2022-10-15 01:53:24,320] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 177, batch_idx: 0, global_img_step: 335, aug_ops:[('saturation', tensor([-0.2402])), ('sharpen', tensor([-0.2433]))]
[2022-10-15 01:54:06,749] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 177	 Inner Train loss: 0.7187, acc=0.7316, lr=0.000000	
[2022-10-15 01:54:08,380] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 177	 Test loss: 0.9690, score: 0.6574
[2022-10-15 01:54:08,381] exp4_main.py->main line:277 [INFO]89% (178/200)
[2022-10-15 01:54:09,065] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([-5.3368e-03,  4.3199e+00, -1.0169e+01,  3.5191e-01, -2.3205e+00,
        -2.4849e+00, -5.0636e+00, -3.0314e+00, -2.4849e+00, -9.4439e-01,
        -2.0671e+00, -1.4277e+00, -2.2703e-01, -2.6094e+00, -8.5832e+00])
[2022-10-15 01:54:09,067] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9493, -0.8079, -1.4243, -0.6680,  0.4354, -2.4420, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.4001,  1.1821, -0.3278, -1.0234,  1.2860,  0.8085,
        -0.3296, -1.2178])
[2022-10-15 01:54:09,217] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 178, batch_idx: 0, global_img_step: 336, aug_ops:[('contrast', tensor([-0.1520])), ('saturation', tensor([-0.0747])), ('gaussian noise', tensor([-0.0674])), ('Rotate', tensor([-0.1150])), ('Equalize', tensor([-0.0851]))]
[2022-10-15 01:54:09,218] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001869	gLtNorm 0.2098 (0.2098)	gLvNorm 0.5262 (0.5262)	mvpNorm 0.2819 (0.2819)

[2022-10-15 01:55:05,424] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 178, batch_idx: 0, global_img_step: 337, aug_ops:[('idenity', [1.0])]
[2022-10-15 01:55:47,880] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 178	 Inner Train loss: 0.6731, acc=0.7461, lr=0.000000	
[2022-10-15 01:55:49,508] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 178	 Test loss: 0.8653, score: 0.6761
[2022-10-15 01:55:49,509] exp4_main.py->main line:277 [INFO]90% (179/200)
[2022-10-15 01:55:50,184] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0236,   4.3221, -10.1874,   0.3419,  -2.3374,  -2.4849,  -5.0636,
         -3.0314,  -2.4849,  -0.9446,  -2.0716,  -1.4366,  -0.2339,  -2.6189,
         -8.6019])
[2022-10-15 01:55:50,186] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9679, -0.8137, -1.4243, -0.6495,  0.4479, -2.4606, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.4001,  1.1821, -0.3278, -1.0420,  1.2673,  0.8085,
        -0.3478, -1.2178])
[2022-10-15 01:55:50,293] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 179, batch_idx: 0, global_img_step: 338, aug_ops:[('contrast', tensor([-0.0833])), ('saturation', tensor([0.4042])), ('gaussian noise', tensor([0.1243])), ('TranslateY', tensor([0.6608])), ('ShearX', tensor([-0.3545]))]
[2022-10-15 01:55:50,293] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001709	gLtNorm 0.2738 (0.2738)	gLvNorm 0.1571 (0.1571)	mvpNorm 0.1360 (0.1360)

[2022-10-15 01:56:46,501] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 179, batch_idx: 0, global_img_step: 339, aug_ops:[('sharpen', tensor([-1.])), ('ShearX', tensor([0.9190]))]
[2022-10-15 01:57:28,954] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 179	 Inner Train loss: 0.7331, acc=0.7318, lr=0.000000	
[2022-10-15 01:57:30,585] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 179	 Test loss: 0.9299, score: 0.6589
[2022-10-15 01:57:30,585] exp4_main.py->main line:277 [INFO]90% (180/200)
[2022-10-15 01:57:31,261] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0405,   4.3244, -10.2032,   0.3323,  -2.3349,  -2.4849,  -5.0632,
         -3.0314,  -2.4849,  -0.9531,  -2.0703,  -1.4236,  -0.2336,  -2.6069,
         -8.5971])
[2022-10-15 01:57:31,263] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9787, -0.8308, -1.4243, -0.6456,  0.4588, -2.4633, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.4001,  1.1821, -0.3278, -1.0591,  1.2673,  0.7914,
        -0.3554, -1.2178])
[2022-10-15 01:57:31,415] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 180, batch_idx: 0, global_img_step: 340, aug_ops:[('Hsv', tensor([-0.1409,  0.0522, -0.1443]))]
[2022-10-15 01:57:31,416] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001556	gLtNorm 0.5377 (0.5377)	gLvNorm 0.2540 (0.2540)	mvpNorm 0.1856 (0.1856)

[2022-10-15 01:58:27,688] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 180, batch_idx: 0, global_img_step: 341, aug_ops:[('contrast', tensor([0.0213]))]
[2022-10-15 01:59:10,096] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 180	 Inner Train loss: 0.6869, acc=0.7411, lr=0.000000	
[2022-10-15 01:59:11,716] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 180	 Test loss: 0.9784, score: 0.6645
[2022-10-15 01:59:11,717] exp4_main.py->main line:277 [INFO]90% (181/200)
[2022-10-15 01:59:12,402] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0414,   4.3337, -10.2033,   0.3207,  -2.3318,  -2.4849,  -5.0620,
         -3.0314,  -2.4849,  -0.9572,  -2.0857,  -1.4083,  -0.2182,  -2.6061,
         -8.5998])
[2022-10-15 01:59:12,404] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9853, -0.8326, -1.4243, -0.6321,  0.4683, -2.4558, -1.2976, -0.5494,
        -0.5403,  0.2022, -0.4001,  1.1821, -0.3278, -1.0591,  1.2673,  0.7914,
        -0.3554, -1.2178])
[2022-10-15 01:59:12,566] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 181, batch_idx: 0, global_img_step: 342, aug_ops:[('contrast', tensor([0.5885])), ('saturation', tensor([0.1340])), ('gaussian noise', tensor([1.])), ('Rotate', tensor([0.0781])), ('TranslateY', tensor([-0.1952])), ('ShearX', tensor([-1.])), ('Equalize', tensor([0.6476]))]
[2022-10-15 01:59:12,566] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001411	gLtNorm 0.1353 (0.1353)	gLvNorm 0.2392 (0.2392)	mvpNorm 0.1021 (0.1021)

[2022-10-15 02:00:08,819] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 181, batch_idx: 0, global_img_step: 343, aug_ops:[('contrast', tensor([0.1554])), ('TranslateX', tensor([0.0891]))]
[2022-10-15 02:00:51,126] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 181	 Inner Train loss: 0.7340, acc=0.7261, lr=0.000000	
[2022-10-15 02:00:52,768] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 181	 Test loss: 0.9447, score: 0.6570
[2022-10-15 02:00:52,769] exp4_main.py->main line:277 [INFO]91% (182/200)
[2022-10-15 02:00:53,457] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0274,   4.3478, -10.2107,   0.3347,  -2.3459,  -2.4849,  -5.0748,
         -3.0314,  -2.4849,  -0.9606,  -2.0858,  -1.4159,  -0.2298,  -2.6202,
         -8.6031])
[2022-10-15 02:00:53,459] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9993, -0.8251, -1.4243, -0.6321,  0.4683, -2.4558, -1.2976, -0.5494,
        -0.5403,  0.2055, -0.4001,  1.1821, -0.3419, -1.0732,  1.2804,  0.7914,
        -0.3695, -1.2178])
[2022-10-15 02:00:53,625] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 182, batch_idx: 0, global_img_step: 344, aug_ops:[('contrast', tensor([-1.])), ('saturation', tensor([-0.9654])), ('gaussian noise', tensor([-0.7829])), ('TranslateX', tensor([-0.2734]))]
[2022-10-15 02:00:53,625] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001272	gLtNorm 2.1315 (2.1315)	gLvNorm 0.2761 (0.2761)	mvpNorm 2.6582 (2.6582)

[2022-10-15 02:01:49,971] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 182, batch_idx: 0, global_img_step: 345, aug_ops:[('saturation', tensor([0.2155])), ('gaussian blur', tensor([0.2532])), ('gaussian noise', tensor([0.2163])), ('Rotate', tensor([0.7285])), ('TranslateX', tensor([0.8433]))]
[2022-10-15 02:02:32,332] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 182	 Inner Train loss: 0.7256, acc=0.7278, lr=0.000000	
[2022-10-15 02:02:33,957] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 182	 Test loss: 0.8960, score: 0.6740
[2022-10-15 02:02:33,958] exp4_main.py->main line:277 [INFO]92% (183/200)
[2022-10-15 02:02:34,629] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0286,   4.3493, -10.2107,   0.3259,  -2.3459,  -2.4849,  -5.0775,
         -3.0314,  -2.4849,  -0.9526,  -2.0776,  -1.4192,  -0.2384,  -2.6253,
         -8.6158])
[2022-10-15 02:02:34,630] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9887, -0.8202, -1.4243, -0.6321,  0.4683, -2.4558, -1.2976, -0.5494,
        -0.5403,  0.2055, -0.4001,  1.1821, -0.3419, -1.0783,  1.2804,  0.7914,
        -0.3756, -1.2178])
[2022-10-15 02:02:34,745] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 183, batch_idx: 0, global_img_step: 346, aug_ops:[('brightness', tensor([-0.5491])), ('gaussian noise', tensor([0.3082])), ('Rotate', tensor([-0.8777])), ('TranslateX', tensor([0.3824])), ('TranslateY', tensor([-0.1372])), ('ShearX', tensor([-0.0617])), ('Equalize', tensor([-0.5491]))]
[2022-10-15 02:02:34,745] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001141	gLtNorm 0.0323 (0.0323)	gLvNorm 0.4179 (0.4179)	mvpNorm 0.5499 (0.5499)

[2022-10-15 02:03:31,191] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 183, batch_idx: 0, global_img_step: 347, aug_ops:[('Hsv', tensor([-0.2235,  0.1652, -0.0294])), ('gaussian noise', tensor([0.2704])), ('ShearX', tensor([0.6446]))]
[2022-10-15 02:04:13,629] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 183	 Inner Train loss: 0.6863, acc=0.7413, lr=0.000000	
[2022-10-15 02:04:15,259] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 183	 Test loss: 0.9079, score: 0.6550
[2022-10-15 02:04:15,260] exp4_main.py->main line:277 [INFO]92% (184/200)
[2022-10-15 02:04:15,956] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0273,   4.3493, -10.2107,   0.3259,  -2.3461,  -2.4849,  -5.0773,
         -3.0314,  -2.4849,  -0.9412,  -2.0798,  -1.4188,  -0.2352,  -2.6323,
         -8.6137])
[2022-10-15 02:04:15,957] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.8316, -1.4243, -0.6217,  0.4686, -2.4585, -1.2976, -0.5494,
        -0.5403,  0.2055, -0.4001,  1.1821, -0.3419, -1.0783,  1.2795,  0.7914,
        -0.3736, -1.2178])
[2022-10-15 02:04:16,105] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 184, batch_idx: 0, global_img_step: 348, aug_ops:[('Hsv', tensor([-0.5245, -0.4744, -0.3221])), ('Equalize', tensor([-0.4856]))]
[2022-10-15 02:04:16,105] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.001017	gLtNorm 1.2480 (1.2480)	gLvNorm 0.8133 (0.8133)	mvpNorm 1.4515 (1.4515)

[2022-10-15 02:05:12,431] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 184, batch_idx: 0, global_img_step: 349, aug_ops:[('TranslateY', tensor([-1.]))]
[2022-10-15 02:05:55,036] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 184	 Inner Train loss: 0.6842, acc=0.7401, lr=0.000000	
[2022-10-15 02:05:56,651] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 184	 Test loss: 0.9244, score: 0.6597
[2022-10-15 02:05:56,652] exp4_main.py->main line:277 [INFO]92% (185/200)
[2022-10-15 02:05:57,324] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0318,   4.3506, -10.2107,   0.3161,  -2.3478,  -2.4849,  -5.0813,
         -3.0314,  -2.4849,  -0.9419,  -2.0703,  -1.4285,  -0.2452,  -2.6349,
         -8.6204])
[2022-10-15 02:05:57,326] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.8335, -1.4243, -0.6132,  0.4584, -2.4484, -1.2976, -0.5494,
        -0.5403,  0.1958, -0.4001,  1.1923, -0.3419, -1.0783,  1.2795,  0.7914,
        -0.3736, -1.2178])
[2022-10-15 02:05:57,475] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 185, batch_idx: 0, global_img_step: 350, aug_ops:[('sharpen', tensor([-0.0288])), ('TranslateY', tensor([0.2219])), ('ShearX', tensor([-0.0483])), ('ShearY', tensor([-0.1718]))]
[2022-10-15 02:05:57,475] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000901	gLtNorm 0.8015 (0.8015)	gLvNorm 0.2834 (0.2834)	mvpNorm 0.5744 (0.5744)

[2022-10-15 02:06:53,886] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 185, batch_idx: 0, global_img_step: 351, aug_ops:[('contrast', tensor([0.0442])), ('saturation', tensor([0.1795])), ('gaussian blur', tensor([0.4875]))]
[2022-10-15 02:07:36,464] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 185	 Inner Train loss: 0.6879, acc=0.7436, lr=0.000000	
[2022-10-15 02:07:38,089] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 185	 Test loss: 0.8926, score: 0.6718
[2022-10-15 02:07:38,090] exp4_main.py->main line:277 [INFO]93% (186/200)
[2022-10-15 02:07:38,779] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0318,   4.3506, -10.2107,   0.3071,  -2.3418,  -2.4849,  -5.0845,
         -3.0314,  -2.4849,  -0.9504,  -2.0699,  -1.4201,  -0.2454,  -2.6270,
         -8.6204])
[2022-10-15 02:07:38,781] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.8335, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5403,  0.1958, -0.4001,  1.1923, -0.3419, -1.0783,  1.2795,  0.7914,
        -0.3750, -1.2178])
[2022-10-15 02:07:38,935] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 186, batch_idx: 0, global_img_step: 352, aug_ops:[('brightness', tensor([-0.4353])), ('contrast', tensor([-0.8955])), ('saturation', tensor([0.3841])), ('Hed', tensor([0.2461, 0.5136, 0.7273])), ('gaussian noise', tensor([-1.])), ('Equalize', tensor([-0.4353]))]
[2022-10-15 02:07:38,935] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000792	gLtNorm 0.4052 (0.4052)	gLvNorm 0.1938 (0.1938)	mvpNorm 0.6005 (0.6005)

[2022-10-15 02:08:35,252] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 186, batch_idx: 0, global_img_step: 353, aug_ops:[('gaussian blur', tensor([0.1554])), ('TranslateX', tensor([-0.3486]))]
[2022-10-15 02:09:17,637] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 186	 Inner Train loss: 0.7142, acc=0.7294, lr=0.000000	
[2022-10-15 02:09:19,245] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 186	 Test loss: 0.9480, score: 0.6602
[2022-10-15 02:09:19,245] exp4_main.py->main line:277 [INFO]94% (187/200)
[2022-10-15 02:09:19,940] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0239,   4.3585, -10.2186,   0.3133,  -2.3368,  -2.4849,  -5.0924,
         -3.0314,  -2.4849,  -0.9577,  -2.0762,  -1.4206,  -0.2390,  -2.6256,
         -8.6283])
[2022-10-15 02:09:19,942] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9918, -0.8414, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1923, -0.3419, -1.0862,  1.2795,  0.7914,
        -0.3750, -1.2178])
[2022-10-15 02:09:20,102] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 187, batch_idx: 0, global_img_step: 354, aug_ops:[('elastic transform', tensor([1.]))]
[2022-10-15 02:09:20,102] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000690	gLtNorm 6.4001 (6.4001)	gLvNorm 0.2024 (0.2024)	mvpNorm 7.6512 (7.6512)

[2022-10-15 02:10:16,360] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 187, batch_idx: 0, global_img_step: 355, aug_ops:[('contrast', tensor([-0.1043])), ('elastic transform', tensor([0.0359])), ('Rotate', tensor([0.4322])), ('TranslateX', tensor([0.2953])), ('Equalize', tensor([0.1323]))]
[2022-10-15 02:10:58,954] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 187	 Inner Train loss: 0.7118, acc=0.7328, lr=0.000000	
[2022-10-15 02:11:00,584] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 187	 Test loss: 0.7557, score: 0.7009
[2022-10-15 02:11:00,585] exp4_main.py->main line:277 [INFO]94% (188/200)
[2022-10-15 02:11:01,271] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0238,   4.3585, -10.2180,   0.3192,  -2.3361,  -2.4849,  -5.0910,
         -3.0314,  -2.4849,  -0.9646,  -2.0693,  -1.4239,  -0.2456,  -2.6324,
         -8.6279])
[2022-10-15 02:11:01,273] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9901, -0.8411, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1923, -0.3419, -1.0862,  1.2864,  0.7914,
        -0.3750, -1.2178])
[2022-10-15 02:11:01,413] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 188, batch_idx: 0, global_img_step: 356, aug_ops:[('brightness', tensor([0.1610])), ('contrast', tensor([0.8990])), ('saturation', tensor([0.4839])), ('Rotate', tensor([-0.5710])), ('ShearX', tensor([-0.5523]))]
[2022-10-15 02:11:01,414] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000596	gLtNorm 1.5302 (1.5302)	gLvNorm 0.1428 (0.1428)	mvpNorm 1.8454 (1.8454)

[2022-10-15 02:11:57,712] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 188, batch_idx: 0, global_img_step: 357, aug_ops:[('Equalize', tensor([-0.1627]))]
[2022-10-15 02:12:40,194] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 188	 Inner Train loss: 0.6588, acc=0.7508, lr=0.000000	
[2022-10-15 02:12:41,820] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 188	 Test loss: 0.9230, score: 0.6663
[2022-10-15 02:12:41,822] exp4_main.py->main line:277 [INFO]94% (189/200)
[2022-10-15 02:12:42,499] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0238,   4.3585, -10.2180,   0.3192,  -2.3360,  -2.4849,  -5.0872,
         -3.0314,  -2.4849,  -0.9651,  -2.0692,  -1.4180,  -0.2454,  -2.6271,
         -8.6279])
[2022-10-15 02:12:42,501] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9901, -0.8411, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1923, -0.3419, -1.0862,  1.2864,  0.7949,
        -0.3750, -1.2178])
[2022-10-15 02:12:42,716] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 189, batch_idx: 0, global_img_step: 358, aug_ops:[('brightness', tensor([-0.0999])), ('Hed', tensor([ 0.1400, -0.4453, -0.0880]))]
[2022-10-15 02:12:42,717] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000509	gLtNorm 3.9082 (3.9082)	gLvNorm 4.5489 (4.5489)	mvpNorm 3.2502 (3.2502)

[2022-10-15 02:13:38,858] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 189, batch_idx: 0, global_img_step: 359, aug_ops:[('contrast', tensor([-0.1601])), ('elastic transform', tensor([-0.0505])), ('Rotate', tensor([-0.4534])), ('ShearX', tensor([0.0523]))]
[2022-10-15 02:14:21,386] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 189	 Inner Train loss: 0.7109, acc=0.7326, lr=0.000000	
[2022-10-15 02:14:23,021] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 189	 Test loss: 0.9872, score: 0.6585
[2022-10-15 02:14:23,022] exp4_main.py->main line:277 [INFO]95% (190/200)
[2022-10-15 02:14:23,706] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0201,   4.3589, -10.2190,   0.3198,  -2.3355,  -2.4849,  -5.0921,
         -3.0314,  -2.4849,  -0.9666,  -2.0707,  -1.4129,  -0.2403,  -2.6308,
         -8.6330])
[2022-10-15 02:14:23,708] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9901, -0.8411, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1923, -0.3368, -1.0862,  1.2864,  0.8000,
        -0.3750, -1.2178])
[2022-10-15 02:14:23,811] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 190, batch_idx: 0, global_img_step: 360, aug_ops:[('contrast', tensor([0.2110])), ('gaussian noise', tensor([-1.]))]
[2022-10-15 02:14:23,812] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000429	gLtNorm 0.0765 (0.0765)	gLvNorm 0.3667 (0.3667)	mvpNorm 0.5623 (0.5623)

[2022-10-15 02:15:20,051] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 190, batch_idx: 0, global_img_step: 361, aug_ops:[('brightness', tensor([1.])), ('saturation', tensor([-1.])), ('ShearX', tensor([0.0306])), ('Equalize', tensor([1.]))]
[2022-10-15 02:16:02,327] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 190	 Inner Train loss: 0.6949, acc=0.7438, lr=0.000000	
[2022-10-15 02:16:03,970] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 190	 Test loss: 0.7979, score: 0.6895
[2022-10-15 02:16:03,971] exp4_main.py->main line:277 [INFO]96% (191/200)
[2022-10-15 02:16:04,657] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0240,   4.3589, -10.2149,   0.3197,  -2.3336,  -2.4849,  -5.0933,
         -3.0314,  -2.4849,  -0.9664,  -2.0735,  -1.4119,  -0.2394,  -2.6280,
         -8.6329])
[2022-10-15 02:16:04,659] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9944, -0.8381, -1.4243, -0.6132,  0.4586, -2.4484, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1923, -0.3368, -1.0862,  1.2907,  0.8000,
        -0.3750, -1.2178])
[2022-10-15 02:16:04,797] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 191, batch_idx: 0, global_img_step: 362, aug_ops:[('saturation', tensor([0.0073]))]
[2022-10-15 02:16:04,797] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000357	gLtNorm 0.1520 (0.1520)	gLvNorm 0.6275 (0.6275)	mvpNorm 0.1750 (0.1750)

[2022-10-15 02:17:00,989] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 191, batch_idx: 0, global_img_step: 363, aug_ops:[('contrast', tensor([-0.4365])), ('gaussian noise', tensor([-0.0641])), ('TranslateY', tensor([0.0916]))]
[2022-10-15 02:17:43,516] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 191	 Inner Train loss: 0.6774, acc=0.7462, lr=0.000000	
[2022-10-15 02:17:45,127] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 191	 Test loss: 0.9175, score: 0.6701
[2022-10-15 02:17:45,129] exp4_main.py->main line:277 [INFO]96% (192/200)
[2022-10-15 02:17:45,813] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0240,   4.3573, -10.2147,   0.3203,  -2.3319,  -2.4849,  -5.0933,
         -3.0314,  -2.4849,  -0.9652,  -2.0737,  -1.4118,  -0.2398,  -2.6280,
         -8.6328])
[2022-10-15 02:17:45,815] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9944, -0.8377, -1.4243, -0.6096,  0.4588, -2.4449, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1887, -0.3368, -1.0862,  1.2907,  0.8002,
        -0.3750, -1.2178])
[2022-10-15 02:17:45,987] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 192, batch_idx: 0, global_img_step: 364, aug_ops:[('brightness', tensor([-0.3904])), ('contrast', tensor([-0.2296])), ('Hed', tensor([-0.4328, -0.3453,  0.5942])), ('ShearY', tensor([0.1751]))]
[2022-10-15 02:17:45,987] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000293	gLtNorm 0.1103 (0.1103)	gLvNorm 2.3074 (2.3074)	mvpNorm 3.1334 (3.1334)

[2022-10-15 02:18:42,300] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 192, batch_idx: 0, global_img_step: 365, aug_ops:[('contrast', tensor([0.2437])), ('saturation', tensor([0.0501])), ('TranslateX', tensor([0.4859])), ('Equalize', tensor([0.2769]))]
[2022-10-15 02:19:24,738] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 192	 Inner Train loss: 0.7136, acc=0.7331, lr=0.000000	
[2022-10-15 02:19:26,362] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 192	 Test loss: 0.8284, score: 0.6932
[2022-10-15 02:19:26,363] exp4_main.py->main line:277 [INFO]96% (193/200)
[2022-10-15 02:19:27,042] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0259,   4.3586, -10.2165,   0.3173,  -2.3349,  -2.4849,  -5.0911,
         -3.0314,  -2.4849,  -0.9653,  -2.0709,  -1.4114,  -0.2369,  -2.6251,
         -8.6330])
[2022-10-15 02:19:27,044] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9944, -0.8362, -1.4243, -0.6096,  0.4588, -2.4449, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1887, -0.3368, -1.0862,  1.2907,  0.8002,
        -0.3750, -1.2178])
[2022-10-15 02:19:27,209] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 193, batch_idx: 0, global_img_step: 366, aug_ops:[('contrast', tensor([0.2263])), ('saturation', tensor([0.0311])), ('Rotate', tensor([0.1472])), ('Equalize', tensor([0.3740]))]
[2022-10-15 02:19:27,210] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000236	gLtNorm 1.4915 (1.4915)	gLvNorm 0.1142 (0.1142)	mvpNorm 1.3280 (1.3280)

[2022-10-15 02:20:23,600] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 193, batch_idx: 0, global_img_step: 367, aug_ops:[('contrast', tensor([-0.3071])), ('Rotate', tensor([-0.4427])), ('TranslateX', tensor([0.0519]))]
[2022-10-15 02:21:06,036] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 193	 Inner Train loss: 0.7014, acc=0.7346, lr=0.000000	
[2022-10-15 02:21:07,681] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 193	 Test loss: 0.8450, score: 0.6821
[2022-10-15 02:21:07,682] exp4_main.py->main line:277 [INFO]97% (194/200)
[2022-10-15 02:21:08,381] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0248,   4.3597, -10.2189,   0.3173,  -2.3356,  -2.4849,  -5.0910,
         -3.0314,  -2.4849,  -0.9630,  -2.0710,  -1.4138,  -0.2369,  -2.6258,
         -8.6338])
[2022-10-15 02:21:08,383] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9968, -0.8352, -1.4243, -0.6096,  0.4588, -2.4449, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1887, -0.3368, -1.0862,  1.2904,  0.8002,
        -0.3773, -1.2178])
[2022-10-15 02:21:08,488] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 194, batch_idx: 0, global_img_step: 368, aug_ops:[('contrast', tensor([0.0425]))]
[2022-10-15 02:21:08,488] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000187	gLtNorm 14.1970 (14.1970)	gLvNorm 0.1525 (0.1525)	mvpNorm 15.5255 (15.5255)

[2022-10-15 02:22:04,771] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 194, batch_idx: 0, global_img_step: 369, aug_ops:[('contrast', tensor([0.1225])), ('saturation', tensor([-0.7304])), ('TranslateX', tensor([-0.0429])), ('ShearX', tensor([0.6895])), ('Equalize', tensor([-0.1625]))]
[2022-10-15 02:22:47,182] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 194	 Inner Train loss: 0.7227, acc=0.7315, lr=0.000000	
[2022-10-15 02:22:48,794] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 194	 Test loss: 0.8933, score: 0.6643
[2022-10-15 02:22:48,795] exp4_main.py->main line:277 [INFO]98% (195/200)
[2022-10-15 02:22:49,478] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0267,   4.3611, -10.2190,   0.3192,  -2.3347,  -2.4849,  -5.0892,
         -3.0314,  -2.4849,  -0.9633,  -2.0691,  -1.4142,  -0.2384,  -2.6275,
         -8.6356])
[2022-10-15 02:22:49,480] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9973, -0.8334, -1.4243, -0.6077,  0.4607, -2.4431, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1887, -0.3368, -1.0862,  1.2923,  0.8002,
        -0.3773, -1.2178])
[2022-10-15 02:22:49,639] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 195, batch_idx: 0, global_img_step: 370, aug_ops:[('idenity', [1.0])]
[2022-10-15 02:22:49,640] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000145	gLtNorm 0.5822 (0.5822)	gLvNorm 4.8956 (4.8956)	mvpNorm 7.3940 (7.3940)

[2022-10-15 02:23:45,967] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 195, batch_idx: 0, global_img_step: 371, aug_ops:[('ShearY', tensor([0.2734])), ('Equalize', tensor([0.0405]))]
[2022-10-15 02:24:28,558] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 195	 Inner Train loss: 0.6776, acc=0.7483, lr=0.000000	
[2022-10-15 02:24:30,167] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 195	 Test loss: 0.8591, score: 0.6786
[2022-10-15 02:24:30,168] exp4_main.py->main line:277 [INFO]98% (196/200)
[2022-10-15 02:24:30,848] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0267,   4.3596, -10.2190,   0.3192,  -2.3339,  -2.4849,  -5.0881,
         -3.0314,  -2.4849,  -0.9633,  -2.0691,  -1.4142,  -0.2384,  -2.6275,
         -8.6356])
[2022-10-15 02:24:30,849] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9974, -0.8333, -1.4243, -0.6077,  0.4607, -2.4431, -1.2976, -0.5494,
        -0.5324,  0.1958, -0.4001,  1.1887, -0.3368, -1.0848,  1.2923,  0.8000,
        -0.3771, -1.2164])
[2022-10-15 02:24:31,029] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 196, batch_idx: 0, global_img_step: 372, aug_ops:[('sharpen', tensor([0.9746])), ('Equalize', tensor([0.8366]))]
[2022-10-15 02:24:31,029] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000111	gLtNorm 0.5891 (0.5891)	gLvNorm 1.3679 (1.3679)	mvpNorm 1.7501 (1.7501)

[2022-10-15 02:25:27,216] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 196, batch_idx: 0, global_img_step: 373, aug_ops:[('Hed', tensor([ 0.2244, -0.0943,  0.1224])), ('gaussian blur', tensor([0.2603])), ('ShearY', tensor([0.0844])), ('Equalize', tensor([0.1758]))]
[2022-10-15 02:26:09,546] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 196	 Inner Train loss: 0.6920, acc=0.7374, lr=0.000000	
[2022-10-15 02:26:11,160] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 196	 Test loss: 0.9388, score: 0.6597
[2022-10-15 02:26:11,161] exp4_main.py->main line:277 [INFO]98% (197/200)
[2022-10-15 02:26:11,846] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0267,   4.3596, -10.2190,   0.3187,  -2.3344,  -2.4849,  -5.0880,
         -3.0314,  -2.4849,  -0.9634,  -2.0691,  -1.4142,  -0.2384,  -2.6275,
         -8.6356])
[2022-10-15 02:26:11,847] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9974, -0.8333, -1.4243, -0.6077,  0.4607, -2.4425, -1.2987, -0.5483,
        -0.5313,  0.1958, -0.4001,  1.1887, -0.3368, -1.0840,  1.2923,  0.7989,
        -0.3771, -1.2164])
[2022-10-15 02:26:11,995] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 197, batch_idx: 0, global_img_step: 374, aug_ops:[('Rotate', tensor([-1.])), ('ShearX', tensor([0.2380]))]
[2022-10-15 02:26:11,995] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000084	gLtNorm 0.0841 (0.0841)	gLvNorm 0.1906 (0.1906)	mvpNorm 0.3242 (0.3242)

[2022-10-15 02:27:08,203] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 197, batch_idx: 0, global_img_step: 375, aug_ops:[('contrast', tensor([0.1875])), ('saturation', tensor([0.2236]))]
[2022-10-15 02:27:50,510] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 197	 Inner Train loss: 0.7374, acc=0.7251, lr=0.000000	
[2022-10-15 02:27:52,149] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 197	 Test loss: 1.0865, score: 0.6306
[2022-10-15 02:27:52,150] exp4_main.py->main line:277 [INFO]99% (198/200)
[2022-10-15 02:27:52,833] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0272,   4.3601, -10.2196,   0.3180,  -2.3343,  -2.4849,  -5.0872,
         -3.0314,  -2.4849,  -0.9642,  -2.0684,  -1.4133,  -0.2383,  -2.6269,
         -8.6362])
[2022-10-15 02:27:52,834] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9966, -0.8341, -1.4243, -0.6085,  0.4604, -2.4417, -1.2987, -0.5483,
        -0.5313,  0.1958, -0.4001,  1.1895, -0.3368, -1.0840,  1.2923,  0.7997,
        -0.3771, -1.2164])
[2022-10-15 02:27:52,938] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 198, batch_idx: 0, global_img_step: 376, aug_ops:[('contrast', tensor([1.]))]
[2022-10-15 02:27:52,938] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000065	gLtNorm 0.0883 (0.0883)	gLvNorm 0.1372 (0.1372)	mvpNorm 0.3212 (0.3212)

[2022-10-15 02:28:49,381] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 198, batch_idx: 0, global_img_step: 377, aug_ops:[('saturation', tensor([0.4713])), ('sharpen', tensor([-0.3676])), ('gaussian noise', tensor([0.0308])), ('Equalize', tensor([-0.4100]))]
[2022-10-15 02:29:31,677] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 198	 Inner Train loss: 0.6954, acc=0.7377, lr=0.000000	
[2022-10-15 02:29:33,317] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 198	 Test loss: 0.8267, score: 0.6890
[2022-10-15 02:29:33,318] exp4_main.py->main line:277 [INFO]100% (199/200)
[2022-10-15 02:29:34,014] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramP_tensor([ -0.0272,   4.3601, -10.2196,   0.3180,  -2.3344,  -2.4849,  -5.0870,
         -3.0314,  -2.4849,  -0.9642,  -2.0684,  -1.4134,  -0.2384,  -2.6266,
         -8.6362])
[2022-10-15 02:29:34,016] automodels.py->Med_hyperHesTrain line:922 [INFO]data point 0 weight: paramM_tensor([-1.9966, -0.8341, -1.4243, -0.6085,  0.4604, -2.4417, -1.2987, -0.5483,
        -0.5313,  0.1965, -0.4001,  1.1895, -0.3368, -1.0840,  1.2923,  0.7997,
        -0.3774, -1.2164])
[2022-10-15 02:29:34,153] automodels.py->Med_hyperHesTrain line:947 [INFO]hyperTrain epoch: 199, batch_idx: 0, global_img_step: 378, aug_ops:[('gaussian noise', tensor([0.0807])), ('elastic transform', tensor([0.3301])), ('TranslateX', tensor([0.3286])), ('ShearX', tensor([0.3161])), ('ShearY', tensor([-0.6496]))]
[2022-10-15 02:29:34,153] automodels.py->Med_hyperHesTrain line:953 [INFO]hyperTrain batch 0% (0/131), task_lr=0.000000, hyper_lr=0.000054	gLtNorm 1.2496 (1.2496)	gLvNorm 0.1416 (0.1416)	mvpNorm 1.9298 (1.9298)

[2022-10-15 02:30:30,486] automodels.py->Med_innerTrain line:1023 [INFO]Train epoch: 199, batch_idx: 0, global_img_step: 379, aug_ops:[('idenity', [1.0])]
[2022-10-15 02:31:12,782] automodels.py->Med_innerTrain line:1040 [INFO]Epoch: 199	 Inner Train loss: 0.6624, acc=0.7469, lr=0.000000	
[2022-10-15 02:31:14,393] automodels.py->Med_innerTest line:1208 [INFO]Epoch: 199	 Test loss: 1.0642, score: 0.6371
[2022-10-15 02:31:14,573] exp4_main.py->main line:317 [INFO]save train history at: /home/rayeh/workspace/project/med/Med_AutoDO/picture/exp4_UNet_e200_opt_HES_est_True_aug_model_SEP_los_model_NONE_ir_1_sr_1.0_nr_0.0.jpg
[2022-10-15 02:31:14,573] exp4_main.py->main line:319 [INFO]BEST trained model has 0.7108 Dice score
