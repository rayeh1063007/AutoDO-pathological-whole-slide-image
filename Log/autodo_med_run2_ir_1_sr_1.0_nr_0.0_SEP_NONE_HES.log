[2022-08-15 23:55:23,236] implicit-augment.py->main line:123 [INFO]Namespace(aug_model='SEP', data='./local_data', dataset='med', epochs=20, gpu='0', hyper_alpha=0.01, hyper_beta=0, hyper_est=True, hyper_gamma=0, hyper_iters=5, hyper_opt='HES', hyper_steps=0, imbalance_ratio=1, log_interval=500, los_model='NONE', lr_cosine=True, lr_decay_epochs='5,10,15', lr_decay_rate=0.1, lr_warm=True, lr_warm_epochs=5, no_cuda=False, noise_ratio=0.0, overfit=False, oversplit=False, plot_debug=False, run_folder='run2', scale=1, subsample_ratio=1.0, workers=4)
[2022-08-15 23:55:28,813] implicit-augment.py->main line:337 [INFO]Valid/Train Split: 3/9
[2022-08-15 23:55:28,815] implicit-augment.py->main line:403 [INFO]Test/Valid/Train Split: 12/3/9 out of total 12 train images
[2022-08-15 23:55:28,818] implicit-augment.py->main line:446 [INFO]Run: ./local_data/med/run2/UNet_opt_HES_est_True_aug_model_SEP_los_model_NONE_ir_1_sr_1.0_nr_0.0
[2022-08-15 23:55:28,819] implicit-augment.py->main line:454 [INFO]0% (0/20)
[2022-08-15 23:55:29,504] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849,
        -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849, -2.4849])
[2022-08-15 23:55:29,505] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
[2022-08-15 23:55:30,110] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 0, batch_idx: 0, global_img_step: 0, aug_ops:[('sharpen', tensor([0.9887]))]
[2022-08-15 23:55:30,110] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000010, hyper_lr=-0.010074	gLtNorm 0.0061 (0.0061)	gLvNorm 0.0044 (0.0044)	mvpNorm 0.0001 (0.0001)

[2022-08-15 23:55:33,079] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 0, batch_idx: 0, global_img_step: 1, aug_ops:[('Equalize', tensor([0.3553]))]
[2022-08-15 23:55:33,819] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 0	 Inner Train loss: 1.2598, acc=0.4875, lr=0.000010	
[2022-08-15 23:55:33,821] implicit-augment.py->main line:454 [INFO]5% (1/20)
[2022-08-15 23:55:34,433] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.5535, -2.4263, -2.5568, -2.5412, -2.5630, -2.4849, -2.5502, -2.4719,
        -2.4849, -2.4294, -2.3784, -2.3780, -2.3798, -2.3908, -2.5496])
[2022-08-15 23:55:34,434] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([-0.0819, -0.0246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000])
[2022-08-15 23:55:34,557] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 1, batch_idx: 0, global_img_step: 2, aug_ops:[('Hsv', tensor([-0.4673,  0.6889, -0.1961])), ('sharpen', tensor([-0.9804]))]
[2022-08-15 23:55:34,558] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000010, hyper_lr=-0.002537	gLtNorm 0.0035 (0.0035)	gLvNorm 0.0160 (0.0160)	mvpNorm 0.0344 (0.0344)

[2022-08-15 23:55:37,326] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 1, batch_idx: 0, global_img_step: 3, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:55:38,005] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 1	 Inner Train loss: 1.2589, acc=0.4717, lr=0.000010	
[2022-08-15 23:55:38,006] implicit-augment.py->main line:454 [INFO]10% (2/20)
[2022-08-15 23:55:38,616] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.5535, -2.4263, -2.5568, -2.5412, -2.5630, -2.4849, -2.5502, -2.4719,
        -2.4849, -2.4294, -2.3784, -2.3780, -2.3798, -2.3908, -2.5496])
[2022-08-15 23:55:38,618] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([-0.0819, -0.0246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000])
[2022-08-15 23:55:38,747] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 2, batch_idx: 0, global_img_step: 4, aug_ops:[('gaussian noise', tensor([-0.2792]))]
[2022-08-15 23:55:38,747] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000010, hyper_lr=0.005000	gLtNorm 0.0019 (0.0019)	gLvNorm 0.0679 (0.0679)	mvpNorm 0.0912 (0.0912)

[2022-08-15 23:55:41,552] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 2, batch_idx: 0, global_img_step: 5, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:55:42,221] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 2	 Inner Train loss: 1.1533, acc=0.5163, lr=0.000010	
[2022-08-15 23:55:42,222] implicit-augment.py->main line:454 [INFO]15% (3/20)
[2022-08-15 23:55:42,841] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.5130, -2.6000, -2.3612, -2.3305, -2.6575, -2.4849, -2.7036, -2.4719,
        -2.4849, -2.3045, -2.2647, -2.4586, -2.4706, -2.5313, -2.4778])
[2022-08-15 23:55:42,842] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0877])
[2022-08-15 23:55:42,984] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 3, batch_idx: 0, global_img_step: 6, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:55:42,984] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000009, hyper_lr=0.012537	gLtNorm 0.0092 (0.0092)	gLvNorm 0.1486 (0.1486)	mvpNorm 0.2313 (0.2313)

[2022-08-15 23:55:45,803] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 3, batch_idx: 0, global_img_step: 7, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:55:46,474] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 3	 Inner Train loss: 1.0147, acc=0.5845, lr=0.000009	
[2022-08-15 23:55:46,475] implicit-augment.py->main line:454 [INFO]20% (4/20)
[2022-08-15 23:55:47,102] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.5130, -2.6000, -2.3612, -2.3305, -2.6575, -2.4849, -2.7036, -2.4719,
        -2.4849, -2.3045, -2.2647, -2.4586, -2.4706, -2.5313, -2.4778])
[2022-08-15 23:55:47,104] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0877])
[2022-08-15 23:55:47,236] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 4, batch_idx: 0, global_img_step: 8, aug_ops:[('gaussian noise', tensor([0.0645]))]
[2022-08-15 23:55:47,236] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000009, hyper_lr=0.020074	gLtNorm 0.3017 (0.3017)	gLvNorm 0.2465 (0.2465)	mvpNorm 0.0046 (0.0046)

[2022-08-15 23:55:50,138] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 4, batch_idx: 0, global_img_step: 9, aug_ops:[('ShearY', tensor([0.4984]))]
[2022-08-15 23:55:50,801] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 4	 Inner Train loss: 1.0296, acc=0.5790, lr=0.000009	
[2022-08-15 23:55:50,802] implicit-augment.py->main line:454 [INFO]25% (5/20)
[2022-08-15 23:55:51,426] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-1.9916, -3.0464, -2.0936, -2.5979, -2.7336, -2.4849, -2.8009, -2.4719,
        -2.4849, -1.8975, -2.6831, -2.7109, -2.4216, -2.3288, -2.0360])
[2022-08-15 23:55:51,428] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000, -0.0877])
[2022-08-15 23:55:51,568] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 5, batch_idx: 0, global_img_step: 10, aug_ops:[('saturation', tensor([-0.5337]))]
[2022-08-15 23:55:51,568] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000009, hyper_lr=0.027611	gLtNorm 0.0686 (0.0686)	gLvNorm 0.3419 (0.3419)	mvpNorm 0.7155 (0.7155)

[2022-08-15 23:55:54,454] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 5, batch_idx: 0, global_img_step: 11, aug_ops:[('gaussian blur', tensor([0.5364]))]
[2022-08-15 23:55:55,121] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 5	 Inner Train loss: 0.9741, acc=0.6155, lr=0.000009	
[2022-08-15 23:55:55,122] implicit-augment.py->main line:454 [INFO]30% (6/20)
[2022-08-15 23:55:55,746] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.0453, -3.3792, -1.8940, -2.5730, -3.0775, -2.4849, -2.4514, -2.4719,
        -2.4849, -2.2415, -2.6921, -2.7046, -2.3304, -2.0243, -1.9312])
[2022-08-15 23:55:55,747] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.2457])
[2022-08-15 23:55:55,882] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 6, batch_idx: 0, global_img_step: 12, aug_ops:[('TranslateY', tensor([-0.4544]))]
[2022-08-15 23:55:55,882] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000008, hyper_lr=0.035148	gLtNorm 0.0096 (0.0096)	gLvNorm 0.2783 (0.2783)	mvpNorm 0.3771 (0.3771)

[2022-08-15 23:55:58,703] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 6, batch_idx: 0, global_img_step: 13, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:55:59,383] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 6	 Inner Train loss: 1.0266, acc=0.5953, lr=0.000008	
[2022-08-15 23:55:59,383] implicit-augment.py->main line:454 [INFO]35% (7/20)
[2022-08-15 23:55:59,997] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.0453, -3.3792, -1.8940, -2.5730, -3.0775, -2.4849, -2.4514, -2.4719,
        -2.4849, -2.2415, -2.6921, -2.7046, -2.3304, -2.0243, -1.9312])
[2022-08-15 23:55:59,998] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.2457])
[2022-08-15 23:56:00,144] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 7, batch_idx: 0, global_img_step: 14, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:00,144] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000007, hyper_lr=0.041079	gLtNorm 0.0196 (0.0196)	gLvNorm 0.3872 (0.3872)	mvpNorm 0.2469 (0.2469)

[2022-08-15 23:56:02,976] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 7, batch_idx: 0, global_img_step: 15, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:03,649] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 7	 Inner Train loss: 1.1499, acc=0.5740, lr=0.000007	
[2022-08-15 23:56:03,651] implicit-augment.py->main line:454 [INFO]40% (8/20)
[2022-08-15 23:56:04,260] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.2918, -3.5409, -1.4886, -2.5571, -3.1885, -2.4849, -2.4034, -2.4719,
        -2.4849, -2.2607, -2.6292, -2.3521, -2.2750, -2.3344, -1.5221])
[2022-08-15 23:56:04,261] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.0253,  0.0000,  0.0000,  0.0000,  0.0000,
         0.4108,  0.2457])
[2022-08-15 23:56:04,357] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 8, batch_idx: 0, global_img_step: 16, aug_ops:[('Hed', tensor([0.2168, 0.9407, 0.1309]))]
[2022-08-15 23:56:04,358] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000007, hyper_lr=0.037513	gLtNorm 0.1293 (0.1293)	gLvNorm 0.0027 (0.0027)	mvpNorm 0.1548 (0.1548)

[2022-08-15 23:56:07,242] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 8, batch_idx: 0, global_img_step: 17, aug_ops:[('Hed', tensor([ 0.2688, -1.0000,  0.1429])), ('gaussian blur', tensor([0.1036])), ('ShearY', tensor([0.5366]))]
[2022-08-15 23:56:07,917] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 8	 Inner Train loss: 0.9658, acc=0.6255, lr=0.000007	
[2022-08-15 23:56:07,918] implicit-augment.py->main line:454 [INFO]45% (9/20)
[2022-08-15 23:56:08,547] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.3358, -3.3502, -1.8001, -2.5892, -2.8540, -2.4849, -2.4034, -2.0974,
        -2.4849, -2.2609, -2.4873, -1.9771, -2.4542, -2.4246, -1.5982])
[2022-08-15 23:56:08,549] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.0246, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000, -0.4003,  0.0000,  0.0000,  0.0000,  0.0000,
         0.4108,  0.2457])
[2022-08-15 23:56:08,741] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 9, batch_idx: 0, global_img_step: 18, aug_ops:[('brightness', tensor([0.2154]))]
[2022-08-15 23:56:08,742] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000006, hyper_lr=0.033567	gLtNorm 14.1885 (14.1885)	gLvNorm 1.1559 (1.1559)	mvpNorm 7.2580 (7.2580)

[2022-08-15 23:56:11,567] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 9, batch_idx: 0, global_img_step: 19, aug_ops:[('ShearX', tensor([-0.2021]))]
[2022-08-15 23:56:12,239] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 9	 Inner Train loss: 1.0482, acc=0.6018, lr=0.000006	
[2022-08-15 23:56:12,240] implicit-augment.py->main line:454 [INFO]50% (10/20)
[2022-08-15 23:56:12,871] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7596, -3.0550, -1.8383, -2.1345, -2.8192, -2.4849, -3.0325, -2.0974,
        -2.4849, -2.0842, -2.4336, -2.2871, -2.4939, -2.4050, -1.7291])
[2022-08-15 23:56:12,872] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0753,  0.2457])
[2022-08-15 23:56:13,005] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 10, batch_idx: 0, global_img_step: 20, aug_ops:[('TranslateX', tensor([-0.0766])), ('Equalize', tensor([-0.5365]))]
[2022-08-15 23:56:13,006] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000005, hyper_lr=0.029362	gLtNorm 62.9677 (62.9677)	gLvNorm 1.4558 (1.4558)	mvpNorm 45.3082 (45.3082)

[2022-08-15 23:56:15,834] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 10, batch_idx: 0, global_img_step: 21, aug_ops:[('contrast', tensor([0.4869])), ('saturation', tensor([-0.0611])), ('elastic transform', tensor([-0.1230]))]
[2022-08-15 23:56:16,509] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 10	 Inner Train loss: 1.0516, acc=0.5973, lr=0.000005	
[2022-08-15 23:56:16,510] implicit-augment.py->main line:454 [INFO]55% (11/20)
[2022-08-15 23:56:17,135] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7596, -3.0550, -1.8383, -2.1345, -2.8192, -2.4849, -3.0325, -2.0974,
        -2.4849, -2.0842, -2.4336, -2.2871, -2.4939, -2.4050, -1.7291])
[2022-08-15 23:56:17,137] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0753,  0.2457])
[2022-08-15 23:56:17,268] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 11, batch_idx: 0, global_img_step: 22, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:17,268] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000004, hyper_lr=0.025025	gLtNorm 34.8423 (34.8423)	gLvNorm 1.2659 (1.2659)	mvpNorm 22.8318 (22.8318)

[2022-08-15 23:56:20,139] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 11, batch_idx: 0, global_img_step: 23, aug_ops:[('Hed', tensor([ 0.4968,  0.2222, -0.1892])), ('ShearY', tensor([0.9769]))]
[2022-08-15 23:56:20,816] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 11	 Inner Train loss: 1.0411, acc=0.5879, lr=0.000004	
[2022-08-15 23:56:20,817] implicit-augment.py->main line:454 [INFO]60% (12/20)
[2022-08-15 23:56:21,446] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.6435, -3.1679, -1.8373, -1.9609, -2.9597, -2.4849, -3.0326, -2.0974,
        -2.4849, -2.1890, -2.4169, -2.2633, -2.4940, -2.4020, -1.5723])
[2022-08-15 23:56:21,448] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.2069,  0.0000,
         0.0753,  0.2457])
[2022-08-15 23:56:21,577] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 12, batch_idx: 0, global_img_step: 24, aug_ops:[('Hsv', tensor([ 0.2188,  0.5549, -0.7509])), ('elastic transform', tensor([0.5667])), ('TranslateX', tensor([0.1848])), ('Equalize', tensor([-0.2513]))]
[2022-08-15 23:56:21,577] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000003, hyper_lr=0.020688	gLtNorm 40.6184 (40.6184)	gLvNorm 0.3124 (0.3124)	mvpNorm 34.0252 (34.0252)

[2022-08-15 23:56:24,402] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 12, batch_idx: 0, global_img_step: 25, aug_ops:[('saturation', tensor([-0.4995])), ('ShearY', tensor([0.3184])), ('Equalize', tensor([-0.0705]))]
[2022-08-15 23:56:25,079] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 12	 Inner Train loss: 1.1837, acc=0.5534, lr=0.000000	
[2022-08-15 23:56:25,081] implicit-augment.py->main line:454 [INFO]65% (13/20)
[2022-08-15 23:56:25,706] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.6435, -3.1679, -1.8373, -1.9609, -2.9597, -2.4849, -3.0326, -2.0974,
        -2.4849, -2.1890, -2.4169, -2.2633, -2.4940, -2.4020, -1.5723])
[2022-08-15 23:56:25,707] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.2069,  0.0000,
         0.0753,  0.2457])
[2022-08-15 23:56:25,834] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 13, batch_idx: 0, global_img_step: 26, aug_ops:[('sharpen', tensor([-0.4116]))]
[2022-08-15 23:56:25,834] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000003, hyper_lr=0.016483	gLtNorm 3.6869 (3.6869)	gLvNorm 0.0945 (0.0945)	mvpNorm 4.9205 (4.9205)

[2022-08-15 23:56:28,697] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 13, batch_idx: 0, global_img_step: 27, aug_ops:[('saturation', tensor([0.3569])), ('sharpen', tensor([-0.3719]))]
[2022-08-15 23:56:29,380] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 13	 Inner Train loss: 1.3880, acc=0.5169, lr=0.000003	
[2022-08-15 23:56:29,382] implicit-augment.py->main line:454 [INFO]70% (14/20)
[2022-08-15 23:56:30,014] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.5056, -3.0408, -1.6774, -1.8046, -2.9654, -2.4849, -3.0327, -2.0974,
        -2.4849, -2.3535, -2.4509, -2.3473, -2.3644, -2.4119, -1.7209])
[2022-08-15 23:56:30,016] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0510,  0.0000,
         0.0753,  0.2457])
[2022-08-15 23:56:30,268] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 14, batch_idx: 0, global_img_step: 28, aug_ops:[('TranslateX', tensor([-0.0629]))]
[2022-08-15 23:56:30,269] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000002, hyper_lr=0.012538	gLtNorm 0.2918 (0.2918)	gLvNorm 0.3460 (0.3460)	mvpNorm 1.1688 (1.1688)

[2022-08-15 23:56:33,113] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 14, batch_idx: 0, global_img_step: 29, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:33,793] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 14	 Inner Train loss: 0.8031, acc=0.6750, lr=0.000002	
[2022-08-15 23:56:33,794] implicit-augment.py->main line:454 [INFO]75% (15/20)
[2022-08-15 23:56:34,416] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.6203, -3.0408, -1.6858, -1.8366, -2.9604, -2.4849, -3.0333, -2.0974,
        -2.4849, -2.2704, -2.3364, -2.4184, -2.3582, -2.4109, -1.6016])
[2022-08-15 23:56:34,418] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0510, -0.1254,
         0.0753,  0.2457])
[2022-08-15 23:56:34,560] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 15, batch_idx: 0, global_img_step: 30, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:34,560] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000001, hyper_lr=0.008971	gLtNorm 6.0672 (6.0672)	gLvNorm 0.2847 (0.2847)	mvpNorm 8.2288 (8.2288)

[2022-08-15 23:56:37,531] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 15, batch_idx: 0, global_img_step: 31, aug_ops:[('Hsv', tensor([-0.2195,  0.4892, -0.9001])), ('Hed', tensor([ 0.2164, -0.4031,  0.1814])), ('sharpen', tensor([0.9836])), ('Equalize', tensor([-0.4765]))]
[2022-08-15 23:56:38,215] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 15	 Inner Train loss: 1.0213, acc=0.6075, lr=0.000001	
[2022-08-15 23:56:38,216] implicit-augment.py->main line:454 [INFO]80% (16/20)
[2022-08-15 23:56:38,837] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7085, -3.1063, -1.7185, -1.8215, -2.9112, -2.4849, -3.0325, -2.0974,
        -2.4849, -2.3572, -2.3528, -2.4070, -2.3426, -2.4108, -1.5249])
[2022-08-15 23:56:38,839] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0019, -0.3183, -0.0184,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0510, -0.1254,
         0.0753,  0.2457])
[2022-08-15 23:56:38,973] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 16, batch_idx: 0, global_img_step: 32, aug_ops:[('saturation', tensor([-0.8058]))]
[2022-08-15 23:56:38,973] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000001, hyper_lr=0.005893	gLtNorm 17.5375 (17.5375)	gLvNorm 1.1011 (1.1011)	mvpNorm 22.1460 (22.1460)

[2022-08-15 23:56:41,861] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 16, batch_idx: 0, global_img_step: 33, aug_ops:[('saturation', tensor([-0.4046]))]
[2022-08-15 23:56:42,541] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 16	 Inner Train loss: 0.9564, acc=0.6338, lr=0.000001	
[2022-08-15 23:56:42,542] implicit-augment.py->main line:454 [INFO]85% (17/20)
[2022-08-15 23:56:43,174] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7081, -3.1639, -1.7185, -1.8801, -2.9355, -2.4849, -3.0369, -2.0974,
        -2.4849, -2.3129, -2.3003, -2.3869, -2.3965, -2.3985, -1.4856])
[2022-08-15 23:56:43,176] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0609, -0.3183,  0.0405,  0.2069,  0.2069,  0.2069,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0510, -0.1254,
         0.0753,  0.2457])
[2022-08-15 23:56:43,334] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 17, batch_idx: 0, global_img_step: 34, aug_ops:[('saturation', tensor([-0.1214]))]
[2022-08-15 23:56:43,334] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000001, hyper_lr=0.003396	gLtNorm 1.1374 (1.1374)	gLvNorm 0.3036 (0.3036)	mvpNorm 2.4058 (2.4058)

[2022-08-15 23:56:46,224] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 17, batch_idx: 0, global_img_step: 35, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:46,899] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 17	 Inner Train loss: 0.7717, acc=0.6813, lr=0.000001	
[2022-08-15 23:56:46,901] implicit-augment.py->main line:454 [INFO]90% (18/20)
[2022-08-15 23:56:47,521] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7081, -3.1680, -1.7198, -1.8814, -2.9361, -2.4849, -3.0370, -2.0974,
        -2.4849, -2.3168, -2.2980, -2.3856, -2.3981, -2.3988, -1.4842])
[2022-08-15 23:56:47,522] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0609, -0.3183,  0.0550,  0.2408,  0.1800,  0.2016,  0.0000,  0.0000,
         0.0000,  0.0000,  0.2936, -0.4003,  0.0000,  0.0000,  0.0824, -0.1254,
         0.0753,  0.2457])
[2022-08-15 23:56:47,663] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 18, batch_idx: 0, global_img_step: 36, aug_ops:[('saturation', tensor([-0.4854]))]
[2022-08-15 23:56:47,664] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000000, hyper_lr=0.001556	gLtNorm 0.1194 (0.1194)	gLvNorm 0.3363 (0.3363)	mvpNorm 0.4072 (0.4072)

[2022-08-15 23:56:50,536] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 18, batch_idx: 0, global_img_step: 37, aug_ops:[('TranslateX', tensor([-0.3031])), ('Equalize', tensor([0.3164]))]
[2022-08-15 23:56:51,221] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 18	 Inner Train loss: 0.9828, acc=0.6266, lr=0.000000	
[2022-08-15 23:56:51,222] implicit-augment.py->main line:454 [INFO]95% (19/20)
[2022-08-15 23:56:51,850] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramP_tensor([-2.7060, -3.1637, -1.7190, -1.8817, -2.9491, -2.4849, -3.0371, -2.0974,
        -2.4849, -2.3171, -2.2979, -2.3855, -2.3981, -2.3988, -1.4886])
[2022-08-15 23:56:51,851] automodels.py->Med_hyperHesTrain line:933 [INFO]data point 0 weight: paramM_tensor([ 0.0609, -0.3183,  0.0550,  0.2408,  0.1800,  0.2016, -0.0156,  0.0000,
         0.0156,  0.0000,  0.2936, -0.4003,  0.0000, -0.0156,  0.0824, -0.1254,
         0.0699,  0.2457])
[2022-08-15 23:56:51,979] automodels.py->Med_hyperHesTrain line:958 [INFO]hyperTrain epoch: 19, batch_idx: 0, global_img_step: 38, aug_ops:[('sharpen', tensor([0.5480])), ('gaussian noise', tensor([-0.1705])), ('Rotate', tensor([0.7314]))]
[2022-08-15 23:56:51,979] automodels.py->Med_hyperHesTrain line:964 [INFO]hyperTrain batch 0% (0/4), task_lr=0.000000, hyper_lr=0.000429	gLtNorm 0.4090 (0.4090)	gLvNorm 0.4650 (0.4650)	mvpNorm 0.5523 (0.5523)

[2022-08-15 23:56:54,857] automodels.py->Med_innerTrain line:1036 [INFO]Train epoch: 19, batch_idx: 0, global_img_step: 39, aug_ops:[('idenity', [1.0])]
[2022-08-15 23:56:55,555] automodels.py->Med_innerTrain line:1048 [INFO]Epoch: 19	 Inner Train loss: 1.0979, acc=0.6011, lr=0.000000	
