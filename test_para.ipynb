{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayeh/miniconda3/envs/autodo/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distrib\n",
    "import kornia\n",
    "import math\n",
    "from custom_models import *\n",
    "from custom_datasets import *\n",
    "from custom_transforms import *\n",
    "from utils import *\n",
    "from torch.utils.data import SubsetRandomSampler, Sampler, Subset, ConcatDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramM = nn.Parameter(torch.ones(3,3), requires_grad=True)\n",
    "paramM = paramM.cuda()\n",
    "a = torch.rand(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_scale = 1.\n",
    "dataset_0to4 = MedDataset('/mnt/Nami/Med_patch/8192_512_0to4/Good', '/mnt/Nami/Med_patch/8192_512_0to4/Good_mask', img_scale)\n",
    "total_images = len(dataset_0to4)\n",
    "val_images_1 = 25\n",
    "train_images = total_images - val_images_1\n",
    "train_dataset, val_dataset_1 = random_split(dataset_0to4, [train_images,val_images_1])\n",
    "#test data: WSI 6-10\n",
    "dataset_5to9 = MedDataset('/mnt/Nami/Med_patch/8192_512_5to9/Good', '/mnt/Nami/Med_patch/8192_512_5to9/Good_mask', img_scale)\n",
    "_, val_dataset_2 = random_split(dataset_5to9, [len(dataset_5to9)-val_images_1,val_images_1])\n",
    "val_dataset = val_dataset_1+val_dataset_2\n",
    "test_dataset = MedDataset('/mnt/Nami/Med_patch/8192_512_10/Good', '/mnt/Nami/Med_patch/8192_512_10/Good_mask', img_scale)\n",
    "valid_images = len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 7\n",
    "N = 5\n",
    "B = 2\n",
    "magn = 5\n",
    "grad = True\n",
    "#預設機率與強度超參數的初始值\n",
    "magnNorm = torch.ones(1)*magn/10.0 # normalize to 10 like in RandAugment\n",
    "probNorm = torch.ones(1)*1/(K-2) # 1/(K-2) probability\n",
    "magnLogit = torch.log(magnNorm/(1-magnNorm)) # convert to logit\n",
    "probLogit = torch.log(probNorm/(1-probNorm)) # convert to logit\n",
    "# affine transforms (mid, range)\n",
    "angle = [0.0, 30.0] # [-30.0:30.0] rotation angle\n",
    "trans = [0.0, 0.45] # [-0.45:0.45] X/Y translate\n",
    "shear = [0.0, 0.30] # [-0.30:0.30] X/Y shear\n",
    "scale = [1.0, 0.50] # [ 0.50:1.50] X/Y scale\n",
    "# color transforms (mid, range)\n",
    "bri = [0.0, 0.9] # [-0.9:0.9] brightness\n",
    "con = [1.0, 0.9] # [0.1:1.9] contrast\n",
    "sat = [0.1, 1.9] # [-0.30:0.30] saturation\n",
    "#hue = [1.0, 0.50] # [ 0.70:1.30] hue\n",
    "#gam = [1.0, 0.50] # [ 0.70:1.30] gamma\n",
    "# actP: 機率的激活函數，actM: 強度的激活函數\n",
    "actP = nn.Sigmoid()\n",
    "actM = nn.Sigmoid()\n",
    "# 建立機率與強度的可學習超參數矩陣 shape = (擴增方法數量*資料數量)\n",
    "paramP = nn.Parameter(probLogit*torch.ones(K,N), requires_grad=grad)\n",
    "paramM = nn.Parameter(magnLogit*torch.ones(K,N), requires_grad=grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [0,3]\n",
    "paramPos = torch.log(    actP(paramP[:,idx])) # [-Inf:0] [擴增方法數, data point number] 取針對該資料的使用機率之參數\n",
    "paramNeg = torch.log(1.0-actP(paramP[:,idx])) # [-Inf:0] [擴增方法數, data point number] 取針對該資料的不使用機率之參數\n",
    "paramM2 = actM(paramM[:,idx]) # (K+J)xB [0:1], default=magn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramP = torch.cat([paramPos.view(-1,1), paramNeg.view(-1,1)], dim=1) # B*(K+J)x2\n",
    "# reparametrize probabilities and magnitudes\n",
    "sampleP = F.gumbel_softmax(paramP, tau=1.0, hard=True) # B*(K+J)x2\n",
    "sampleP = sampleP[:,0]\n",
    "sampleP = sampleP.reshape(K,B)\n",
    "# # reparametrize magnitudes\n",
    "# sampleM = paramM[:K] * torch.rand(K,B) # KxB, prior: U[0,1]\n",
    "G = torch.randn(K,B)\n",
    "sampleM = paramM2 * G # KxB, prior: N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7640,  0.4978],\n",
      "        [ 0.1357,  1.2249],\n",
      "        [ 0.1424, -0.5961],\n",
      "        [-1.2880, -0.6164],\n",
      "        [ 0.1763,  0.3200],\n",
      "        [ 1.7368, -0.5983],\n",
      "        [ 0.9187,  3.0334],\n",
      "        [ 1.0921, -1.4722],\n",
      "        [ 0.3853, -0.1416]])\n"
     ]
    }
   ],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3820,  0.2489],\n",
      "        [ 0.0678,  0.6124],\n",
      "        [ 0.0712, -0.2981],\n",
      "        [-0.6440, -0.3082],\n",
      "        [ 0.0881,  0.1600],\n",
      "        [ 0.8684, -0.2991],\n",
      "        [ 0.4593,  1.5167],\n",
      "        [ 0.5461, -0.7361],\n",
      "        [ 0.1927, -0.0708]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sampleM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('autodo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab1c5bcb2e12e60572765b72c297d9973a4d1aa919b4c84abd79a2f642f5ee12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
